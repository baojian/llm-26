{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61abb5ee-ddb8-4b8a-bc6b-da2e1dc16bc6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "/* JupyterLab 4.x: center the notebook area */\n",
       ".jp-NotebookPanel-notebook,\n",
       ".jp-NotebookPanel .jp-Notebook {\n",
       "  width: 85% !important;\n",
       "  max-width: 1100px !important;\n",
       "  margin: 0 auto !important;\n",
       "}\n",
       "\n",
       "/* Make wide outputs scroll instead of breaking the layout */\n",
       ".jp-OutputArea-output {\n",
       "  overflow-x: auto !important;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centered JupyterLab notebook + SVG inline figures.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(r\"\"\"\n",
    "<style>\n",
    "/* JupyterLab 4.x: center the notebook area */\n",
    ".jp-NotebookPanel-notebook,\n",
    ".jp-NotebookPanel .jp-Notebook {\n",
    "  width: 85% !important;\n",
    "  max-width: 1100px !important;\n",
    "  margin: 0 auto !important;\n",
    "}\n",
    "\n",
    "/* Make wide outputs scroll instead of breaking the layout */\n",
    ".jp-OutputArea-output {\n",
    "  overflow-x: auto !important;\n",
    "}\n",
    "</style>\n",
    "\"\"\"))\n",
    "\n",
    "%config InlineBackend.figure_format = \"svg\"\n",
    "print(\"Centered JupyterLab notebook + SVG inline figures.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1725d4c-f79e-44c3-90cd-5436528d211f",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Lecture-02: Statistical language models\n",
    "\n",
    "- **CS40008.01, NLP and LLMs**\n",
    "- **Date:** 03/12/2026\n",
    "- **Lecturer:** Baojian Zhou\n",
    "- **Institution:** The School of Data Science, Fudan University"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ee137b-dc38-4989-8ace-9ab1f8c1d409",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<a id=\"0\"></a> <br>\n",
    "## Table of Contents\n",
    "- [1. Understand data distribution](#1)\n",
    "  - [1.1 KL divergence](#11)\n",
    "  - [1.2 Log probability of sentences](#12)\n",
    "- [1. Build Ngram-LMs](#2)\n",
    "  - [1.1 Load wikitext-103](#21)\n",
    "  - [1.2 Sentence tokenization for wikitext](#22)\n",
    "  - [1.3 Training Ngram via kenlm](#23)\n",
    "  - [1.4 Calculate the perplexity](#24)\n",
    "  - [1.5 Generate sentences](#25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9618ec-0528-4010-81fc-f78b2ae864c5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<a id=\"1\"></a>\n",
    "## 1. Understand data distribution\n",
    "\n",
    "- **Motivation: assign probabilities to sentences**\n",
    "  - **Speech Recognition:** In the task of speech recongnition, we should need to know which sentence is more likely than others. Exmplore, the sentence `It's hard to recognize speech` is more likely the corrent speech than the sentence `It's hard to recognize speech`. That is, a good model should give\n",
    "    \n",
    "    $P_\\theta($ `It's hard to recognize speech` $) > P_\\theta($ `It's hard to wreck a nice beach` $)$\n",
    "  - **Machine Translation (MT):** Given the source sentence, `他向记者介绍了主要内容` that we want to tranlate into English, there are some potential candidates\n",
    "    - $S_1$ = He briefed reporters on the main contents of the statement\n",
    "    - $S_2$ = He introduced reporters to the main contents of the statement\n",
    "    - $S_3$ = He briefed to reporters the main contents of the statement\n",
    "    - $S_4$ = He to reporters introduced main content\n",
    "    A good MT model should have $P_\\theta(S_1 )> P_\\theta(S_2) \\approx P_\\theta(S_3) > P_\\theta(S_4)$\n",
    "  - **Spell Correction:** Consider the testing sentence `The office is about fifteen minuets from my house`, where `minuets` is misspelled. A good model should have\n",
    "    \n",
    "    $P_\\theta($ `about fifteen minutes from` $)$ $>P_\\theta($ `about fifteen minuets from` $)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b37aed-cd36-48b4-aba7-a5f2155b88c0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<a id=\"11\"></a>\n",
    "### 1.1 KL divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95723a5-a0f5-40fa-ba10-d5efa6abd384",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- **Model distribution approximate true distribution via KL divergence**\n",
    "  \n",
    "In general, LLMs approximate an unknown distribution $p_{\\text{data}}$, which is a distribution over token sequences:\n",
    "      $$\\mathbf{w}_{1:n}=(w_1,\\ldots,w_n), \\qquad \\mathbf{w}_{1:n}\\sim p_{\\text{data}}(\\cdot),$$\n",
    "      where $p_{\\text{data}}$ is unknown. We only observe a corpus (samples):\n",
    "      $$\\mathcal{D}=\\{\\mathbf{w}^{(i)}\\}_{i=1}^{N}, \\qquad \\mathbf{w}^{(i)} \\overset{\\text{i.i.d.}}{\\sim} p_{\\text{data}}(\\cdot).$$\n",
    "    </div>\n",
    "We train a model distribution (LLMs) $p_\\theta(\\mathbf{w})$ so that\n",
    "      $$p_\\theta(\\mathbf{w}) \\approx p_{\\text{data}}(\\mathbf{w}).$$\n",
    "Under $p_\\theta$, sequences that look like real language should get **higher** probability than corrupted/random ones:\n",
    "      $$p_\\theta(\\text{“natural sentence”})\\;>\\;p_\\theta(\\text{“random sentence”}).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dbe8a7-ed57-4d89-8779-c05d9cb30b1b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- **Next, we will see how to use KL divergence to measure difference between $p_{\\text{data}}$ and $p_\\theta$**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d7d80a-ff0f-440b-ae34-df713b8accea",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**Training objective: make $p_\\theta \\approx p_{\\text{data}}:$** Ideal goal (distribution matching) is to make $p_\\theta \\approx p_{\\text{data}}.$ To do this, one principled way is to find a $\\theta$ such that the [KL divergence](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence) is minimized, i.e.,\n",
    "      $$\\theta^\\star=\\arg\\min_\\theta \\mathrm{KL}\\big(p_{\\text{data}} \\,\\|\\, p_\\theta\\big).$$\n",
    "This is equivalent to maximizing expected log-likelihood:\n",
    "      $$\\arg\\min_\\theta \\mathrm{KL}(p_{\\text{data}}\\|p_\\theta)\n",
    "      \\;\\Longleftrightarrow\\;\n",
    "      \\arg\\max_\\theta \\mathbb{E}_{\\mathbf{w} \\sim p_{\\text{data}}}\\big[\\log p_\\theta(\\mathbf{w})\\big].$$\n",
    "Since $p_{\\text{data}}$ is unknown, use the dataset $\\{\\mathbf{w}^{(i)}\\}_{i=1}^N$ to approximate the expectation:\n",
    "      $$\\max_\\theta \\frac{1}{N}\\sum_{i=1}^N \\log p_\\theta (\\mathbf{w}^{(i)}).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379f9d40-5b76-4034-b4dc-383aadc96b1c",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "  background: #f2f2f2;\n",
    "  border: 1px solid #d9d9d9;\n",
    "  border-left: 6px solid #9e9e9e;\n",
    "  padding: 16px 18px;\n",
    "  border-radius: 12px;\n",
    "  font-size: 18px;\n",
    "  line-height: 1.35;\n",
    "\">\n",
    "\n",
    "  <div style=\"font-weight: 800; font-size: 20px; margin-bottom: 10px;\">\n",
    "    Theorem (KL minimization ⇔ maximum expected log-likelihood)\n",
    "  </div>\n",
    "  <div style=\"margin-bottom: 10px;\">\n",
    "    Let \\(p_{\\text{data}}(\\mathbf{w})\\) be fixed and let \\(p_\\theta(\\mathbf{w})\\) be a model family.\n",
    "    Assume \\(\\mathbb{E}_{p_{\\text{data}}}[|\\log p_\\theta(\\mathbf{w})|] < \\infty\\) and\n",
    "    \\(p_\\theta(\\mathbf{w})>0\\) whenever \\(p_{\\text{data}}(\\mathbf{w})>0\\).\n",
    "    Then\n",
    "  </div>\n",
    "\n",
    "  <div style=\"margin: 10px 0;\">\n",
    "    \\[\n",
    "      \\theta^\\star \\in \\arg\\min_{\\theta} \\mathrm{KL}\\!\\left(p_{\\text{data}}\\;\\|\\;p_\\theta\\right)\n",
    "      \\quad\\Longleftrightarrow\\quad\n",
    "      \\theta^\\star \\in \\arg\\max_{\\theta}\\mathbb{E}_{\\mathbf{w}\\sim p_{\\text{data}}}\\!\\left[\\log p_\\theta(\\mathbf{w})\\right].\n",
    "    \\]\n",
    "  </div>\n",
    "\n",
    "  <details style=\"margin-top: 10px;\">\n",
    "    <summary style=\"cursor: pointer; font-weight: 700;\">Proof (click to expand)</summary>\n",
    "    <div style=\"margin-top: 10px;\">\n",
    "      By definition,\n",
    "      \\[\n",
    "        \\mathrm{KL}(p_{\\text{data}}\\|p_\\theta)\n",
    "        = \\mathbb{E}_{p_{\\text{data}}}\\!\\left[\\log\\frac{p_{\\text{data}}(\\mathbf{w})}{p_\\theta(\\mathbf{w})}\\right]\n",
    "        = \\mathbb{E}_{p_{\\text{data}}}[\\log p_{\\text{data}}(\\mathbf{w})]\n",
    "          - \\mathbb{E}_{p_{\\text{data}}}[\\log p_\\theta(\\mathbf{w})].\n",
    "      \\]\n",
    "      The term \\(\\mathbb{E}_{p_{\\text{data}}}[\\log p_{\\text{data}}(\\mathbf{w})]\\) does not depend on \\(\\theta\\),\n",
    "      so minimizing \\(\\mathrm{KL}(p_{\\text{data}}\\|p_\\theta)\\) over \\(\\theta\\) is equivalent to maximizing\n",
    "      \\(\\mathbb{E}_{p_{\\text{data}}}[\\log p_\\theta(\\mathbf{w})]\\) over \\(\\theta\\). $\\square$\n",
    "    <hr class=\"thick-line\">\n",
    "In detail, recall the definition of KL divergence:\n",
    "$$\\mathrm{KL}\\!\\left(p_{\\text{data}}\\;\\|\\;p_\\theta\\right):=\\mathbb{E}_{\\mathbf{w}\\sim p_{\\text{data}}}\n",
    "\\left[\\log\\frac{p_{\\text{data}}(\\mathbf{w})}{p_\\theta(\\mathbf{w})}\\right].$$\n",
    "Expand the log-ratio:\n",
    "$$\\log\\frac{p_{\\text{data}}(\\mathbf{w})}{p_\\theta(\\mathbf{w})}\n",
    "= \\log p_{\\text{data}}(\\mathbf{w})-\\log p_\\theta(\\mathbf{w}).$$\n",
    "Take expectation w.r.t. $p_{\\text{data}}$:\n",
    "$$\\mathrm{KL}\\!\\left(p_{\\text{data}}\\;\\|\\;p_\\theta\\right) = \\mathbb{E}_{p_{\\text{data}}}\\!\\left[\\log p_{\\text{data}}(\\mathbf{w})\\right] - \\mathbb{E}_{p_{\\text{data}}}\\!\\left[\\log p_\\theta(\\mathbf{w})\\right].\n",
    "\\tag{1} $$\n",
    "Now observe the key point: the first term, $\\mathbb{E}_{p_{\\text{data}}}\\!\\left[\\log p_{\\text{data}}(\\mathbf{w})\\right]$, does not depend on $\\theta$, because $p_{\\text{data}}$ is fixed. Therefore, as a function of $\\theta$, the KL divergence differs from $\\mathbb{E}_{p_{\\text{data}}}[\\log p_\\theta(\\mathbf{w})]$ only by an additive constant. Formally, let $C := \\mathbb{E}_{p_{\\text{data}}}\\!\\left[\\log p_{\\text{data}}(\\mathbf{w})\\right]$, which is independent of $\\theta$. Then (1) becomes \n",
    "$$\\mathrm{KL}\\!\\left(p_{\\text{data}}\\;\\|\\;p_\\theta\\right)= C-\\mathbb{E}_{p_{\\text{data}}}\\!\\left[\\log p_\\theta(\\mathbf{w})\\right].\\tag{2}$$\n",
    "Minimizing the left-hand side over $\\theta$ is equivalent to minimizing the right-hand side over $\\theta$. Since $C$ is constant in $\\theta$, minimizing $C-\\mathbb{E}_{p_{\\text{data}}}[\\log p_\\theta(\\mathbf{w})]$ is equivalent to maximizing $\\mathbb{E}_{p_{\\text{data}}}[\\log p_\\theta(\\mathbf{w})]$. Hence,\n",
    "$$\\arg\\min_{\\theta}\\mathrm{KL}\\!\\left(p_{\\text{data}}\\;\\|\\;p_\\theta\\right)\n",
    "= \\arg\\max_{\\theta}\\mathbb{E}_{\\mathbf{w}\\sim p_{\\text{data}}}\\!\\left[\\log p_\\theta(\\mathbf{w})\\right].$$\n",
    "\n",
    "This proves the equivalence. $\\square$\n",
    "        \n",
    "        \\(\\square\\)\n",
    "    </div>\n",
    "  </details>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b49b61c-9aac-4f68-9b86-dde0fdc21676",
   "metadata": {},
   "source": [
    "- **Remark**:\n",
    "Equation (2) can be rewritten as:\n",
    "$$\\mathbb{E}_{p_{\\text{data}}}\\!\\left[\\log p_\\theta(\\mathbf{w})\\right] = -\\mathrm{KL}(p_{\\text{data}}\\|p_\\theta) + \\mathbb{E}_{p_{\\text{data}}}[\\log p_{\\text{data}}(\\mathbf{w})],$$\n",
    "so maximizing expected log-likelihood is maximizing a negative KL plus a constant (the entropy term of $p_{\\text{data}})$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b36aec4-10fd-480b-888d-2de3904a3dff",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- **Test the KL divergence under Gaussian distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5f6d344c-8de9-4eb6-a0f3-4589e0e7ca13",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\mathrm{KL}\\!\\left(p_{\\text{data}} \\,\\|\\, p_{\\theta_1}\\right) = 0.954754\\quad \\text{$p_{\\theta_1}$ (two peaks, wrong means)}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\mathrm{KL}\\!\\left(p_{\\text{data}} \\,\\|\\, p_{\\theta_2}\\right) = 0.295194\\quad \\text{$p_{\\theta_2}$ (two peaks, wrong std)}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\mathrm{KL}\\!\\left(p_{\\text{data}} \\,\\|\\, p_{\\theta_3}\\right) = 0.016962\\quad \\text{$p_{\\theta_3}$ (close to true)}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"712.34375pt\" height=\"351.03625pt\" viewBox=\"0 0 712.34375 351.03625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2026-01-11T20:50:03.360736</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.10.7, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 351.03625 \n",
       "L 712.34375 351.03625 \n",
       "L 712.34375 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 50.14375 313.48 \n",
       "L 705.14375 313.48 \n",
       "L 705.14375 22.32 \n",
       "L 50.14375 22.32 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path id=\"m9b44a431e6\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m9b44a431e6\" x=\"79.916477\" y=\"313.48\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- −8 -->\n",
       "      <g transform=\"translate(72.545384 328.078438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-2212\" d=\"M 678 2272 \n",
       "L 4684 2272 \n",
       "L 4684 1741 \n",
       "L 678 1741 \n",
       "L 678 2272 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \n",
       "Q 1584 2216 1326 1975 \n",
       "Q 1069 1734 1069 1313 \n",
       "Q 1069 891 1326 650 \n",
       "Q 1584 409 2034 409 \n",
       "Q 2484 409 2743 651 \n",
       "Q 3003 894 3003 1313 \n",
       "Q 3003 1734 2745 1975 \n",
       "Q 2488 2216 2034 2216 \n",
       "z\n",
       "M 1403 2484 \n",
       "Q 997 2584 770 2862 \n",
       "Q 544 3141 544 3541 \n",
       "Q 544 4100 942 4425 \n",
       "Q 1341 4750 2034 4750 \n",
       "Q 2731 4750 3128 4425 \n",
       "Q 3525 4100 3525 3541 \n",
       "Q 3525 3141 3298 2862 \n",
       "Q 3072 2584 2669 2484 \n",
       "Q 3125 2378 3379 2068 \n",
       "Q 3634 1759 3634 1313 \n",
       "Q 3634 634 3220 271 \n",
       "Q 2806 -91 2034 -91 \n",
       "Q 1263 -91 848 271 \n",
       "Q 434 634 434 1313 \n",
       "Q 434 1759 690 2068 \n",
       "Q 947 2378 1403 2484 \n",
       "z\n",
       "M 1172 3481 \n",
       "Q 1172 3119 1398 2916 \n",
       "Q 1625 2713 2034 2713 \n",
       "Q 2441 2713 2670 2916 \n",
       "Q 2900 3119 2900 3481 \n",
       "Q 2900 3844 2670 4047 \n",
       "Q 2441 4250 2034 4250 \n",
       "Q 1625 4250 1398 4047 \n",
       "Q 1172 3844 1172 3481 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-38\" transform=\"translate(83.789062 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m9b44a431e6\" x=\"154.348295\" y=\"313.48\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- −6 -->\n",
       "      <g transform=\"translate(146.977202 328.078438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \n",
       "Q 1688 2584 1439 2293 \n",
       "Q 1191 2003 1191 1497 \n",
       "Q 1191 994 1439 701 \n",
       "Q 1688 409 2113 409 \n",
       "Q 2538 409 2786 701 \n",
       "Q 3034 994 3034 1497 \n",
       "Q 3034 2003 2786 2293 \n",
       "Q 2538 2584 2113 2584 \n",
       "z\n",
       "M 3366 4563 \n",
       "L 3366 3988 \n",
       "Q 3128 4100 2886 4159 \n",
       "Q 2644 4219 2406 4219 \n",
       "Q 1781 4219 1451 3797 \n",
       "Q 1122 3375 1075 2522 \n",
       "Q 1259 2794 1537 2939 \n",
       "Q 1816 3084 2150 3084 \n",
       "Q 2853 3084 3261 2657 \n",
       "Q 3669 2231 3669 1497 \n",
       "Q 3669 778 3244 343 \n",
       "Q 2819 -91 2113 -91 \n",
       "Q 1303 -91 875 529 \n",
       "Q 447 1150 447 2328 \n",
       "Q 447 3434 972 4092 \n",
       "Q 1497 4750 2381 4750 \n",
       "Q 2619 4750 2861 4703 \n",
       "Q 3103 4656 3366 4563 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-36\" transform=\"translate(83.789062 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m9b44a431e6\" x=\"228.780114\" y=\"313.48\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- −4 -->\n",
       "      <g transform=\"translate(221.40902 328.078438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \n",
       "L 825 1625 \n",
       "L 2419 1625 \n",
       "L 2419 4116 \n",
       "z\n",
       "M 2253 4666 \n",
       "L 3047 4666 \n",
       "L 3047 1625 \n",
       "L 3713 1625 \n",
       "L 3713 1100 \n",
       "L 3047 1100 \n",
       "L 3047 0 \n",
       "L 2419 0 \n",
       "L 2419 1100 \n",
       "L 313 1100 \n",
       "L 313 1709 \n",
       "L 2253 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-34\" transform=\"translate(83.789062 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m9b44a431e6\" x=\"303.211932\" y=\"313.48\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- −2 -->\n",
       "      <g transform=\"translate(295.840838 328.078438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" transform=\"translate(83.789062 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m9b44a431e6\" x=\"377.64375\" y=\"313.48\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(374.4625 328.078438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m9b44a431e6\" x=\"452.075568\" y=\"313.48\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 2 -->\n",
       "      <g transform=\"translate(448.894318 328.078438) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_7\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m9b44a431e6\" x=\"526.507386\" y=\"313.48\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 4 -->\n",
       "      <g transform=\"translate(523.326136 328.078438) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_8\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m9b44a431e6\" x=\"600.939205\" y=\"313.48\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 6 -->\n",
       "      <g transform=\"translate(597.757955 328.078438) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-36\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_9\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m9b44a431e6\" x=\"675.371023\" y=\"313.48\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 8 -->\n",
       "      <g transform=\"translate(672.189773 328.078438) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-38\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_10\">\n",
       "     <!-- x -->\n",
       "     <g transform=\"translate(374.684375 341.756562) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-78\" d=\"M 3513 3500 \n",
       "L 2247 1797 \n",
       "L 3578 0 \n",
       "L 2900 0 \n",
       "L 1881 1375 \n",
       "L 863 0 \n",
       "L 184 0 \n",
       "L 1544 1831 \n",
       "L 300 3500 \n",
       "L 978 3500 \n",
       "L 1906 2253 \n",
       "L 2834 3500 \n",
       "L 3513 3500 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-78\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <defs>\n",
       "       <path id=\"m94bd77bc0a\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m94bd77bc0a\" x=\"50.14375\" y=\"300.245455\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 0.00 -->\n",
       "      <g transform=\"translate(20.878125 304.044673) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \n",
       "L 1344 794 \n",
       "L 1344 0 \n",
       "L 684 0 \n",
       "L 684 794 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(63.623047 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(95.410156 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(159.033203 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m94bd77bc0a\" x=\"50.14375\" y=\"267.071369\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 0.05 -->\n",
       "      <g transform=\"translate(20.878125 270.870587) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(63.623047 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(95.410156 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" transform=\"translate(159.033203 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m94bd77bc0a\" x=\"50.14375\" y=\"233.897283\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 0.10 -->\n",
       "      <g transform=\"translate(20.878125 237.696502) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(63.623047 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(95.410156 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(159.033203 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m94bd77bc0a\" x=\"50.14375\" y=\"200.723197\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_14\">\n",
       "      <!-- 0.15 -->\n",
       "      <g transform=\"translate(20.878125 204.522416) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(63.623047 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(95.410156 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" transform=\"translate(159.033203 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_14\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m94bd77bc0a\" x=\"50.14375\" y=\"167.549111\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_15\">\n",
       "      <!-- 0.20 -->\n",
       "      <g transform=\"translate(20.878125 171.34833) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(63.623047 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" transform=\"translate(95.410156 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(159.033203 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_15\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m94bd77bc0a\" x=\"50.14375\" y=\"134.375025\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_16\">\n",
       "      <!-- 0.25 -->\n",
       "      <g transform=\"translate(20.878125 138.174244) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(63.623047 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" transform=\"translate(95.410156 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" transform=\"translate(159.033203 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_7\">\n",
       "     <g id=\"line2d_16\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m94bd77bc0a\" x=\"50.14375\" y=\"101.20094\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_17\">\n",
       "      <!-- 0.30 -->\n",
       "      <g transform=\"translate(20.878125 105.000158) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \n",
       "Q 3050 2419 3304 2112 \n",
       "Q 3559 1806 3559 1356 \n",
       "Q 3559 666 3084 287 \n",
       "Q 2609 -91 1734 -91 \n",
       "Q 1441 -91 1130 -33 \n",
       "Q 819 25 488 141 \n",
       "L 488 750 \n",
       "Q 750 597 1062 519 \n",
       "Q 1375 441 1716 441 \n",
       "Q 2309 441 2620 675 \n",
       "Q 2931 909 2931 1356 \n",
       "Q 2931 1769 2642 2001 \n",
       "Q 2353 2234 1838 2234 \n",
       "L 1294 2234 \n",
       "L 1294 2753 \n",
       "L 1863 2753 \n",
       "Q 2328 2753 2575 2939 \n",
       "Q 2822 3125 2822 3475 \n",
       "Q 2822 3834 2567 4026 \n",
       "Q 2313 4219 1838 4219 \n",
       "Q 1578 4219 1281 4162 \n",
       "Q 984 4106 628 3988 \n",
       "L 628 4550 \n",
       "Q 988 4650 1302 4700 \n",
       "Q 1616 4750 1894 4750 \n",
       "Q 2613 4750 3031 4423 \n",
       "Q 3450 4097 3450 3541 \n",
       "Q 3450 3153 3228 2886 \n",
       "Q 3006 2619 2597 2516 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(63.623047 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-33\" transform=\"translate(95.410156 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(159.033203 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_8\">\n",
       "     <g id=\"line2d_17\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m94bd77bc0a\" x=\"50.14375\" y=\"68.026854\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_18\">\n",
       "      <!-- 0.35 -->\n",
       "      <g transform=\"translate(20.878125 71.826072) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(63.623047 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-33\" transform=\"translate(95.410156 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" transform=\"translate(159.033203 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_9\">\n",
       "     <g id=\"line2d_18\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m94bd77bc0a\" x=\"50.14375\" y=\"34.852768\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_19\">\n",
       "      <!-- 0.40 -->\n",
       "      <g transform=\"translate(20.878125 38.651987) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(63.623047 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-34\" transform=\"translate(95.410156 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(159.033203 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_20\">\n",
       "     <!-- density -->\n",
       "     <g transform=\"translate(14.798438 186.232812) rotate(-90) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \n",
       "L 2906 4863 \n",
       "L 3481 4863 \n",
       "L 3481 0 \n",
       "L 2906 0 \n",
       "L 2906 525 \n",
       "Q 2725 213 2448 61 \n",
       "Q 2172 -91 1784 -91 \n",
       "Q 1150 -91 751 415 \n",
       "Q 353 922 353 1747 \n",
       "Q 353 2572 751 3078 \n",
       "Q 1150 3584 1784 3584 \n",
       "Q 2172 3584 2448 3432 \n",
       "Q 2725 3281 2906 2969 \n",
       "z\n",
       "M 947 1747 \n",
       "Q 947 1113 1208 752 \n",
       "Q 1469 391 1925 391 \n",
       "Q 2381 391 2643 752 \n",
       "Q 2906 1113 2906 1747 \n",
       "Q 2906 2381 2643 2742 \n",
       "Q 2381 3103 1925 3103 \n",
       "Q 1469 3103 1208 2742 \n",
       "Q 947 2381 947 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
       "L 3597 1613 \n",
       "L 953 1613 \n",
       "Q 991 1019 1311 708 \n",
       "Q 1631 397 2203 397 \n",
       "Q 2534 397 2845 478 \n",
       "Q 3156 559 3463 722 \n",
       "L 3463 178 \n",
       "Q 3153 47 2828 -22 \n",
       "Q 2503 -91 2169 -91 \n",
       "Q 1331 -91 842 396 \n",
       "Q 353 884 353 1716 \n",
       "Q 353 2575 817 3079 \n",
       "Q 1281 3584 2069 3584 \n",
       "Q 2775 3584 3186 3129 \n",
       "Q 3597 2675 3597 1894 \n",
       "z\n",
       "M 3022 2063 \n",
       "Q 3016 2534 2758 2815 \n",
       "Q 2500 3097 2075 3097 \n",
       "Q 1594 3097 1305 2825 \n",
       "Q 1016 2553 972 2059 \n",
       "L 3022 2063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \n",
       "L 2834 2853 \n",
       "Q 2591 2978 2328 3040 \n",
       "Q 2066 3103 1784 3103 \n",
       "Q 1356 3103 1142 2972 \n",
       "Q 928 2841 928 2578 \n",
       "Q 928 2378 1081 2264 \n",
       "Q 1234 2150 1697 2047 \n",
       "L 1894 2003 \n",
       "Q 2506 1872 2764 1633 \n",
       "Q 3022 1394 3022 966 \n",
       "Q 3022 478 2636 193 \n",
       "Q 2250 -91 1575 -91 \n",
       "Q 1294 -91 989 -36 \n",
       "Q 684 19 347 128 \n",
       "L 347 722 \n",
       "Q 666 556 975 473 \n",
       "Q 1284 391 1588 391 \n",
       "Q 1994 391 2212 530 \n",
       "Q 2431 669 2431 922 \n",
       "Q 2431 1156 2273 1281 \n",
       "Q 2116 1406 1581 1522 \n",
       "L 1381 1569 \n",
       "Q 847 1681 609 1914 \n",
       "Q 372 2147 372 2553 \n",
       "Q 372 3047 722 3315 \n",
       "Q 1072 3584 1716 3584 \n",
       "Q 2034 3584 2315 3537 \n",
       "Q 2597 3491 2834 3397 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \n",
       "L 1178 3500 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 3500 \n",
       "z\n",
       "M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 4134 \n",
       "L 603 4134 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \n",
       "L 1172 3500 \n",
       "L 2356 3500 \n",
       "L 2356 3053 \n",
       "L 1172 3053 \n",
       "L 1172 1153 \n",
       "Q 1172 725 1289 603 \n",
       "Q 1406 481 1766 481 \n",
       "L 2356 481 \n",
       "L 2356 0 \n",
       "L 1766 0 \n",
       "Q 1100 0 847 248 \n",
       "Q 594 497 594 1153 \n",
       "L 594 3053 \n",
       "L 172 3053 \n",
       "L 172 3500 \n",
       "L 594 3500 \n",
       "L 594 4494 \n",
       "L 1172 4494 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-79\" d=\"M 2059 -325 \n",
       "Q 1816 -950 1584 -1140 \n",
       "Q 1353 -1331 966 -1331 \n",
       "L 506 -1331 \n",
       "L 506 -850 \n",
       "L 844 -850 \n",
       "Q 1081 -850 1212 -737 \n",
       "Q 1344 -625 1503 -206 \n",
       "L 1606 56 \n",
       "L 191 3500 \n",
       "L 800 3500 \n",
       "L 1894 763 \n",
       "L 2988 3500 \n",
       "L 3597 3500 \n",
       "L 2059 -325 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-64\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(63.476562 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" transform=\"translate(125 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" transform=\"translate(188.378906 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" transform=\"translate(240.478516 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(268.261719 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-79\" transform=\"translate(307.470703 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_19\">\n",
       "    <path d=\"M 79.916477 300.245455 \n",
       "L 215.620568 300.134884 \n",
       "L 222.557614 299.889061 \n",
       "L 227.112841 299.516162 \n",
       "L 230.626023 299.014076 \n",
       "L 233.54375 298.37842 \n",
       "L 236.074432 297.603473 \n",
       "L 238.337159 296.680788 \n",
       "L 240.42125 295.590746 \n",
       "L 242.356477 294.328449 \n",
       "L 244.202386 292.858557 \n",
       "L 245.98875 291.148669 \n",
       "L 247.715568 289.187937 \n",
       "L 249.442386 286.88473 \n",
       "L 251.139432 284.247844 \n",
       "L 252.86625 281.143503 \n",
       "L 254.593068 277.572763 \n",
       "L 256.349659 273.42002 \n",
       "L 258.136023 268.617422 \n",
       "L 259.981932 263.000988 \n",
       "L 261.887386 256.470237 \n",
       "L 263.852386 248.926791 \n",
       "L 265.906705 240.146777 \n",
       "L 268.109886 229.721009 \n",
       "L 270.461932 217.481234 \n",
       "L 273.052159 202.789436 \n",
       "L 276.088977 184.216025 \n",
       "L 280.286932 157.004354 \n",
       "L 286.360568 117.738067 \n",
       "L 289.099659 101.536817 \n",
       "L 291.302841 89.778323 \n",
       "L 293.178523 80.910155 \n",
       "L 294.845795 74.05793 \n",
       "L 296.334432 68.851862 \n",
       "L 297.644432 65.037804 \n",
       "L 298.835341 62.227885 \n",
       "L 299.877386 60.302195 \n",
       "L 300.830114 58.988146 \n",
       "L 301.66375 58.194176 \n",
       "L 302.408068 57.768812 \n",
       "L 303.122614 57.613516 \n",
       "L 303.807386 57.697762 \n",
       "L 304.492159 58.009888 \n",
       "L 305.236477 58.606574 \n",
       "L 306.040341 59.549905 \n",
       "L 306.933523 60.957706 \n",
       "L 307.916023 62.935704 \n",
       "L 309.017614 65.674636 \n",
       "L 310.238295 69.330048 \n",
       "L 311.607841 74.169043 \n",
       "L 313.12625 80.384349 \n",
       "L 314.853068 88.438703 \n",
       "L 316.818068 98.716674 \n",
       "L 319.140341 112.109238 \n",
       "L 322.087841 130.496464 \n",
       "L 328.161477 170.24566 \n",
       "L 332.12125 195.252419 \n",
       "L 335.06875 212.48474 \n",
       "L 337.629205 226.180584 \n",
       "L 339.98125 237.581732 \n",
       "L 342.184432 247.178714 \n",
       "L 344.268523 255.278733 \n",
       "L 346.263295 262.151655 \n",
       "L 348.16875 267.938246 \n",
       "L 350.014659 272.851618 \n",
       "L 351.801023 276.994397 \n",
       "L 353.557614 280.519464 \n",
       "L 355.284432 283.493043 \n",
       "L 356.981477 285.977736 \n",
       "L 358.64875 288.031512 \n",
       "L 360.316023 289.734654 \n",
       "L 361.953523 291.096343 \n",
       "L 363.620795 292.194643 \n",
       "L 365.288068 293.028349 \n",
       "L 366.985114 293.629365 \n",
       "L 368.711932 294.006464 \n",
       "L 370.498295 294.167716 \n",
       "L 372.344205 294.10763 \n",
       "L 374.249659 293.818893 \n",
       "L 376.214659 293.291478 \n",
       "L 378.209432 292.524985 \n",
       "L 380.26375 291.49546 \n",
       "L 382.347841 290.200932 \n",
       "L 384.461705 288.62557 \n",
       "L 386.605341 286.749773 \n",
       "L 388.77875 284.550741 \n",
       "L 390.981932 282.003252 \n",
       "L 393.244659 279.039295 \n",
       "L 395.537159 275.66345 \n",
       "L 397.889205 271.79786 \n",
       "L 400.330568 267.346124 \n",
       "L 402.86125 262.256454 \n",
       "L 405.511023 256.416093 \n",
       "L 408.339432 249.628235 \n",
       "L 411.406023 241.673636 \n",
       "L 414.889432 231.993145 \n",
       "L 419.23625 219.209071 \n",
       "L 430.490341 185.767038 \n",
       "L 433.556932 177.543694 \n",
       "L 436.147159 171.210136 \n",
       "L 438.409886 166.242997 \n",
       "L 440.434432 162.313824 \n",
       "L 442.280341 159.200576 \n",
       "L 443.977386 156.76388 \n",
       "L 445.525568 154.916675 \n",
       "L 446.954659 153.54297 \n",
       "L 448.294432 152.552702 \n",
       "L 449.544886 151.893708 \n",
       "L 450.735795 151.507492 \n",
       "L 451.896932 151.359498 \n",
       "L 453.058068 151.437866 \n",
       "L 454.219205 151.742238 \n",
       "L 455.410114 152.287725 \n",
       "L 456.660568 153.111913 \n",
       "L 457.970568 154.246915 \n",
       "L 459.369886 155.758948 \n",
       "L 460.888295 157.738526 \n",
       "L 462.525795 160.251657 \n",
       "L 464.312159 163.415613 \n",
       "L 466.277159 167.367095 \n",
       "L 468.450568 172.255905 \n",
       "L 470.891932 178.310637 \n",
       "L 473.750114 186.016293 \n",
       "L 477.352614 196.410972 \n",
       "L 483.783523 215.801663 \n",
       "L 489.231932 231.908778 \n",
       "L 492.953523 242.234369 \n",
       "L 496.168977 250.519943 \n",
       "L 499.086705 257.443742 \n",
       "L 501.825795 263.387254 \n",
       "L 504.445795 268.550481 \n",
       "L 506.946705 273.000343 \n",
       "L 509.388068 276.900378 \n",
       "L 511.769886 280.296313 \n",
       "L 514.121932 283.271661 \n",
       "L 516.473977 285.893098 \n",
       "L 518.826023 288.185184 \n",
       "L 521.207841 290.197625 \n",
       "L 523.619432 291.947624 \n",
       "L 526.120341 293.488217 \n",
       "L 528.710568 294.823477 \n",
       "L 531.449659 295.984809 \n",
       "L 534.397159 296.989172 \n",
       "L 537.582841 297.836949 \n",
       "L 541.125795 298.546254 \n",
       "L 545.174886 299.124552 \n",
       "L 549.968295 299.576657 \n",
       "L 555.952614 299.906999 \n",
       "L 564.140114 300.120605 \n",
       "L 577.835568 300.225572 \n",
       "L 624.340568 300.245447 \n",
       "L 675.371023 300.245455 \n",
       "L 675.371023 300.245455 \n",
       "\" clip-path=\"url(#p732411b6bd)\" style=\"fill: none; stroke: #ff0000; stroke-width: 3; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_20\">\n",
       "    <path d=\"M 79.916477 300.245455 \n",
       "L 178.404659 300.134884 \n",
       "L 185.341705 299.889061 \n",
       "L 189.896932 299.516162 \n",
       "L 193.410114 299.014076 \n",
       "L 196.327841 298.37842 \n",
       "L 198.858523 297.603473 \n",
       "L 201.12125 296.680788 \n",
       "L 203.205341 295.590746 \n",
       "L 205.140568 294.328449 \n",
       "L 206.986477 292.858557 \n",
       "L 208.772841 291.148669 \n",
       "L 210.499659 289.187937 \n",
       "L 212.226477 286.88473 \n",
       "L 213.923523 284.247844 \n",
       "L 215.650341 281.143503 \n",
       "L 217.377159 277.572763 \n",
       "L 219.13375 273.42002 \n",
       "L 220.920114 268.617422 \n",
       "L 222.766023 263.000988 \n",
       "L 224.671477 256.470237 \n",
       "L 226.636477 248.926791 \n",
       "L 228.690795 240.146777 \n",
       "L 230.893977 229.721009 \n",
       "L 233.246023 217.481234 \n",
       "L 235.83625 202.789436 \n",
       "L 238.873068 184.216025 \n",
       "L 243.071023 157.004354 \n",
       "L 249.144659 117.738067 \n",
       "L 251.88375 101.536817 \n",
       "L 254.086932 89.778323 \n",
       "L 255.962614 80.910155 \n",
       "L 257.629886 74.05793 \n",
       "L 259.118523 68.851862 \n",
       "L 260.428523 65.037804 \n",
       "L 261.619432 62.227885 \n",
       "L 262.661477 60.302195 \n",
       "L 263.614205 58.988146 \n",
       "L 264.447841 58.194176 \n",
       "L 265.192159 57.768812 \n",
       "L 265.906705 57.613516 \n",
       "L 266.591477 57.697762 \n",
       "L 267.27625 58.009888 \n",
       "L 268.020568 58.606574 \n",
       "L 268.824432 59.549905 \n",
       "L 269.717614 60.957706 \n",
       "L 270.700114 62.935704 \n",
       "L 271.801705 65.674636 \n",
       "L 273.022386 69.330048 \n",
       "L 274.391932 74.169043 \n",
       "L 275.910341 80.384349 \n",
       "L 277.637159 88.438703 \n",
       "L 279.602159 98.716674 \n",
       "L 281.924432 112.109238 \n",
       "L 284.871932 130.496464 \n",
       "L 290.945568 170.24566 \n",
       "L 294.905341 195.252419 \n",
       "L 297.852841 212.48474 \n",
       "L 300.413295 226.180584 \n",
       "L 302.765341 237.581732 \n",
       "L 304.968523 247.178714 \n",
       "L 307.052614 255.278733 \n",
       "L 309.047386 262.151655 \n",
       "L 310.952841 267.938246 \n",
       "L 312.79875 272.851618 \n",
       "L 314.585114 276.994397 \n",
       "L 316.341705 280.519464 \n",
       "L 318.068523 283.493043 \n",
       "L 319.765568 285.977736 \n",
       "L 321.432841 288.031512 \n",
       "L 323.100114 289.734654 \n",
       "L 324.737614 291.096343 \n",
       "L 326.404886 292.194643 \n",
       "L 328.072159 293.028349 \n",
       "L 329.769205 293.629365 \n",
       "L 331.496023 294.006464 \n",
       "L 333.282386 294.167716 \n",
       "L 335.128295 294.10763 \n",
       "L 337.03375 293.818893 \n",
       "L 338.99875 293.291478 \n",
       "L 340.993523 292.524985 \n",
       "L 343.047841 291.49546 \n",
       "L 345.131932 290.200932 \n",
       "L 347.245795 288.62557 \n",
       "L 349.389432 286.749773 \n",
       "L 351.562841 284.550741 \n",
       "L 353.766023 282.003252 \n",
       "L 356.02875 279.039295 \n",
       "L 358.32125 275.66345 \n",
       "L 360.673295 271.79786 \n",
       "L 363.114659 267.346124 \n",
       "L 365.645341 262.256454 \n",
       "L 368.295114 256.416093 \n",
       "L 371.123523 249.628235 \n",
       "L 374.190114 241.673636 \n",
       "L 377.673523 231.993145 \n",
       "L 382.020341 219.209071 \n",
       "L 393.274432 185.767038 \n",
       "L 396.341023 177.543694 \n",
       "L 398.93125 171.210136 \n",
       "L 401.193977 166.242997 \n",
       "L 403.218523 162.313824 \n",
       "L 405.064432 159.200576 \n",
       "L 406.761477 156.76388 \n",
       "L 408.309659 154.916675 \n",
       "L 409.73875 153.54297 \n",
       "L 411.078523 152.552702 \n",
       "L 412.328977 151.893708 \n",
       "L 413.519886 151.507492 \n",
       "L 414.681023 151.359498 \n",
       "L 415.842159 151.437866 \n",
       "L 417.003295 151.742238 \n",
       "L 418.194205 152.287725 \n",
       "L 419.444659 153.111913 \n",
       "L 420.754659 154.246915 \n",
       "L 422.153977 155.758948 \n",
       "L 423.672386 157.738526 \n",
       "L 425.309886 160.251657 \n",
       "L 427.09625 163.415613 \n",
       "L 429.06125 167.367095 \n",
       "L 431.234659 172.255905 \n",
       "L 433.676023 178.310637 \n",
       "L 436.534205 186.016293 \n",
       "L 440.136705 196.410972 \n",
       "L 446.567614 215.801663 \n",
       "L 452.016023 231.908778 \n",
       "L 455.737614 242.234369 \n",
       "L 458.953068 250.519943 \n",
       "L 461.870795 257.443742 \n",
       "L 464.609886 263.387254 \n",
       "L 467.229886 268.550481 \n",
       "L 469.730795 273.000343 \n",
       "L 472.172159 276.900378 \n",
       "L 474.553977 280.296313 \n",
       "L 476.906023 283.271661 \n",
       "L 479.258068 285.893098 \n",
       "L 481.610114 288.185184 \n",
       "L 483.991932 290.197625 \n",
       "L 486.403523 291.947624 \n",
       "L 488.904432 293.488217 \n",
       "L 491.494659 294.823477 \n",
       "L 494.23375 295.984809 \n",
       "L 497.18125 296.989172 \n",
       "L 500.366932 297.836949 \n",
       "L 503.909886 298.546254 \n",
       "L 507.958977 299.124552 \n",
       "L 512.752386 299.576657 \n",
       "L 518.736705 299.906999 \n",
       "L 526.924205 300.120605 \n",
       "L 540.619659 300.225572 \n",
       "L 587.124659 300.245447 \n",
       "L 675.371023 300.245455 \n",
       "L 675.371023 300.245455 \n",
       "\" clip-path=\"url(#p732411b6bd)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #1f77b4; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_21\">\n",
       "    <path d=\"M 79.916477 300.245455 \n",
       "L 221.604886 300.134468 \n",
       "L 229.107614 299.887312 \n",
       "L 234.139205 299.507893 \n",
       "L 238.039432 298.998576 \n",
       "L 241.314432 298.352841 \n",
       "L 244.202386 297.55931 \n",
       "L 246.792614 296.620186 \n",
       "L 249.204205 295.51048 \n",
       "L 251.466932 294.22638 \n",
       "L 253.640341 292.739096 \n",
       "L 255.783977 290.998794 \n",
       "L 257.897841 288.989992 \n",
       "L 260.011705 286.667019 \n",
       "L 262.125568 284.010761 \n",
       "L 264.298977 280.91838 \n",
       "L 266.561705 277.3036 \n",
       "L 268.943523 273.069036 \n",
       "L 271.503977 268.052406 \n",
       "L 274.391932 261.884491 \n",
       "L 277.905114 253.825544 \n",
       "L 288.146932 229.974124 \n",
       "L 290.618068 224.988831 \n",
       "L 292.702159 221.265907 \n",
       "L 294.518295 218.454804 \n",
       "L 296.155795 216.311858 \n",
       "L 297.644432 214.715097 \n",
       "L 299.013977 213.560179 \n",
       "L 300.294205 212.764556 \n",
       "L 301.485114 212.277849 \n",
       "L 302.64625 212.042562 \n",
       "L 303.777614 212.042375 \n",
       "L 304.908977 212.268283 \n",
       "L 306.070114 212.733395 \n",
       "L 307.261023 213.451948 \n",
       "L 308.54125 214.490206 \n",
       "L 309.910795 215.894545 \n",
       "L 311.399432 217.747476 \n",
       "L 313.036932 220.150633 \n",
       "L 314.882841 223.27324 \n",
       "L 316.966932 227.253819 \n",
       "L 319.438068 232.47545 \n",
       "L 322.653523 239.828747 \n",
       "L 333.163295 264.267943 \n",
       "L 336.021477 270.134125 \n",
       "L 338.581932 274.896198 \n",
       "L 340.933977 278.816795 \n",
       "L 343.166932 282.118394 \n",
       "L 345.310568 284.89842 \n",
       "L 347.364886 287.208739 \n",
       "L 349.389432 289.155934 \n",
       "L 351.354432 290.744734 \n",
       "L 353.319432 292.050231 \n",
       "L 355.254659 293.072519 \n",
       "L 357.189886 293.84634 \n",
       "L 359.125114 294.383398 \n",
       "L 361.090114 294.696571 \n",
       "L 363.055114 294.783517 \n",
       "L 365.020114 294.648949 \n",
       "L 367.014886 294.287172 \n",
       "L 369.009659 293.696258 \n",
       "L 371.004432 292.870139 \n",
       "L 372.999205 291.799003 \n",
       "L 374.964205 290.491281 \n",
       "L 376.929205 288.916871 \n",
       "L 378.894205 287.057037 \n",
       "L 380.859205 284.890656 \n",
       "L 382.853977 282.354229 \n",
       "L 384.84875 279.452656 \n",
       "L 386.873295 276.107407 \n",
       "L 388.927614 272.272572 \n",
       "L 391.011705 267.900394 \n",
       "L 393.125568 262.942373 \n",
       "L 395.298977 257.268908 \n",
       "L 397.531932 250.808949 \n",
       "L 399.854205 243.394238 \n",
       "L 402.265795 234.933812 \n",
       "L 404.796477 225.227426 \n",
       "L 407.476023 214.053259 \n",
       "L 410.39375 200.903143 \n",
       "L 413.638977 185.211653 \n",
       "L 417.509432 165.336033 \n",
       "L 423.731932 132.002177 \n",
       "L 429.150568 103.460246 \n",
       "L 432.455341 87.217737 \n",
       "L 435.134886 75.114495 \n",
       "L 437.457159 65.61253 \n",
       "L 439.511477 58.104317 \n",
       "L 441.357386 52.162604 \n",
       "L 443.024659 47.507104 \n",
       "L 444.543068 43.89172 \n",
       "L 445.942386 41.111594 \n",
       "L 447.222614 39.047579 \n",
       "L 448.38375 37.581687 \n",
       "L 449.455568 36.577447 \n",
       "L 450.438068 35.954588 \n",
       "L 451.361023 35.630765 \n",
       "L 452.224432 35.557854 \n",
       "L 453.087841 35.707493 \n",
       "L 453.981023 36.096078 \n",
       "L 454.903977 36.746272 \n",
       "L 455.886477 37.714036 \n",
       "L 456.958295 39.090281 \n",
       "L 458.119432 40.952567 \n",
       "L 459.399659 43.443607 \n",
       "L 460.798977 46.675874 \n",
       "L 462.317386 50.76146 \n",
       "L 463.984659 55.90495 \n",
       "L 465.830568 62.347751 \n",
       "L 467.884886 70.359746 \n",
       "L 470.207159 80.356589 \n",
       "L 472.886705 92.925709 \n",
       "L 476.131932 109.272701 \n",
       "L 480.80625 134.085607 \n",
       "L 488.874659 176.93382 \n",
       "L 492.59625 195.408926 \n",
       "L 495.781932 210.133687 \n",
       "L 498.669886 222.460326 \n",
       "L 501.349432 232.952855 \n",
       "L 503.909886 242.095665 \n",
       "L 506.35125 250.001096 \n",
       "L 508.703295 256.875767 \n",
       "L 510.966023 262.821134 \n",
       "L 513.198977 268.071468 \n",
       "L 515.372386 272.623117 \n",
       "L 517.516023 276.604968 \n",
       "L 519.629886 280.071704 \n",
       "L 521.74375 283.116629 \n",
       "L 523.857614 285.775097 \n",
       "L 525.971477 288.082428 \n",
       "L 528.115114 290.099199 \n",
       "L 530.318295 291.869452 \n",
       "L 532.581023 293.40568 \n",
       "L 534.962841 294.753772 \n",
       "L 537.46375 295.914228 \n",
       "L 540.173068 296.922939 \n",
       "L 543.120568 297.778756 \n",
       "L 546.395568 298.493993 \n",
       "L 550.146932 299.079728 \n",
       "L 554.583068 299.539752 \n",
       "L 560.120795 299.87987 \n",
       "L 567.653295 300.104088 \n",
       "L 579.949432 300.219332 \n",
       "L 616.421023 300.245391 \n",
       "L 675.371023 300.245455 \n",
       "L 675.371023 300.245455 \n",
       "\" clip-path=\"url(#p732411b6bd)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_22\">\n",
       "    <path d=\"M 79.916477 300.245455 \n",
       "L 205.468068 300.134437 \n",
       "L 213.030341 299.889114 \n",
       "L 218.032159 299.515096 \n",
       "L 221.902614 299.009602 \n",
       "L 225.118068 298.369228 \n",
       "L 227.886932 297.595297 \n",
       "L 230.358068 296.678269 \n",
       "L 232.620795 295.605425 \n",
       "L 234.734659 294.360137 \n",
       "L 236.759205 292.907968 \n",
       "L 238.694432 291.245183 \n",
       "L 240.570114 289.341553 \n",
       "L 242.416023 287.152538 \n",
       "L 244.261932 284.615346 \n",
       "L 246.107841 281.69482 \n",
       "L 247.983523 278.298961 \n",
       "L 249.859205 274.437092 \n",
       "L 251.794432 269.930718 \n",
       "L 253.759432 264.78221 \n",
       "L 255.783977 258.848319 \n",
       "L 257.897841 251.952896 \n",
       "L 260.130795 243.887153 \n",
       "L 262.482841 234.538512 \n",
       "L 265.043295 223.42037 \n",
       "L 267.901477 209.97573 \n",
       "L 271.295568 192.886358 \n",
       "L 277.10125 162.26549 \n",
       "L 281.448068 139.908755 \n",
       "L 284.276477 126.490309 \n",
       "L 286.568977 116.645532 \n",
       "L 288.533977 109.13538 \n",
       "L 290.290568 103.265442 \n",
       "L 291.83875 98.825116 \n",
       "L 293.238068 95.448696 \n",
       "L 294.518295 92.918668 \n",
       "L 295.649659 91.144863 \n",
       "L 296.691705 89.905105 \n",
       "L 297.644432 89.108316 \n",
       "L 298.507841 88.667288 \n",
       "L 299.311705 88.498476 \n",
       "L 300.085795 88.55684 \n",
       "L 300.889659 88.846677 \n",
       "L 301.723295 89.392909 \n",
       "L 302.616477 90.253514 \n",
       "L 303.598977 91.525038 \n",
       "L 304.670795 93.293093 \n",
       "L 305.861705 95.711513 \n",
       "L 307.171705 98.903554 \n",
       "L 308.600795 102.98984 \n",
       "L 310.208523 108.29031 \n",
       "L 311.994886 114.975115 \n",
       "L 314.019432 123.439614 \n",
       "L 316.40125 134.397926 \n",
       "L 319.34875 149.065767 \n",
       "L 324.052841 173.784232 \n",
       "L 329.650114 202.899973 \n",
       "L 332.925114 218.764169 \n",
       "L 335.72375 231.260875 \n",
       "L 338.254432 241.57802 \n",
       "L 340.606477 250.265535 \n",
       "L 342.839432 257.68637 \n",
       "L 344.983068 264.053664 \n",
       "L 347.037386 269.475733 \n",
       "L 349.032159 274.128347 \n",
       "L 350.967386 278.094854 \n",
       "L 352.872841 281.5059 \n",
       "L 354.748523 284.417717 \n",
       "L 356.594432 286.884356 \n",
       "L 358.440341 288.987766 \n",
       "L 360.28625 290.759554 \n",
       "L 362.132159 292.2298 \n",
       "L 364.007841 293.443636 \n",
       "L 365.913295 294.414729 \n",
       "L 367.878295 295.165212 \n",
       "L 369.873068 295.689373 \n",
       "L 371.927386 295.998757 \n",
       "L 374.011477 296.089369 \n",
       "L 376.155114 295.958977 \n",
       "L 378.328523 295.600772 \n",
       "L 380.501932 295.014605 \n",
       "L 382.645568 294.207287 \n",
       "L 384.789205 293.161657 \n",
       "L 386.903068 291.882655 \n",
       "L 389.016932 290.339731 \n",
       "L 391.101023 288.540359 \n",
       "L 393.185114 286.44342 \n",
       "L 395.269205 284.026692 \n",
       "L 397.353295 281.267875 \n",
       "L 399.467159 278.09818 \n",
       "L 401.610795 274.48095 \n",
       "L 403.813977 270.321588 \n",
       "L 406.076705 265.568578 \n",
       "L 408.42875 260.101727 \n",
       "L 410.899886 253.780477 \n",
       "L 413.519886 246.447955 \n",
       "L 416.348295 237.84646 \n",
       "L 419.474432 227.602624 \n",
       "L 423.196023 214.604052 \n",
       "L 429.091023 193.061807 \n",
       "L 434.420341 173.902499 \n",
       "L 437.606023 163.256867 \n",
       "L 440.19625 155.341304 \n",
       "L 442.429205 149.199046 \n",
       "L 444.423977 144.338226 \n",
       "L 446.210341 140.546422 \n",
       "L 447.847841 137.576017 \n",
       "L 449.336477 135.321043 \n",
       "L 450.706023 133.637948 \n",
       "L 451.956477 132.439415 \n",
       "L 453.117614 131.622082 \n",
       "L 454.219205 131.113762 \n",
       "L 455.26125 130.874494 \n",
       "L 456.273523 130.867942 \n",
       "L 457.285795 131.084029 \n",
       "L 458.327841 131.538124 \n",
       "L 459.429432 132.271603 \n",
       "L 460.590568 133.322978 \n",
       "L 461.841023 134.768437 \n",
       "L 463.180795 136.667981 \n",
       "L 464.639659 139.134298 \n",
       "L 466.247386 142.309756 \n",
       "L 468.003977 146.29275 \n",
       "L 469.939205 151.249358 \n",
       "L 472.112614 157.446739 \n",
       "L 474.613523 165.276095 \n",
       "L 477.620568 175.457252 \n",
       "L 481.758977 190.33108 \n",
       "L 491.048068 223.937639 \n",
       "L 494.56125 235.666218 \n",
       "L 497.598068 245.050432 \n",
       "L 500.366932 252.903801 \n",
       "L 502.957159 259.599408 \n",
       "L 505.428295 265.383483 \n",
       "L 507.810114 270.400325 \n",
       "L 510.102614 274.722047 \n",
       "L 512.335568 278.470771 \n",
       "L 514.53875 281.745923 \n",
       "L 516.741932 284.626077 \n",
       "L 518.915341 287.108077 \n",
       "L 521.118523 289.289845 \n",
       "L 523.351477 291.189429 \n",
       "L 525.643977 292.846988 \n",
       "L 527.996023 294.274819 \n",
       "L 530.467159 295.515441 \n",
       "L 533.087159 296.581985 \n",
       "L 535.915568 297.492492 \n",
       "L 539.041705 298.26184 \n",
       "L 542.554886 298.893414 \n",
       "L 546.663523 299.399048 \n",
       "L 551.665341 299.780675 \n",
       "L 558.215341 300.043503 \n",
       "L 568.040341 300.193287 \n",
       "L 589.566023 300.243711 \n",
       "L 675.371023 300.245455 \n",
       "L 675.371023 300.245455 \n",
       "\" clip-path=\"url(#p732411b6bd)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 50.14375 313.48 \n",
       "L 50.14375 22.32 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 705.14375 313.48 \n",
       "L 705.14375 22.32 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 50.14375 313.48 \n",
       "L 705.14375 313.48 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 50.14375 22.32 \n",
       "L 705.14375 22.32 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_21\">\n",
       "    <!-- Two-peaked $p_{\\mathrm{data}}$ vs. candidate $p_{\\theta}$ distributions -->\n",
       "    <g transform=\"translate(235.86375 16.32) scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path id=\"DejaVuSans-54\" d=\"M -19 4666 \n",
       "L 3928 4666 \n",
       "L 3928 4134 \n",
       "L 2272 4134 \n",
       "L 2272 0 \n",
       "L 1638 0 \n",
       "L 1638 4134 \n",
       "L -19 4134 \n",
       "L -19 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-77\" d=\"M 269 3500 \n",
       "L 844 3500 \n",
       "L 1563 769 \n",
       "L 2278 3500 \n",
       "L 2956 3500 \n",
       "L 3675 769 \n",
       "L 4391 3500 \n",
       "L 4966 3500 \n",
       "L 4050 0 \n",
       "L 3372 0 \n",
       "L 2619 2869 \n",
       "L 1863 0 \n",
       "L 1184 0 \n",
       "L 269 3500 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \n",
       "Q 1497 3097 1228 2736 \n",
       "Q 959 2375 959 1747 \n",
       "Q 959 1119 1226 758 \n",
       "Q 1494 397 1959 397 \n",
       "Q 2419 397 2687 759 \n",
       "Q 2956 1122 2956 1747 \n",
       "Q 2956 2369 2687 2733 \n",
       "Q 2419 3097 1959 3097 \n",
       "z\n",
       "M 1959 3584 \n",
       "Q 2709 3584 3137 3096 \n",
       "Q 3566 2609 3566 1747 \n",
       "Q 3566 888 3137 398 \n",
       "Q 2709 -91 1959 -91 \n",
       "Q 1206 -91 779 398 \n",
       "Q 353 888 353 1747 \n",
       "Q 353 2609 779 3096 \n",
       "Q 1206 3584 1959 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-2d\" d=\"M 313 2009 \n",
       "L 1997 2009 \n",
       "L 1997 1497 \n",
       "L 313 1497 \n",
       "L 313 2009 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-70\" d=\"M 1159 525 \n",
       "L 1159 -1331 \n",
       "L 581 -1331 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2969 \n",
       "Q 1341 3281 1617 3432 \n",
       "Q 1894 3584 2278 3584 \n",
       "Q 2916 3584 3314 3078 \n",
       "Q 3713 2572 3713 1747 \n",
       "Q 3713 922 3314 415 \n",
       "Q 2916 -91 2278 -91 \n",
       "Q 1894 -91 1617 61 \n",
       "Q 1341 213 1159 525 \n",
       "z\n",
       "M 3116 1747 \n",
       "Q 3116 2381 2855 2742 \n",
       "Q 2594 3103 2138 3103 \n",
       "Q 1681 3103 1420 2742 \n",
       "Q 1159 2381 1159 1747 \n",
       "Q 1159 1113 1420 752 \n",
       "Q 1681 391 2138 391 \n",
       "Q 2594 391 2855 752 \n",
       "Q 3116 1113 3116 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \n",
       "Q 1497 1759 1228 1600 \n",
       "Q 959 1441 959 1056 \n",
       "Q 959 750 1161 570 \n",
       "Q 1363 391 1709 391 \n",
       "Q 2188 391 2477 730 \n",
       "Q 2766 1069 2766 1631 \n",
       "L 2766 1759 \n",
       "L 2194 1759 \n",
       "z\n",
       "M 3341 1997 \n",
       "L 3341 0 \n",
       "L 2766 0 \n",
       "L 2766 531 \n",
       "Q 2569 213 2275 61 \n",
       "Q 1981 -91 1556 -91 \n",
       "Q 1019 -91 701 211 \n",
       "Q 384 513 384 1019 \n",
       "Q 384 1609 779 1909 \n",
       "Q 1175 2209 1959 2209 \n",
       "L 2766 2209 \n",
       "L 2766 2266 \n",
       "Q 2766 2663 2505 2880 \n",
       "Q 2244 3097 1772 3097 \n",
       "Q 1472 3097 1187 3025 \n",
       "Q 903 2953 641 2809 \n",
       "L 641 3341 \n",
       "Q 956 3463 1253 3523 \n",
       "Q 1550 3584 1831 3584 \n",
       "Q 2591 3584 2966 3190 \n",
       "Q 3341 2797 3341 1997 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-6b\" d=\"M 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 1991 \n",
       "L 2875 3500 \n",
       "L 3609 3500 \n",
       "L 1753 1863 \n",
       "L 3688 0 \n",
       "L 2938 0 \n",
       "L 1159 1709 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-Oblique-70\" d=\"M 3175 2156 \n",
       "Q 3175 2616 2975 2859 \n",
       "Q 2775 3103 2400 3103 \n",
       "Q 2144 3103 1911 2972 \n",
       "Q 1678 2841 1497 2591 \n",
       "Q 1319 2344 1212 1994 \n",
       "Q 1106 1644 1106 1300 \n",
       "Q 1106 863 1306 627 \n",
       "Q 1506 391 1875 391 \n",
       "Q 2147 391 2380 519 \n",
       "Q 2613 647 2778 891 \n",
       "Q 2956 1147 3065 1494 \n",
       "Q 3175 1841 3175 2156 \n",
       "z\n",
       "M 1394 2969 \n",
       "Q 1625 3272 1939 3428 \n",
       "Q 2253 3584 2638 3584 \n",
       "Q 3175 3584 3472 3232 \n",
       "Q 3769 2881 3769 2247 \n",
       "Q 3769 1728 3584 1258 \n",
       "Q 3400 788 3053 416 \n",
       "Q 2822 169 2531 39 \n",
       "Q 2241 -91 1919 -91 \n",
       "Q 1547 -91 1294 64 \n",
       "Q 1041 219 916 525 \n",
       "L 556 -1331 \n",
       "L -19 -1331 \n",
       "L 922 3500 \n",
       "L 1497 3500 \n",
       "L 1394 2969 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-76\" d=\"M 191 3500 \n",
       "L 800 3500 \n",
       "L 1894 563 \n",
       "L 2988 3500 \n",
       "L 3597 3500 \n",
       "L 2284 0 \n",
       "L 1503 0 \n",
       "L 191 3500 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \n",
       "L 3122 2828 \n",
       "Q 2878 2963 2633 3030 \n",
       "Q 2388 3097 2138 3097 \n",
       "Q 1578 3097 1268 2742 \n",
       "Q 959 2388 959 1747 \n",
       "Q 959 1106 1268 751 \n",
       "Q 1578 397 2138 397 \n",
       "Q 2388 397 2633 464 \n",
       "Q 2878 531 3122 666 \n",
       "L 3122 134 \n",
       "Q 2881 22 2623 -34 \n",
       "Q 2366 -91 2075 -91 \n",
       "Q 1284 -91 818 406 \n",
       "Q 353 903 353 1747 \n",
       "Q 353 2603 823 3093 \n",
       "Q 1294 3584 2113 3584 \n",
       "Q 2378 3584 2631 3529 \n",
       "Q 2884 3475 3122 3366 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-Oblique-3b8\" d=\"M 2913 2219 \n",
       "L 925 2219 \n",
       "Q 791 1284 928 888 \n",
       "Q 1100 400 1566 400 \n",
       "Q 2034 400 2391 891 \n",
       "Q 2703 1322 2913 2219 \n",
       "z\n",
       "M 3009 2750 \n",
       "Q 3094 3638 2984 3950 \n",
       "Q 2813 4444 2353 4444 \n",
       "Q 1875 4444 1525 3956 \n",
       "Q 1250 3563 1034 2750 \n",
       "L 3009 2750 \n",
       "z\n",
       "M 2444 4913 \n",
       "Q 3194 4913 3494 4250 \n",
       "Q 3794 3591 3566 2422 \n",
       "Q 3341 1256 2781 594 \n",
       "Q 2225 -72 1475 -72 \n",
       "Q 722 -72 425 594 \n",
       "Q 128 1256 353 2422 \n",
       "Q 581 3591 1134 4250 \n",
       "Q 1691 4913 2444 4913 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \n",
       "Q 2534 3019 2420 3045 \n",
       "Q 2306 3072 2169 3072 \n",
       "Q 1681 3072 1420 2755 \n",
       "Q 1159 2438 1159 1844 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1341 3275 1631 3429 \n",
       "Q 1922 3584 2338 3584 \n",
       "Q 2397 3584 2469 3576 \n",
       "Q 2541 3569 2628 3553 \n",
       "L 2631 2963 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-62\" d=\"M 3116 1747 \n",
       "Q 3116 2381 2855 2742 \n",
       "Q 2594 3103 2138 3103 \n",
       "Q 1681 3103 1420 2742 \n",
       "Q 1159 2381 1159 1747 \n",
       "Q 1159 1113 1420 752 \n",
       "Q 1681 391 2138 391 \n",
       "Q 2594 391 2855 752 \n",
       "Q 3116 1113 3116 1747 \n",
       "z\n",
       "M 1159 2969 \n",
       "Q 1341 3281 1617 3432 \n",
       "Q 1894 3584 2278 3584 \n",
       "Q 2916 3584 3314 3078 \n",
       "Q 3713 2572 3713 1747 \n",
       "Q 3713 922 3314 415 \n",
       "Q 2916 -91 2278 -91 \n",
       "Q 1894 -91 1617 61 \n",
       "Q 1341 213 1159 525 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 2969 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-75\" d=\"M 544 1381 \n",
       "L 544 3500 \n",
       "L 1119 3500 \n",
       "L 1119 1403 \n",
       "Q 1119 906 1312 657 \n",
       "Q 1506 409 1894 409 \n",
       "Q 2359 409 2629 706 \n",
       "Q 2900 1003 2900 1516 \n",
       "L 2900 3500 \n",
       "L 3475 3500 \n",
       "L 3475 0 \n",
       "L 2900 0 \n",
       "L 2900 538 \n",
       "Q 2691 219 2414 64 \n",
       "Q 2138 -91 1772 -91 \n",
       "Q 1169 -91 856 284 \n",
       "Q 544 659 544 1381 \n",
       "z\n",
       "M 1991 3584 \n",
       "L 1991 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-54\" transform=\"translate(0 0.015625)\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-77\" transform=\"translate(61.083984 0.015625)\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(142.871094 0.015625)\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-2d\" transform=\"translate(204.052734 0.015625)\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-70\" transform=\"translate(240.136719 0.015625)\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(303.613281 0.015625)\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(365.136719 0.015625)\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6b\" transform=\"translate(426.416016 0.015625)\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(484.326172 0.015625)\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-64\" transform=\"translate(545.849609 0.015625)\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(609.326172 0.015625)\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-Oblique-70\" transform=\"translate(641.113281 0.015625)\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-64\" transform=\"translate(704.589844 -16.390625) scale(0.7)\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(749.023438 -16.390625) scale(0.7)\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(791.918945 -16.390625) scale(0.7)\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(819.365234 -16.390625) scale(0.7)\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(864.995117 0.015625)\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-76\" transform=\"translate(896.782227 0.015625)\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-73\" transform=\"translate(955.961914 0.015625)\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(1008.061523 0.015625)\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(1039.848633 0.015625)\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-63\" transform=\"translate(1071.635742 0.015625)\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(1126.616211 0.015625)\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6e\" transform=\"translate(1187.895508 0.015625)\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-64\" transform=\"translate(1251.274414 0.015625)\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-69\" transform=\"translate(1314.750977 0.015625)\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-64\" transform=\"translate(1342.53418 0.015625)\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(1406.010742 0.015625)\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(1467.290039 0.015625)\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(1506.499023 0.015625)\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(1568.022461 0.015625)\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-Oblique-70\" transform=\"translate(1599.80957 0.015625)\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-Oblique-3b8\" transform=\"translate(1663.286133 -16.390625) scale(0.7)\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(1708.847656 0.015625)\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-64\" transform=\"translate(1740.634766 0.015625)\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-69\" transform=\"translate(1804.111328 0.015625)\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-73\" transform=\"translate(1831.894531 0.015625)\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(1883.994141 0.015625)\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" transform=\"translate(1923.203125 0.015625)\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-69\" transform=\"translate(1964.316406 0.015625)\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-62\" transform=\"translate(1992.099609 0.015625)\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-75\" transform=\"translate(2055.576172 0.015625)\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(2118.955078 0.015625)\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-69\" transform=\"translate(2158.164062 0.015625)\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(2185.947266 0.015625)\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6e\" transform=\"translate(2247.128906 0.015625)\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-73\" transform=\"translate(2310.507812 0.015625)\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 515.64375 91.318438 \n",
       "L 698.14375 91.318438 \n",
       "Q 700.14375 91.318438 700.14375 89.318438 \n",
       "L 700.14375 29.32 \n",
       "Q 700.14375 27.32 698.14375 27.32 \n",
       "L 515.64375 27.32 \n",
       "Q 513.64375 27.32 513.64375 29.32 \n",
       "L 513.64375 89.318438 \n",
       "Q 513.64375 91.318438 515.64375 91.318438 \n",
       "z\n",
       "\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_23\">\n",
       "     <path d=\"M 517.64375 35.418438 \n",
       "L 527.64375 35.418438 \n",
       "L 537.64375 35.418438 \n",
       "\" style=\"fill: none; stroke: #ff0000; stroke-width: 3; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_22\">\n",
       "     <!-- $p_{\\mathrm{data}}$ -->\n",
       "     <g transform=\"translate(545.64375 38.918438) scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-Oblique-70\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-64\" transform=\"translate(63.476562 -16.40625) scale(0.7)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(107.910156 -16.40625) scale(0.7)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(150.805664 -16.40625) scale(0.7)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(178.251953 -16.40625) scale(0.7)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_24\">\n",
       "     <path d=\"M 517.64375 50.118438 \n",
       "L 527.64375 50.118438 \n",
       "L 537.64375 50.118438 \n",
       "\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #1f77b4; stroke-width: 1.5\"/>\n",
       "    </g>\n",
       "    <g id=\"text_23\">\n",
       "     <!-- $p_{\\theta_1}$ (two peaks, wrong means) -->\n",
       "     <g transform=\"translate(545.64375 53.618438) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-28\" d=\"M 1984 4856 \n",
       "Q 1566 4138 1362 3434 \n",
       "Q 1159 2731 1159 2009 \n",
       "Q 1159 1288 1364 580 \n",
       "Q 1569 -128 1984 -844 \n",
       "L 1484 -844 \n",
       "Q 1016 -109 783 600 \n",
       "Q 550 1309 550 2009 \n",
       "Q 550 2706 781 3412 \n",
       "Q 1013 4119 1484 4856 \n",
       "L 1984 4856 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-2c\" d=\"M 750 794 \n",
       "L 1409 794 \n",
       "L 1409 256 \n",
       "L 897 -744 \n",
       "L 494 -744 \n",
       "L 750 256 \n",
       "L 750 794 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-67\" d=\"M 2906 1791 \n",
       "Q 2906 2416 2648 2759 \n",
       "Q 2391 3103 1925 3103 \n",
       "Q 1463 3103 1205 2759 \n",
       "Q 947 2416 947 1791 \n",
       "Q 947 1169 1205 825 \n",
       "Q 1463 481 1925 481 \n",
       "Q 2391 481 2648 825 \n",
       "Q 2906 1169 2906 1791 \n",
       "z\n",
       "M 3481 434 \n",
       "Q 3481 -459 3084 -895 \n",
       "Q 2688 -1331 1869 -1331 \n",
       "Q 1566 -1331 1297 -1286 \n",
       "Q 1028 -1241 775 -1147 \n",
       "L 775 -588 \n",
       "Q 1028 -725 1275 -790 \n",
       "Q 1522 -856 1778 -856 \n",
       "Q 2344 -856 2625 -561 \n",
       "Q 2906 -266 2906 331 \n",
       "L 2906 616 \n",
       "Q 2728 306 2450 153 \n",
       "Q 2172 0 1784 0 \n",
       "Q 1141 0 747 490 \n",
       "Q 353 981 353 1791 \n",
       "Q 353 2603 747 3093 \n",
       "Q 1141 3584 1784 3584 \n",
       "Q 2172 3584 2450 3431 \n",
       "Q 2728 3278 2906 2969 \n",
       "L 2906 3500 \n",
       "L 3481 3500 \n",
       "L 3481 434 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6d\" d=\"M 3328 2828 \n",
       "Q 3544 3216 3844 3400 \n",
       "Q 4144 3584 4550 3584 \n",
       "Q 5097 3584 5394 3201 \n",
       "Q 5691 2819 5691 2113 \n",
       "L 5691 0 \n",
       "L 5113 0 \n",
       "L 5113 2094 \n",
       "Q 5113 2597 4934 2840 \n",
       "Q 4756 3084 4391 3084 \n",
       "Q 3944 3084 3684 2787 \n",
       "Q 3425 2491 3425 1978 \n",
       "L 3425 0 \n",
       "L 2847 0 \n",
       "L 2847 2094 \n",
       "Q 2847 2600 2669 2842 \n",
       "Q 2491 3084 2119 3084 \n",
       "Q 1678 3084 1418 2786 \n",
       "Q 1159 2488 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1356 3278 1631 3431 \n",
       "Q 1906 3584 2284 3584 \n",
       "Q 2666 3584 2933 3390 \n",
       "Q 3200 3197 3328 2828 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-29\" d=\"M 513 4856 \n",
       "L 1013 4856 \n",
       "Q 1481 4119 1714 3412 \n",
       "Q 1947 2706 1947 2009 \n",
       "Q 1947 1309 1714 600 \n",
       "Q 1481 -109 1013 -844 \n",
       "L 513 -844 \n",
       "Q 928 -128 1133 580 \n",
       "Q 1338 1288 1338 2009 \n",
       "Q 1338 2731 1133 3434 \n",
       "Q 928 4138 513 4856 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-Oblique-70\" transform=\"translate(0 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-Oblique-3b8\" transform=\"translate(63.476562 -16.390625) scale(0.7)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(106.303711 -27.875) scale(0.49)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(142.127441 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-28\" transform=\"translate(173.914551 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(212.928223 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-77\" transform=\"translate(252.137207 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(333.924316 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(395.105957 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-70\" transform=\"translate(426.893066 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(490.369629 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(551.893066 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6b\" transform=\"translate(613.172363 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" transform=\"translate(671.08252 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-2c\" transform=\"translate(723.182129 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(754.969238 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-77\" transform=\"translate(786.756348 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" transform=\"translate(868.543457 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(909.656738 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" transform=\"translate(970.838379 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-67\" transform=\"translate(1034.217285 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(1097.693848 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6d\" transform=\"translate(1129.480957 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(1226.893066 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(1288.416504 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" transform=\"translate(1349.695801 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" transform=\"translate(1413.074707 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-29\" transform=\"translate(1465.174316 0.015625)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_25\">\n",
       "     <path d=\"M 517.64375 65.518438 \n",
       "L 527.64375 65.518438 \n",
       "L 537.64375 65.518438 \n",
       "\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #ff7f0e; stroke-width: 1.5\"/>\n",
       "    </g>\n",
       "    <g id=\"text_24\">\n",
       "     <!-- $p_{\\theta_2}$ (two peaks, wrong std) -->\n",
       "     <g transform=\"translate(545.64375 69.018438) scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-Oblique-70\" transform=\"translate(0 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-Oblique-3b8\" transform=\"translate(63.476562 -16.390625) scale(0.7)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-32\" transform=\"translate(106.303711 -27.875) scale(0.49)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(142.127441 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-28\" transform=\"translate(173.914551 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(212.928223 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-77\" transform=\"translate(252.137207 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(333.924316 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(395.105957 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-70\" transform=\"translate(426.893066 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(490.369629 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(551.893066 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6b\" transform=\"translate(613.172363 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" transform=\"translate(671.08252 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-2c\" transform=\"translate(723.182129 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(754.969238 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-77\" transform=\"translate(786.756348 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" transform=\"translate(868.543457 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(909.656738 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" transform=\"translate(970.838379 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-67\" transform=\"translate(1034.217285 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(1097.693848 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" transform=\"translate(1129.480957 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(1181.580566 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-64\" transform=\"translate(1220.789551 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-29\" transform=\"translate(1284.266113 0.015625)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_26\">\n",
       "     <path d=\"M 517.64375 80.918438 \n",
       "L 527.64375 80.918438 \n",
       "L 537.64375 80.918438 \n",
       "\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #2ca02c; stroke-width: 1.5\"/>\n",
       "    </g>\n",
       "    <g id=\"text_25\">\n",
       "     <!-- $p_{\\theta_3}$ (close to true) -->\n",
       "     <g transform=\"translate(545.64375 84.418438) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-Oblique-70\" transform=\"translate(0 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-Oblique-3b8\" transform=\"translate(63.476562 -16.390625) scale(0.7)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-33\" transform=\"translate(106.303711 -27.875) scale(0.49)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(142.127441 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-28\" transform=\"translate(173.914551 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" transform=\"translate(212.928223 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6c\" transform=\"translate(267.908691 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(295.691895 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" transform=\"translate(356.873535 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(408.973145 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(470.496582 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(502.283691 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(541.492676 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(602.674316 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(634.461426 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" transform=\"translate(673.67041 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-75\" transform=\"translate(714.783691 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(778.162598 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-29\" transform=\"translate(839.686035 0.015625)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p732411b6bd\">\n",
       "   <rect x=\"50.14375\" y=\"22.32\" width=\"655\" height=\"291.16\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Math\n",
    "\n",
    "# ----------------------------\n",
    "# 1) Define distributions\n",
    "# ----------------------------\n",
    "def normal_pdf(x, mu, sigma):\n",
    "    return (1.0 / (sigma * np.sqrt(2*np.pi))) * np.exp(-0.5 * ((x - mu) / sigma)**2)\n",
    "\n",
    "def mix_pdf(x, mus, sigmas, weights):\n",
    "    weights = np.asarray(weights, dtype=float)\n",
    "    weights = weights / weights.sum()\n",
    "    p = np.zeros_like(x, dtype=float)\n",
    "    for w, mu, sig in zip(weights, mus, sigmas):\n",
    "        p += w * normal_pdf(x, mu, sig)\n",
    "    return p\n",
    "\n",
    "# True data distribution p_data: two-peaked Gaussian mixture\n",
    "p_data_params = dict(mus=[-2.0, 2.0], sigmas=[0.6, 0.8], weights=[0.55, 0.45])\n",
    "\n",
    "# Candidate model distributions p_theta (intentionally different)\n",
    "candidates = {\n",
    "    r\"$p_{\\theta_1}$ (two peaks, wrong means)\": dict(mus=[-3.0, 1.0], sigmas=[0.6, 0.8], weights=[0.55, 0.45]),\n",
    "    r\"$p_{\\theta_2}$ (two peaks, wrong std)\": dict(mus=[-2.0, 2.0], sigmas=[0.6, 0.8], weights=[0.20, 0.80]),\n",
    "    r\"$p_{\\theta_3}$ (close to true)\": dict(mus=[-2.1, 2.1], sigmas=[0.65, 0.75], weights=[0.52, 0.48]),\n",
    "}\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Numerical KL divergence on a grid\n",
    "# ----------------------------\n",
    "# KL(p||q) = ∫ p(x) log(p(x)/q(x)) dx\n",
    "x = np.linspace(-8, 8, 20001)  # fine grid\n",
    "p = mix_pdf(x, **p_data_params)\n",
    "p = p / np.trapezoid(p, x)  # normalize numerically\n",
    "\n",
    "EPS = 1e-300  # avoid log(0)\n",
    "\n",
    "def kl_divergence(p, q, x):\n",
    "    p_safe = np.maximum(p, EPS)\n",
    "    q_safe = np.maximum(q, EPS)\n",
    "    integrand = p_safe * (np.log(p_safe) - np.log(q_safe))\n",
    "    return float(np.trapezoid(integrand, x))\n",
    "\n",
    "results = []\n",
    "q_dict = {}\n",
    "\n",
    "for ind, (name, params) in enumerate(candidates.items(), start=1):\n",
    "    q = mix_pdf(x, **params)\n",
    "    q = q / np.trapezoid(q, x)\n",
    "    q_dict[name] = q\n",
    "\n",
    "    kl = kl_divergence(p, q, x)\n",
    "    results.append((name, kl))\n",
    "\n",
    "    display(Math(rf\"\\mathrm{{KL}}\\!\\left(p_{{\\text{{data}}}} \\,\\|\\, p_{{\\theta_{ind}}}\\right)\"\n",
    "                 rf\" = {kl:.6f}\\quad \\text{{{name}}}\"))\n",
    "\n",
    "# ----------------------------\n",
    "# 3) Plot PDFs and show KL table\n",
    "# ----------------------------\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(x, p, label=r\"$p_{\\mathrm{data}}$\", color=\"r\", linewidth=3)\n",
    "\n",
    "for name in candidates.keys():\n",
    "    plt.plot(x, q_dict[name], label=name, linestyle=\"-.\")\n",
    "\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"density\")\n",
    "plt.title(r\"Two-peaked $p_{\\mathrm{data}}$ vs. candidate $p_{\\theta}$ distributions\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aa563f-9215-4d3d-aef1-fb2b5ade9e59",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<div style=\"\n",
    "  background: #f2f2f2;\n",
    "  border: 1px solid #d9d9d9;\n",
    "  border-left: 6px solid #9e9e9e;\n",
    "  padding: 16px 18px;\n",
    "  border-radius: 12px;\n",
    "  font-size: 18px;\n",
    "  line-height: 1.38;\n",
    "  margin: 10px 0;\n",
    "\">\n",
    "\n",
    "  <div style=\"font-weight: 800; font-size: 20px; margin-bottom: 10px;\">\n",
    "    Theorem (Monte Carlo / sample-average MLE is effective)\n",
    "  </div>\n",
    "\n",
    "  <div style=\"margin-bottom: 10px;\">\n",
    "    Let \\(\\mathbf{w}^{(1)},\\ldots,\\mathbf{w}^{(N)} \\overset{\\text{i.i.d.}}{\\sim} p_{\\text{data}}\\).\n",
    "    Define the population objective and its Monte Carlo (empirical) estimator:\n",
    "    \\[\n",
    "      \\mu(\\theta):=\\mathbb{E}_{\\mathbf{w}\\sim p_{\\text{data}}}\\!\\big[\\log p_\\theta(\\mathbf{w})\\big],\\qquad\n",
    "      \\hat{\\mu}_N(\\theta):=\\frac{1}{N}\\sum_{i=1}^{N}\\log p_\\theta\\!\\big(\\mathbf{w}^{(i)}\\big).\n",
    "    \\]\n",
    "  </div>\n",
    "\n",
    "  <div style=\"margin-bottom: 10px;\">\n",
    "    Assume for each fixed \\(\\theta\\), \\(\\mathbb{E}_{p_{\\text{data}}}[\\,|\\log p_\\theta(\\mathbf{w})|\\,] < \\infty\\).\n",
    "    Then for every fixed \\(\\theta\\),\n",
    "    \\[\n",
    "      \\hat{\\mu}_N(\\theta)\\xrightarrow[N\\to\\infty]{a.s.}\\mu(\\theta).\n",
    "    \\]\n",
    "    Moreover, if the convergence is <em>uniform</em> over \\(\\theta\\in\\Theta\\),\n",
    "    \\[\n",
    "      \\sup_{\\theta\\in\\Theta}\\big|\\hat{\\mu}_N(\\theta)-\\mu(\\theta)\\big|\\xrightarrow[N\\to\\infty]{a.s.}0,\n",
    "    \\]\n",
    "    and if \\(\\mu(\\theta)\\) has a unique maximizer \\(\\theta^\\star=\\arg\\max_{\\theta\\in\\Theta}\\mu(\\theta)\\),\n",
    "    then any maximizer of the empirical objective\n",
    "    \\[\n",
    "      \\hat{\\theta}_N\\in\\arg\\max_{\\theta\\in\\Theta}\\hat{\\mu}_N(\\theta)\n",
    "    \\]\n",
    "    is <strong>consistent</strong>: $\\hat{\\theta}_N \\xrightarrow[N\\to\\infty]{} \\theta^\\star$\n",
    "  </div>\n",
    "\n",
    "  <div style=\"margin-top: 10px; opacity: 0.95;\">\n",
    "    <strong>Interpretation:</strong> maximizing the empirical average log-likelihood (MC estimate)\n",
    "    is a principled and effective way to approximate the ideal objective.\n",
    "  </div>\n",
    "\n",
    "  <details style=\"margin-top: 12px;\">\n",
    "    <summary style=\"cursor: pointer; font-weight: 700;\">Proof (click to expand)</summary>\n",
    "    <div style=\"margin-top: 10px;\">\n",
    "      <div style=\"font-weight: 800; margin-bottom: 6px;\">Step 1: Fixed-\\(\\theta\\) convergence (Law of Large Numbers).</div>\n",
    "      For a fixed \\(\\theta\\), define \\(X_i(\\theta):=\\log p_\\theta(\\mathbf{w}^{(i)})\\).\n",
    "      Since \\(\\mathbf{w}^{(i)}\\) are i.i.d., the random variables \\(X_i(\\theta)\\) are also i.i.d. with\n",
    "      \\(\\mathbb{E}[|X_i(\\theta)|]<\\infty\\) by assumption. The Strong Law of Large Numbers implies\n",
    "      \\[\n",
    "        \\frac{1}{N}\\sum_{i=1}^{N}X_i(\\theta)\\xrightarrow[]{a.s.}\\mathbb{E}[X_1(\\theta)].\n",
    "      \\]\n",
    "      Substituting back \\(X_i(\\theta)=\\log p_\\theta(\\mathbf{w}^{(i)})\\) gives\n",
    "      \\[\n",
    "        \\hat{\\mu}_N(\\theta)\\xrightarrow[]{a.s.}\\mu(\\theta).\n",
    "      \\]\n",
    "      <div style=\"font-weight: 800; margin: 12px 0 6px;\">Step 2: Why uniform convergence matters for the argmax.</div>\n",
    "      In MLE, \\(\\theta\\) is not fixed: we choose \\(\\hat{\\theta}_N\\) by maximizing \\(\\hat{\\mu}_N(\\theta)\\).\n",
    "      Pointwise convergence \\(\\hat{\\mu}_N(\\theta)\\to\\mu(\\theta)\\) for each fixed \\(\\theta\\) does not by itself\n",
    "      guarantee that the maximizers converge. A standard sufficient condition is a <em>uniform law of large numbers</em>:\n",
    "      \\[\n",
    "        \\sup_{\\theta\\in\\Theta}\\big|\\hat{\\mu}_N(\\theta)-\\mu(\\theta)\\big|\\xrightarrow[]{a.s.}0.\n",
    "      \\]\n",
    "      Intuitively, this says the entire empirical objective surface approaches the population surface everywhere.\n",
    "      <div style=\"font-weight: 800; margin: 12px 0 6px;\">Step 3: Argmax consistency under uniform convergence + uniqueness.</div>\n",
    "      Assume \\(\\mu(\\theta)\\) has a unique maximizer \\(\\theta^\\star\\). Fix any \\(\\varepsilon>0\\).\n",
    "      By uniqueness, there exists a gap \\(\\gamma(\\varepsilon)>0\\) such that\n",
    "      \\[\n",
    "        \\mu(\\theta^\\star) \\ge \\sup_{\\|\\theta-\\theta^\\star\\|\\ge \\varepsilon}\\mu(\\theta) + 2\\gamma(\\varepsilon).\n",
    "      \\]\n",
    "      By uniform convergence, for all large enough \\(N\\) (almost surely),\n",
    "      \\[\n",
    "        \\sup_{\\theta\\in\\Theta}|\\hat{\\mu}_N(\\theta)-\\mu(\\theta)| < \\gamma(\\varepsilon).\n",
    "      \\]\n",
    "      Then for any \\(\\theta\\) with \\(\\|\\theta-\\theta^\\star\\|\\ge \\varepsilon\\),\n",
    "      \\[\n",
    "        \\hat{\\mu}_N(\\theta)\n",
    "        \\le \\mu(\\theta) + \\gamma(\\varepsilon)\n",
    "        \\le \\big(\\mu(\\theta^\\star)-2\\gamma(\\varepsilon)\\big) + \\gamma(\\varepsilon)\n",
    "        = \\mu(\\theta^\\star)-\\gamma(\\varepsilon)\n",
    "        \\le \\hat{\\mu}_N(\\theta^\\star).\n",
    "      \\]\n",
    "      So no parameter outside the \\(\\varepsilon\\)-ball can maximize \\(\\hat{\\mu}_N\\); hence any maximizer\n",
    "      \\(\\hat{\\theta}_N\\) must satisfy \\(\\|\\hat{\\theta}_N-\\theta^\\star\\|<\\varepsilon\\) for all large \\(N\\) (a.s.).\n",
    "      Because \\(\\varepsilon\\) is arbitrary, \\(\\hat{\\theta}_N\\to\\theta^\\star\\).\n",
    "      <div style=\"margin-top: 10px;\">\n",
    "        This shows that <strong>maximizing the MC (empirical) log-likelihood reliably recovers the population optimum</strong>\n",
    "        when \\(N\\) is large and the model class is well-behaved (so the uniform convergence assumption holds).\n",
    "        \\(\\square\\)\n",
    "      </div>\n",
    "    </div>\n",
    "  </details>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a10f56-0c9a-4cac-89d9-608c7dc97bce",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<a id=\"12\"></a>\n",
    "### 1.2 Log probability of sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3657bda7-56f9-46db-ba49-a29439eed1b1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- **Get log probability of sentences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5ac7ed27-cb55-42e5-b06c-65ea53647f27",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "def get_sentence_probability(sentence, model_id):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\")\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\").to(model.device)\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Passing labels=input_ids tells the model to calculate the cross-entropy loss\n",
    "        outputs = model(input_ids, labels=input_ids)\n",
    "        avg_loss = outputs.loss.item()\n",
    "    \n",
    "    # Total Log-Likelihood is -(average_loss * sequence_length)\n",
    "    total_log_prob = -avg_loss * input_ids.shape[1]\n",
    "    \n",
    "    return total_log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d86c0099-7ce4-4feb-b51d-c8f040ef7ce5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: [He to reporters introduced main content], Log-Prob: -56.2687\n",
      "Sentence 2: [He briefed reporters on the main contents of the statement], Log-Prob: -52.7838\n",
      "Sentence 2 is more \"natural\" according to Qwen/Qwen3-0.6B.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0cca48649df46e5bd6a89ec5073c99f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the disk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: [He to reporters introduced main content], Log-Prob: -65.9077\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f468435643d447d1b14b218ea92ddf76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the disk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 2: [He briefed reporters on the main contents of the statement], Log-Prob: -45.0296\n",
      "Sentence 2 is more \"natural\" according to Qwen/Qwen3-1.7B.\n"
     ]
    }
   ],
   "source": [
    "for model_id in [\"Qwen/Qwen3-0.6B\", \"Qwen/Qwen3-1.7B\"]:\n",
    "    s1 = \"He to reporters introduced main content\"\n",
    "    s2 = \"He briefed reporters on the main contents of the statement\"\n",
    "    print(f\"Sentence 1: [{s1}], Log-Prob: {get_sentence_probability(s1, model_id):.4f}\")\n",
    "    print(f\"Sentence 2: [{s2}], Log-Prob: {get_sentence_probability(s2, model_id):.4f}\")\n",
    "    if loss2 < loss1:\n",
    "        print(f\"Sentence 2 is more \\\"natural\\\" according to {model_id}.\")\n",
    "    else:\n",
    "        print(f\"Sentence 1 is more \\\"natural\\\" according to {model_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "814feb47-ab45-44f2-addf-57659d639b5b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: [It's hard to recognize speech], Log-Prob: -46.3041\n",
      "Sentence 2: [It's hard to wreck a nice beach], Log-Prob: -55.6418\n",
      "Sentence 2 is more \"natural\" according to Qwen/Qwen3-0.6B.\n"
     ]
    }
   ],
   "source": [
    "s1 = \"It's hard to recognize speech\"\n",
    "s2 = \"It's hard to wreck a nice beach\"\n",
    "for model_id in [\"Qwen/Qwen3-0.6B\"]:\n",
    "    print(f\"Sentence 1: [{s1}], Log-Prob: {get_sentence_probability(s1, model_id):.4f}\")\n",
    "    print(f\"Sentence 2: [{s2}], Log-Prob: {get_sentence_probability(s2, model_id):.4f}\")\n",
    "    if loss2 < loss1:\n",
    "        print(f\"Sentence 2 is more \\\"natural\\\" according to {model_id}.\")\n",
    "    else:\n",
    "        print(f\"Sentence 1 is more \\\"natural\\\" according to {model_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe397464-19dc-4a9a-a7fa-0673e7918c63",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "This note introduces the $N$-gram language model. We define the $N$-gram language model and show how to use maximum likelihood estimation to learn these parameters. We then discuss techniques to handle zero probability issues (smoothing) and define perplexity.\n",
    "\n",
    "**Notations:** A sentence after tokenization is $[w_1, w_2, \\ldots, w_t]$ denoted it as $s = w_{1:t}$. For example, for the sentence *\"the cat saw the dog\"*, we have $s=w_{1:5} = [\\textit{the, cat, saw, the, dog}]$. Let $P(X)$ represent the probability distribution of a discrete random variable $X$. We use $w_i$ to denote the random variable $X_i$ at the $i$-th position of $s$. That is, $P(X_i = w_i) \\equiv P(w_i)$. Let $X_{i+1}$ represent the choice $w_{i+1}$, and $X_i$ represent $w_i$, which occurs before $w_{i+1}$. Then, $P(X_i, X_{i+1})$ is the probability of $w_i w_{i+1}$, which we write as $P(X_i = w_i, X_{i+1} = w_{i+1}) \\equiv P(w_{i:i+1})$. We define the vocabulary $\\mathcal{V} = \\{v_1,v_2,\\ldots,v_{|\\mathcal{V}|}\\}$ and two special symbols $v_0=\\text{BOS}$ and $v_{|\\mathcal{V}|+1} = \\text{EOS}$ presenting the beginning and end of a sentence, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e5ba91-e633-4579-b50d-ce9d405e5db2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**Summary of our motivation:** Say you have a speech recognition task where you need to design a speech recognizer. Given an acoustic signal, the recognizer produces two possible sentences: $s_1 =$*\"It's hard to recognize speech\"* and $s_2 =$*\"It's hard to wreck a nice beach\"*. If the model is good enough, it will produce probabilities such that $P(s_1) > P(s_2)$ because both $s_1$ and $s_2$ have very similar acoustic signals, but $s_1$ is more realistic in everyday language. Thus, the speech recognizer needs to be able to assign probabilities to different sentence sequences, comparing how likely $s_1$ and $s_2$ are to occur in the real world. The task of language modeling is to assign probabilities to sentences. In other words, we want to learn a model—specifically, the distribution $P$—that satisfies $P\\left(s_1\\right) > P\\left(s_2\\right)$.\n",
    "\n",
    "**Our task:** The goal is to learn a language model given a *training* corpus, which consists of a set of sentences in some language $\\mathcal{V}$. Using this training corpus, we aim to learn a language model. Then, we use a *validation* corpus to tune the hyperparameters of the model. Finally, the *test* corpus is used to evaluate the performance of the trained language model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67f9c8f-5b55-4ca3-a79a-40051b29875f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<a id=\"2\"></a>\n",
    "## 2. Understanding N-gram LMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106efa75-7f74-4a40-bef1-0229a0fabf3b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<a id=\"21\"></a>\n",
    "### 2.1 Statistical LMs and $N$-gram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88779dae-d56e-4ee5-aaa4-3affd2071be8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "A statistical language model defines a probability distribution over sentences from a given language vocabulary $\\mathcal{V}$. A possible vocabulary of English language model could be $\\mathcal{V}=\\{\\textit{the}, \\textit{dog}, \\textit{laughs}, \\textit{saw},\\ldots\\}$ where we assume $\\mathcal{V}$ is a finite set. A *sentence* in the language is a sequence of words\n",
    "\n",
    "$$s=w_1 w_2 \\ldots w_t \\equiv w_{1:t},$$\n",
    "\n",
    "where the integer $t\\geq 1$ is not fixed and $w_i \\in \\mathcal{V}$ for $i \\in\\{1,\\ldots,t-1\\}$, and we assume that $w_t = \\text{EOS}$ is a special symbol, which is not in $\\mathcal{V}$. We define $\\mathcal{V}^{\\dagger}$ to be the set of all sentences with the vocabulary $\\mathcal{V}$. The set $\\mathcal{V}^{\\dagger}$ is an infinite set because sentences can be of any length. For example, $\\mathcal{V}^{\\dagger}$ could be like,\n",
    "\n",
    "$$\\mathcal{V}^{\\dagger} = \\{\\text{the dog barks EOS}, \\text{the EOS}, \\text{cat cat cat EOS}, \\text{EOS}, \\ldots\\}.$$\n",
    "\n",
    "A language model computes the probability of $w_{1:t}$, $p(w_{1:t})$, which can be formally defined as\n",
    "\n",
    "> **Definition (Language model (LM))**  \n",
    "> Given a finite vocabulary set $\\mathcal{V}$, for any $t\\geq 1$, a $t$-length sentence is a sequence $w_{1:t}$ where each $w_i \\in \\mathcal{V} \\equiv \\{v_1, \\ldots, v_{|\\mathcal{V}|}\\}$ for $i=1,2,\\ldots,t-1$ and $w_t = \\text{EOS}$. Let $\\mathcal{V}^{\\dagger}$ be the set of such sentences. A language model is a probability distribution function $p(w_{1:t})$ over $\\mathcal{V}^{\\dagger}$ such that\n",
    "> \n",
    "> - For any $w_{1:t} \\in \\mathcal{V}^{\\dagger}, p(w_{1:t}) \\geq 0$.\n",
    "> - In addition, $\\sum_{w_{1:t} \\in \\mathcal{V}^{\\dagger}} p(w_{1:t})=1$.\n",
    "\n",
    "Hence, $p\\left(w_{1:t}\\right)$ defined above is a probability distribution over $\\mathcal{V}^{\\dagger}$. This language model enables us to *understand*: Given a sentence $w_{1:t}$, we can use $p$ to compute $p(w_{1:t})$ so that we can compare the probabilities of any two sentences; and to *generate*: the distribution $p$ can be employed to generate sentences. One can use the Chain rule to decompose it as a product of conditional probability as\n",
    "\n",
    "$$p\\left(w_{1:t}\\right) = \\prod_{i=1}^t p\\left(w_i|w_{1:i-1}\\right),$$\n",
    "\n",
    "where $p\\left(w_1|w_{1:0}=\\text{EOS}\\right) = p\\left(w_1\\right)$ by default and $w_{1:i-1}$ is called *history* of $w_i$. Computing $p(w_{1:t})$ *exactly* is generally difficult or impossible. For example, if one only wants to compute sentences with five words $p(w_{1:5})$ and the vocabulary size $|\\mathcal{V}|= 10^4$. Then, we need to know all possible $p(w_{1:5})$, which is about $10^{4\\times 5}=10^{20}$ parameters only for $p(w_{1:5})$. So far, all language models we have seen are certain models that try to *estimate* $p\\left(w_{1:t}\\right)$ from some training text. Of course, we hope that the training text can well sample the language. There are roughly three types of language models:\n",
    "\n",
    "1. **Statistical language models**: These models use statistical methods to predict the next word in a sentence based on the probabilities of word sequences, known as $N$-gram models.\n",
    "2. **Neural language models**: These are based on neural networks and include various architectures like two-layer neural networks (word2vec) and RNNs (e.g., LSTMs, GRUs).\n",
    "3. **Large language models (LLMs)**: Neural network model that uses self-attention mechanisms (Transformers), such as the BERT and GPT (Generative Pre-trained Transformer) families.\n",
    "\n",
    "Why we need $w_t = \\text{EOS}$? In our definition of the sentence $w_{1:t}$, the sentence length $t$ is itself a random variable. There are various ways of modeling this variability in length. However, the most common language modeling approach is assuming that the last word, $w_t$, is always equal to a special symbol, EOS. This symbol can only appear at the end of a sequence.  Approximating $p(w_{1:t})$ is key to building a practical language model. For example, under a first-order Markov assumption, we can approximate it as $p(w_{1:t}) = P(X_{1:t}=w_{1:t})=\\prod_{i=1}^t P(X_i=w_i \\mid X_{i-1}=w_{i-1})$. Similarly, under the second-order Markov assumption, we can approximate it as\n",
    "\n",
    "$$p(w_{1:t}) = P(X_{1:t}=w_{1:t})=\\prod_{i=1}^t P(X_i=w_i \\mid X_{i-2}=w_{i-2}, X_{i-1}=w_{i-1}),$$\n",
    "\n",
    "for any $t \\geq 1$. The second-order Markov process generates a symbol $x_i$ from the distribution\n",
    "\n",
    "$$P\\left(X_i=x_i \\mid X_{i-2}=x_{i-2}, X_{i-1}=x_{i-1}\\right),$$\n",
    "\n",
    "where $x_i \\in \\mathcal{V} \\cup \\{\\text{EOS}\\}$. To sample a sentence from $P$, we can do the following: If we generate the EOS symbol, we finish the sequence. Otherwise, we continue to generate the next symbol in the sequence. A little more formally, the process that generates sentences would be as follows:\n",
    "\n",
    "- **Step 1:** Initialize $i=1$, and $x_0=x_{-1}=\\text{BOS}$\n",
    "- **Step 2:** Generate $x_i$ from the distribution $p\\left(X_i= x_i \\mid X_{i-2:i-1}=x_{i-2:i-1}\\right)$\n",
    "- **Step 3:** If $x_i=$ EOS, then return $x_{1:i}$. Otherwise, set $i=i+1$ and return to **Step 2**.\n",
    "\n",
    "Thus, the model generates sentences that vary in length. The $N$-gram model can be defined as\n",
    "\n",
    "> **Definition ($N$-gram LM)**  \n",
    "> Given the finite vocabulary set $\\mathcal{V}$, for any $t\\geq 1$, a $t$-length sentence is a sequence $w_{1:t}$ where each $w_i \\in \\mathcal{V} \\equiv \\{v_1, \\ldots, v_{|\\mathcal{V}|}\\}$ for $i=1,2,\\ldots,t-1$ and $w_t = \\text{EOS}$. For any sentence $w_{1:t}$, the $N$-gram language model computes the probability of sentence $w_{1:t}$, $p(w_{1:t})$, by using the $(N-1)$-order of Markov assumption, that is\n",
    "> \n",
    "> $$p\\left(w_{1:t}\\right) = \\prod_{i=1}^t q\\left(w_i \\mid w_{i-N+1:i-1}\\right),$$\n",
    "> \n",
    "> where the function $q(x_{N}|x_{1:N-1})$ is the conditional probability distribution of $N$-gram $x_{1:N}$ where $x_i \\in \\mathcal{V} \\cup\\{\\text{BOS}\\}$ for $i=1,2,\\ldots,N-1$ and $x_N \\in \\mathcal{V} \\cup \\{\\text{EOS}\\}$. The value for $q(x_N \\mid x_{1:N-1})$ can be interpreted as the probability of seeing the word $x_N$ immediately after the gram $x_{1:N-1}$. By default, we define $w_i=\\text{BOS}$ for any $i\\leq 0$.\n",
    "\n",
    "For example,\n",
    "\n",
    "- When $N=1$, the $p$ is an *unigram* LM where $p\\left(w_{1:t}\\right) = \\prod_{i=1}^t q\\left(w_i\\right)$.\n",
    "- When $N=2$, we call $p$ a *bigram* LM where $p\\left(w_{1:t}\\right) = \\prod_{i=1}^t q\\left(w_i | w_{i-1}\\right)$.\n",
    "- When $N=3$, we call it a *trigram* LM where $p\\left(w_{1:t}\\right) = \\prod_{i=1}^t q\\left(w_i \\mid w_{i-2:i-1}\\right)$.\n",
    "\n",
    "In the above definition, $q(x_N|x_{1:N-1})$ are parameters that will be learned from the training corpus. For example, the parameters satisfy the constraints that for any trigram $(u, v, w)$, $q(w \\mid u, v) \\geq 0$ and for any bigram $u, v$, $\\sum_{w \\in \\mathcal{V} \\cup\\{\\text{EOS}\\}} q(w \\mid u, v)=1$. Thus $q(w \\mid u, v)$ defines a distribution over possible words $w$, conditioned on the bigram context $u, v$. The key problem we are left with is estimating the model parameters $q(x_N \\mid x_{1:N-1})$. The model has around $|\\mathcal{V}|^{N}$ parameters. This is likely to be a very large number. For example, with $|\\mathcal{V}|=10,000$, we have $|\\mathcal{V}|^3 \\approx 10^{12}$ number of parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fc29f9-6dd4-4760-bb5d-8a6584ee90be",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<a id=\"22\"></a>\n",
    "### 2.2 Learning parameters via MLE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c08f24-3468-4e49-a42d-d18772879e7e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<div style=\"\n",
    "  background: rgba(0,0,0,0.05);\n",
    "  border: 0px solid rgba(0,0,0,0.1);\n",
    "  border-radius: 6px;\n",
    "  padding: 15px 15px;\n",
    "  line-height: 1.2;\n",
    "\">\n",
    "\n",
    "To estimate $q(x_N|x_{1:N-1})$, a reasonable process is to collect a set of raw text (e.g., Wikipedia pages, Web context, books, etc) as training dataset $\\mathcal{D}_{\\text{tr}}$. After the tokenization, it is\n",
    "\n",
    "$$\\mathcal{D}_{\\text{tr}}= \\left\\{ s_1, s_2,\\ldots, s_T\\right\\} \\equiv s_{1:T}, \\text{ where } s_i = w_{1:t_i}^{(i)} \\in \\mathcal{V}^{\\dagger},$$\n",
    "\n",
    "where $T$ is the total number of sentences in $\\mathcal{D}_{\\text{tr}}$. We can estimate $q(\\cdot)$ based on $\\mathcal{D}_{\\text{tr}} = s_{1:T}$. Let us assume $d$ unknown parameters parameterize $P$. We write the parameters governing the joint distribution as a vector $\\mathbf{\\theta}=\\left[\\theta_1, \\theta_2, \\ldots, \\theta_d\\right]^{\\top}$ so that $P$ falls within a parametric family $\\{P(\\mathcal{D}; \\mathbf{\\theta}) \\mid \\mathbf{\\theta} \\in \\Theta \\subseteq \\mathbb{R}^d\\}$ where $\\Theta$ is the parameter space. Maximum likelihood estimation (MLE) estimates the parameters of an assumed probability distribution given some observed data $\\mathcal{D}$. **Maximum likelihood estimation (MLE) aims to determine the parameters $\\mathbf{\\theta}$ for which the observed data have the highest joint probability.**  Specifically, to maximize the likelihood function of $T$ random sentences in $\\mathcal{D}_{\\text{tr}}$, one needs to solve the following optimization problem\n",
    "\n",
    "$$\\hat{\\mathbf{\\theta}} \\in \\arg \\max_{ \\mathbf{\\theta} \\in \\mathbf{\\Theta} } \\left\\{  \\mathcal{L}_T(\\mathbf{\\theta} ; \\mathcal{D}_{\\text{tr}}) := P(s_{1:T}; \\mathbf{\\theta})  \\right\\}.$$\n",
    "\n",
    "The above MLE allows us to estimate the $N$-gram model. There are two questions: What are the parameters $\\mathbf{\\theta}$ of unigram, bigram, and trigram? and How to estimate these parameters $\\mathbf{\\theta}$?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d28423e-0cf0-42b8-933f-44f06bd090d9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<a id=\"23\"></a>\n",
    "### 2.3 MLE for unigram model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254f356d-1224-4c70-8e4b-6d2cc17f732e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<div style=\"\n",
    "  background: rgba(0,0,0,0.05);\n",
    "  border: 0px solid rgba(0,0,0,0.1);\n",
    "  border-radius: 6px;\n",
    "  padding: 15px 15px;\n",
    "  line-height: 1.2;\n",
    "\">\n",
    "Given the training corpus $\\mathcal{D}_{\\text{tr}} = \\{s_1,s_2,\\ldots,s_T\\}$ observed from true distribution $P$. Under the assumption of the unigram model, we have\n",
    "\n",
    "$$P(s_{1:T}) = \\prod_{i=1}^{T} P(s_i \\equiv w_{1:t_i}^{(i)} ) = \\prod_{i=1}^{T} \\prod_{j=1}^{t_i} q(w_{j}^{(i)}) = \\prod_{i=1}^{|\\mathcal{V}|+1} q(v_i)^{C(v_i)} = \\prod_{i=1}^{|\\mathcal{V}|+1} \\theta_{i}^{C(v_i)},$$\n",
    "\n",
    "where we assume sentences $s_i$ are independent with each other, the count $C(v_i) = \\sum_{i=1}^T |\\{w_j^{(i)} : w_j^{(i)} = v_i, j = 1,\\ldots,t_i\\}|$ denotes the number of $v_i$ in $s_{1:T}$, the parameter vector $\\mathbf{\\theta} = [\\theta_1,\\theta_2,\\ldots,\\theta_{|\\mathcal{V}|},\\theta_{\\text{EOS}}]^\\top$ with $\\theta_i := q(v_i)$. Indeed, the parameter $\\mathbf{\\theta}$ completely defines the distribution $P(w_{1:t})$, and we have the constraint that $\\sum_{i=1}^{|\\mathcal{V}|+1} \\theta_i = \\sum_{i=1}^{|\\mathcal{V}|+1} q\\left(v_i\\right) = 1$. We continue to write out the likelihood function\n",
    "\n",
    "$$\\mathcal{L}_T(\\mathbf{\\theta} ; \\mathcal{D}_{\\text{tr}}) := P(s_{1:T}; \\mathbf{\\theta}) = \\prod_{i=1}^T P(s_i; \\mathbf{\\theta}) = \\prod_{i=1}^{|\\mathcal{V}|+1} q\\left(v_i; \\mathbf{\\theta}\\right)^{C\\left(v_i\\right)} = \\prod_{i=1}^{|\\mathcal{V}|+1} \\theta_i^{C\\left(v_i\\right)}.$$\n",
    "\n",
    "To solve the MLE problem, it is equivalent to maximize the log of $\\mathcal{L}$, we have\n",
    "\n",
    "$${\\mathbf{\\theta}}^* \\in \\arg \\max_{ \\mathbf{\\theta} \\in \\{ \\mathbf{x}: \\|\\mathbf{x}\\|_1 =1\\}} \\big\\{  \\mathcal{L}_T(\\mathbf{\\theta} ; \\mathcal{D}_{\\text{tr}}) := P(s_{1:T}; \\mathbf{\\theta})  \\big\\} = \\arg \\max_{ \\sum_{j} \\theta_j = 1 } \\sum_{i=1}^{|\\mathcal{V}|+1} C\\left(v_i\\right) \\log \\theta_i.$$\n",
    "\n",
    "Since the constraint set is convex, it is a convex-constrained optimization problem as the following\n",
    "\n",
    "$$\\max_{\\mathbf{\\theta}} \\sum_{i=1}^{|\\mathcal{V}|+1} C(v_i) \\log \\theta_i, \\text{ subject to }  \\sum_{i=1}^{|\\mathcal{V}|+1} \\theta_{i} = 1.$$\n",
    "\n",
    "To solve this convex-constrained optimization problem, we introduce a scalar $\\lambda$ called a *Lagrange multiplier* (one for each constraint), rewrite the equality constraint as $E(x)=0$, and define a new Lagrangian function of the form $G(x, \\lambda)=F(x)-\\lambda E(x)$, where $F(x)$ is the original objective. Then, we just need to check the saddle points of the Lagrangian function $G$. In our case, the Lagrangian is\n",
    "\n",
    "$$G(\\mathbf{\\theta}, \\lambda) := \\sum_{i=1}^{|\\mathcal{V}|+1} C(v_i) \\log \\theta_{i} - \\lambda\\left(\\sum_{i=1}^{|\\mathcal{V}|+1} \\theta_i - 1\\right) = \\sum_{i=1}^{|\\mathcal{V}|+1}( C(v_i) \\log \\theta_i - \\lambda \\theta_i) + \\lambda = \\sum_{i=1}^{|\\mathcal{V}|+1} g( \\theta_i) + \\lambda,$$\n",
    "\n",
    "where $g(\\theta_i) := C(v_i) \\log \\theta_i - \\lambda \\theta_i$ is a concave function and $G$ is linear in term of $\\lambda$. Hence, $G(\\mathbf{\\theta},\\lambda)$ is decomposible concave function in terms of $\\mathbf{\\theta}$, one can get maximal value of $\\mathcal{L}$ by getting the saddle points of $G$. The function $g_i$ is differentiable and concave, and we set the gradient of $g_i$ to zero to get such saddle point (Since the original objective is concave and constraint equation is linear, then the saddle point is unique. To find this saddle point, we just need to letting gradient of $\\mathbf{\\theta}$ and $\\lambda$ be zeros.)\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\frac{\\partial g_i }{\\partial \\theta_i} & =\\frac{C (v_i) }{\\theta_i} -\\lambda=0, \\text{ for } i = 1,2,\\ldots, |\\mathcal{V}|+1. \\\\\n",
    "\\frac{\\partial G }{\\partial \\lambda} & =\\sum_{i=1}^{|\\mathcal{V}|} \\theta_i -1=0\n",
    "\\end{aligned}$$\n",
    "\n",
    "which gives $\\lambda = \\sum_{i=1}^T |s_i| = \\sum_{i=1}^{|\\mathcal{V}|+1} C(v_i)$ and each optimal $\\theta_i^*$ is\n",
    "\n",
    "$${\\theta}_i^* = \\frac{C(v_i)}{\\sum_{i=1}^{|\\mathcal{V}|+1} C(v_i) }=\\frac{C(v_i)}{\\sum_{i=1}^T |s_i|},$$\n",
    "\n",
    "where $\\sum_{i=1}^T |s_i|$ is the number of tokens in training corpus $s_{1:T}$. It can be seen that the purpose of $\\lambda = \\sum_{i=1}^{|\\mathcal{V}|+1} C(v_i)$ is normalization. Therefore, the parameter estimation of MLE for the unigram model is simply the frequency estimate for the unigram model!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e90e09-c376-48dc-afdb-e5262df37a1a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<a id=\"24\"></a>\n",
    "### 2.4 MLE for bigram model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f825b63a-cb75-439e-bbbf-4c5071eb64e6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<div style=\"\n",
    "  background: rgba(0,0,0,0.05);\n",
    "  border: 0px solid rgba(0,0,0,0.1);\n",
    "  border-radius: 6px;\n",
    "  padding: 15px 15px;\n",
    "  line-height: 1.2;\n",
    "\">\n",
    "\n",
    "For bigram model, given a training dataset $\\mathcal{D}_{\\text{tr}} = s_{1:T}$ where each sentence $s_i = w_{1:t_i}^{(i)}$, we have\n",
    "\n",
    "$$P(s_{1:T}) = \\prod_{i=1}^T P(s_i) = \\prod_{i=1}^T \\prod_{j=1}^{t_i} q(w_{j}^{(i)}|w_{j-1}^{(i)}) = \\prod_{i=0}^{|V|} \\prod_{j=0}^{|V|} q(v_{j+1} | v_i)^{C(v_i, v_{j+1})},$$\n",
    "\n",
    "where $C(v_i,v_{j+1})$ is the number of bigram $(v_i,v_{j+1})$ appeared in $s_{1:T}$. We may need to consider the conditional probability $q(v_{j+1}|v_i)$ more carefully. Recall we defined $v_0= \\text{EOS}$ as the starting mark of a sentence. Let $\\theta_{i,j+1} := q(v_{j+1}|v_i)$, and $\\mathbf{\\theta}_i = [\\theta_{i,1},\\theta_{i,2},\\ldots,\\theta_{i,|\\mathcal{V}|+1}]^\\top$ for $i=0,1,\\ldots,|V|$. Indeed, these $\\mathbf{\\theta}_i$ completely define the distribution $p(w_{1:t})$, and we have the constraint that $\\sum_{j=0}^{|\\mathcal{V}|} \\theta_{i,j+1} = \\sum_{j=0}^{|\\mathcal{V}|} q\\left(v_{j+1}|v_i\\right) = 1$ for all $i=0,1,\\ldots,|V|$. We continue to write out the log-likelihood function\n",
    "\n",
    "$$\\log P(s_{1:T};{\\mathbf{\\Theta}}) = \\sum_{i=0}^{|\\mathcal{V}|} \\sum_{j=0}^{|\\mathcal{V}|} C\\left(v_i, v_{j+1}\\right) \\log q\\left(v_{j+1} \\mid v_i\\right).$$\n",
    "\n",
    "To maximize the above score, equivalently, we have the following optimization problem:\n",
    "\n",
    "$$\\max_{\\mathbf{\\theta}_{0:|\\mathcal{V}|}} \\log P(s_{1:T};\\mathbf{\\theta}_{0:|\\mathcal{V}|}), \\text{ subject to } \\sum_{j=0}^{|\\mathcal{V}|} \\theta_{i,j+1} = 1, \\forall \\ i =0,1,\\ldots,|\\mathcal{V}|.$$\n",
    "\n",
    "Similar to the unigram model, we introduce $|\\mathcal{V}|+1$ Lagrange multipliers $\\lambda_i$ for each equation constraint  $\\sum_{j=0}^{|\\mathcal{V}|}  \\theta_{i,j+1} -1=0$ for $i=0,1,\\ldots,|\\mathcal{V}|$. We have the following Lagrangian function\n",
    "\n",
    "$$\\mathcal{G}(\\mathbf{\\theta}_{0},\\ldots, \\mathbf{\\theta}_{|\\mathcal{V}|},\\mathbf{\\lambda}) := \\sum_{i=0}^{|\\mathcal{V}|} \\sum_{j=0}^{|\\mathcal{V}|} C\\left(v_i, v_{j+1}\\right) \\log \\theta_{i,j+1} - \\sum_{i=0}^{|\\mathcal{V}|} \\lambda_i\\left( \\sum_{j=0}^{|\\mathcal{V}|} \\theta_{i,j+1} -1\\right),$$\n",
    "\n",
    "where again, we can decompose $\\mathcal{G}$ function into $n$ concave function, and the corresponding optimal solution $\\mathbf{\\theta}_0^*,\\ldots, {\\mathbf{\\theta}}_{|\\mathcal{V}|}^*$ are obtained by letting the gradient of $\\theta_{i,j+1}$ be 0:\n",
    "\n",
    "$$\\frac{\\partial \\mathcal{L}}{\\partial \\theta_{i,j+1}} = \\frac{C(v_i, v_{j+1})}{ \\theta_{i,j+1}} - \\lambda_i=0 \\quad\\Rightarrow\\quad\n",
    "\\theta_{i,j+1}^* = \\frac{C(v_i, v_{j+1})}{\\lambda_i}.$$\n",
    "\n",
    "To compute $\\lambda_i$, note that $\\sum_{j=0}^{|\\mathcal{V}|} \\theta_{i,j+1} =1$, we have\n",
    "\n",
    "$$\\sum_{j=0}^{|\\mathcal{V}|} \\theta_{i,j+1} = \\sum_{j=0}^{|\\mathcal{V}|}  \\frac{C(v_i, v_{j+1})}{\\lambda_i} = \\frac{\\sum_{j=0}^{|\\mathcal{V}|} C(v_i, v_{j+1})}{\\lambda_i}=1 \\quad \\Rightarrow \\quad \\lambda_i = \\sum_{j=0}^{|\\mathcal{V}|} C(v_i, v_{j+1}).$$\n",
    "\n",
    "Hence, we plug $\\lambda_i$ into the solution, we obtain\n",
    "\n",
    "$$\\theta_{i,j+1}^* = q(v_{j+1} \\mid v_i) = \\frac{C(v_i, v_{j+1})}{\\sum_{j=0}^{|\\mathcal{V}|} C(v_i, v_{j+1})}.$$\n",
    "\n",
    "For the trigram model and beyond, the MLE of the estimate $q\\left(x_N \\mid x_{1:N-1}\\right)$ is given by\n",
    "\n",
    "$$q\\left(x_N \\mid x_{1: N-1}\\right) = \\frac{C(x_{1:N})}{C(x_{1: N-1})}.$$\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b828d22-ed23-4836-bce3-d07996d1434d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<a id=\"25\"></a>\n",
    "### 2.5 Smoothing for $N$-gram LMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb89b92b-a943-488e-960e-1065c8ee5b0b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<div style=\"\n",
    "  background: rgba(0,0,0,0.05);\n",
    "  border: 0px solid rgba(0,0,0,0.1);\n",
    "  border-radius: 6px;\n",
    "  padding: 15px 15px;\n",
    "  line-height: 1.2;\n",
    "\">\n",
    "\n",
    "$N$-gram models usually have sparsity issues. For example, after observing all trigrams (i.e., consecutive word triplets) in 38 million words' worth of newspaper articles, a third of trigrams in new articles from the same source are novel. Furthermore, even among the observed trigrams, the vast majority occurred only once, and the majority of the rest had similarly low counts.\n",
    "\n",
    "Therefore, straightforward MLE of $N$-gram probabilities from counts is not advisable. Instead, various smoothing techniques have been developed. These include discounting MLE, recursively backing off to lower order $N$-grams, and linearly interpolating $N$-grams of different order.\n",
    "\n",
    "To keep a language model from assigning zero probability to these unseen events, we will have to shave off a bit of probability mass from some more frequent events and give it to the events we have never seen. The following gives you some smoothing techniques to avoid probability zero.\n",
    "\n",
    "- **Additive smoothing.** To avoid zero probabilities, we pretend that each $N$-gram occurs slightly more often than it does: we add a factor $\\delta$ to every count, where typically $0<\\delta \\leq 1$. Thus, we set\n",
    "\n",
    "$$q_{\\text{Add}}(x_N \\mid x_{1:N-1}) = \\frac{\\delta+C(x_{1:N})}{\\delta(|\\mathcal{V}|+1)+\\sum_{x_N\\in \\mathcal{V} \\cup \\text{EOS} } C(x_{1:N})}.$$\n",
    "\n",
    "The simplest smoothing method above is adding one smoothing ($\\delta = 1$) to all the $N$-gram counts. Since there are $|\\mathcal{V}|$ words in the vocabulary, and each one was incremented, we also need to adjust the denominator to account for the extra $|\\mathcal{V}|$ observations.\n",
    "\n",
    "- **Linear interpolation.** By contrast, in the linear interpolation, we always mix the probability estimates from all the $N$-gram estimators, weighting and combining the trigram, bigram, and unigram counts. For example, consider the trigram model; the linear interpolation gives\n",
    "\n",
    "$$q_{\\text{Int}}(x_3 \\mid x_{1:2})= \\lambda_1 \\cdot q_{\\text{ML}}(x_3) + \\lambda_2 \\cdot q_{\\text{ML}}(x_3 \\mid x_{2}) + \\lambda_3 \\cdot q_{\\text{ML}}\\left(x_3 \\mid x_{1:2}\\right),$$\n",
    "\n",
    "where $\\lambda_1, \\lambda_2$, and $\\lambda_3$ are parameters such that $\\sum_{i=1}^3 \\lambda_i=1$ which are learned from validation text. Furthermore, $q_{\\text{ML}}(x_3 \\mid x_1, x_2) = \\frac{C(x_{1:3})}{C(x_{1:2})} , q_\\text{ML}(x_3 \\mid x_2) =\\frac{C(x_{2:3})}{C(x_2)}, q_{\\text{ML}}(x_3) = \\frac{C(x_3)}{ \\sum_{i=1}^T t_i}$. One extension to the method, often referred to as *bucketing*, is a much simpler method defined as\n",
    "\n",
    "$$\\begin{aligned}\n",
    "& \\lambda_1=\\frac{C(x_{1:2})}{C(x_{1:2})+\\gamma}, \\quad \\lambda_2=\\left(1-\\lambda_1\\right) \\times \\frac{C(x_2)}{C(x_2)+\\gamma}, \\quad \\lambda_3=1-\\lambda_1-\\lambda_2,\n",
    "\\end{aligned}$$\n",
    "\n",
    "where $\\gamma>0$ is the only parameter. One can verify that $\\lambda_i$ are positive and $\\lambda_1 + \\lambda_2 + \\lambda_3=1$.\n",
    "\n",
    "- **Katz Back-off (discounting).** The back-off smoothing strategy is recursively defined. We first consider the bigram model where, for any $x_1$, define the sets\n",
    "\n",
    "$$\\mathcal{A}(x_1)=\\{x_2: C(x_1 x_2)>0\\}, \\quad \\text{ and } \\quad \\mathcal{B}(x_1)=\\{x_2: C(x_1 x_2)=0\\}.$$\n",
    "\n",
    "Then, the estimate is defined as\n",
    "\n",
    "$$q_{\\text{Katz}}(x_2 \\mid x_1)= \\begin{cases}\\frac{C^*(x_1, x_2)}{C(x_1)} & \\text { If } x_2 \\in \\mathcal{A}(x_1) \\\\ \\alpha(x_1) \\cdot \\frac{q_{\\text{ML}}(x_2)}{\\sum_{x_2 \\in \\mathcal{B}(x_1)} q_{\\text{ML}}(x_2)} & \\text { If } x_2 \\in \\mathcal{B}(x_1)\\end{cases},$$\n",
    "\n",
    "where $C^*$ is the discounted count. For any bigram $C(x_1, x_2)$ such that $C(x_1, x_2)>0$, we define the discounted count as\n",
    "\n",
    "$$C^*(x_1, x_2)=C(x_1, x_2)-\\beta,$$\n",
    "\n",
    "where $\\beta\\in [0,1]$ (a typical value might be $\\beta=0.5$ ). Thus, we simply subtract a constant value, $\\beta$, from the count. This reflects the intuition that if we take counts from the training corpus, we will systematically over-estimate the probability of bigrams seen in the corpus (and under-estimate bigrams not seen in the corpus). In other words, if $C(x_1,x_2)>0$, we return the estimate $C^*(x_1,x_2) / C(x_1)$; otherwise, we divide the remaining probability mass $\\alpha(x_1)$ in proportion to the unigram estimates $q_{\\text{ML}}(x_2)$. The method can be generalized to trigram language models in a natural way: for any bigram $(u, v)$ define\n",
    "\n",
    "$$\\mathcal{A}(u, v)=\\{w: c(u, v, w)>0\\}, \\quad \\text{ and } \\mathcal{B}(u, v)=\\{w: c(u, v, w)=0\\}.$$\n",
    "\n",
    "Define $C^*(u, v, w)$ to be the discounted count for the trigram $(u, v, w)$ : that is, $C^*(u, v, w)=C(u, v, w)-\\beta$ where $\\beta$ is again the discounted value. Then, the trigram model is\n",
    "\n",
    "$$q_{\\text{Katz}} (w \\mid u, v)= \\begin{cases}\\frac{C^*(u, v, w)}{C(u, v)} & \\text { If } w \\in \\mathcal{A}(u, v) \\\\ \\alpha(u, v) \\times \\frac{q_{ \\text{Katz} }(w \\mid v)}{\\sum_{w \\in \\mathcal{B}(u, v)} q_{\\text{Katz}}(w \\mid v)} & \\text { If } w \\in \\mathcal{B}(u, v)\\end{cases},$$\n",
    "\n",
    "where $\\alpha(u, v)=1-\\sum_{w \\in \\mathcal{A}(u, v)} \\frac{C^*(u, v, w)}{C(u, v)}$ is again the \"missing\" probability mass. Note that we have divided the missing probability mass in proportion to the bigram estimates $q_{\\text{Katz}}(w \\mid v)$, which were defined previously.\n",
    "\n",
    "- **Kneser-Ney Smoothing.** Given the discount parameter $\\delta$ with $0 \\leq \\delta \\leq 1$, the Kneser-Ney smoothing for bigram model is\n",
    "\n",
    "$$q_{\\text{KN}}\\left(x_2 \\mid x_1 \\right)=\\frac{\\max \\left\\{C\\left(x_1 x_2\\right) - \\delta, 0\\right\\}}{ \\sum_{x \\in \\mathcal{V} \\cup \\text{EOS}} C(x_1 x)} + \\lambda_{x_1} \\cdot q_{\\text{KN}}\\left(x_2\\right)$$\n",
    "\n",
    "where the unigram probability $q_{\\text{KN}}\\left(x_2\\right)$ depends on how likely it is to see the word $x_2$ in an unfamiliar context, which is estimated as the number of times it appears after any other word divided by the number of distinct pairs of consecutive words in the corpus:\n",
    "\n",
    "$$q_{\\text{KN}}\\left(x_2\\right) =\\frac{|\\{x: C(x x_2)>0\\}|}{\\left|\\left\\{(x_1,x_2): C\\left(x_1x_2\\right)>0\\right\\}\\right|}.$$\n",
    "\n",
    "The parameter $\\lambda_{x_1}$ can be calculated as\n",
    "\n",
    "$$\\lambda_{x_1} = \\frac{\\delta \\cdot \\left|\\left\\{w: C\\left(x_1 w\\right)>0\\right\\}\\right|}{\\sum_v C\\left(x_1 v\\right)}.$$\n",
    "\n",
    "Just like Katz smoothing, we can extend KN smoothing to $N$-gram as follows\n",
    "\n",
    "$$q_{\\text{KN}}(x_N \\mid x_{1:N-1}) = \\frac{\\max \\left\\{C(x_{1:N})-\\delta, 0\\right\\}}{\\sum_{x \\in \\mathcal{V}\\cup \\text{EOS} } C\\left(x_{1:N-1} x\\right)}+\\lambda_{x_{1:N-1}} q_{\\text{KN}}\\left(x_N \\mid x_{1:N-1}\\right),$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\\lambda_{1:N-1} = \\frac{ \\delta\\cdot \\left|\\left\\{x: C(x_{1:N-1} x) > 0 \\right\\}\\right|}{\\sum_{x \\in \\mathcal{V} \\cup \\text{EOS} } C\\left(x_{1:N-1} x\\right)}.$$\n",
    "\n",
    "A modified Kneser-Ney smoothing is implemented in [kenlm](https://github.com/kpu/kenlm).\n",
    "\n",
    "- **Stupid Back-off.** Back-off without discounting (not a true probability) is defined as\n",
    "\n",
    "$$\\begin{aligned}\n",
    "S\\left(x_N \\mid x_{1:N-1}\\right) &= \\left\\{\\begin{array}{c}\n",
    "\\frac{C(x_{1:N})}{C(x_{1:N-1})} \\quad\\quad\\quad\\quad\\quad \\text { if } C(x_{1:N})>0 \\\\\n",
    "0.4 \\cdot S(x_N \\mid x_{2:N-1}) \\quad \\text { otherwise }\n",
    "\\end{array}\\right. \\\\\n",
    "S\\left(x_N\\right) &= \\frac{C(x_N)}{T},\n",
    "\\end{aligned}$$\n",
    "\n",
    "where $T$ is the size of the total training corpus.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644a2f26-9131-4fc5-821c-7cf0c8f0ee83",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<a id=\"26\"></a>\n",
    "### 2.6 Evaluating ngram LMs via perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d5168a-abf5-4749-af89-d9ca19f33d2b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<div style=\"\n",
    "  background: rgba(0,0,0,0.05);\n",
    "  border: 0px solid rgba(0,0,0,0.1);\n",
    "  border-radius: 6px;\n",
    "  padding: 15px 15px;\n",
    "  line-height: 1.2;\n",
    "\">\n",
    "\n",
    "Assume we have some test data sentences (examples of new, unseen sentences) $s_1, s_2, \\ldots s_m$. Each $s_i:= w_{1:t_i}^{(i)}$. Since a good model should \"predict\" these real-world sentences well, the total probability assigned to these testing sentences should be high. So, the intuition is that the higher the probability assigned, the better the language model is at modeling unseen sentences. For any $s_i$, we can measure its probability $p\\left(s_i\\right)$ under the language model. A natural measure of the quality of the language model would be the probability it assigns to the entire set of test sentences, that is\n",
    "\n",
    "$$\\prod_{i=1}^m p\\left(s_i\\right)$$\n",
    "\n",
    "The perplexity on $s_{1:m}$ is derived as a direct transformation of this quantity. Define $M := \\sum_{i=1}^m t_i$ to be the total number of words in the test corpus. Then the average log probability under the model is defined as\n",
    "\n",
    "$$\\frac{1}{\\sum_{i=1}^m |s_i|} \\log_2 \\prod_{i=1}^m p\\left(s_i\\right)=\\frac{1}{\\sum_{i=1}^m |s_i|} \\sum_{i=1}^m \\log_2 p\\left(s_i\\right).$$\n",
    "\n",
    "This is just the log probability of the entire test corpus divided by the total number of words in $s_{1:m}$. Again, the higher this quantity is, the better the language model. The perplexity is then defined as\n",
    "\n",
    "$$\\operatorname{PPL}(s_{1:m}) := 2^{-l}, \\quad \\text{ where } l=\\frac{1}{\\sum_{i=1}^m |s_i|} \\sum_{i=1}^m \\log_2 p\\left(s_i\\right).$$\n",
    "\n",
    "Thus, we take the negative of the average log probability and raise it to power two. The perplexity is a positive number. The smaller the perplexity value, the better LM is at modeling unseen data. We can understand the quantity of perplexity as: \"*If we randomly picked words from the probability distribution calculated by the language model at each time step, on average, how many words would it have to pick to get the correct one?*\" (Neubig, 2017, Page 9). For example, if we assume the language model is the uni-gram model and take all words that occurred in the training set with equal probability, then, for the testing sequence $s_{1:m}$, $\\operatorname{PPL}(s_{1:m}) = p(s_{1:m})^{-1/M} = (1/|\\mathcal{V}|)^{M\\cdot (-1/M)} = |\\mathcal{V}|$. On average, we have to pick $|\\mathcal{V}|$ words to get the correct one. It is true because every word occurs with equal probability. For another example, if $|\\mathcal{V}|=1,000,000$ and there is a good language model with perplexity $\\operatorname{PPL}(s_{1:m})=30$, we must pick about 30 words to get the \"correct\" one.\n",
    "</div>\n",
    "\n",
    "<details>\n",
    "    <summary style=\"cursor:pointer; font-weight:700; font-size: 18px;\">\n",
    "        Click to expand: Entropy and cross-entropy\n",
    "    </summary>\n",
    "\n",
    "<div style=\"\n",
    "  background: rgba(0,0,0,0.05);\n",
    "  border: 0px solid rgba(0,0,0,0.1);\n",
    "  border-radius: 6px;\n",
    "  padding: 15px 15px;\n",
    "  line-height: 1.2;\n",
    "\">\n",
    "    \n",
    "**Entropy and cross-entropy:** What is the relation between perplexity and entropy? The perplexity essentially measures the entropy of a language model. Another way to understand the perplexity is to see its relationship to cross-entropy. Given a discrete random variable $X$, with possible outcomes $x_1,\\ldots, x_n$, which occur with probability $p(x_1), \\ldots, p( x_n)$, the *entropy* of $X$ is defined as\n",
    "\n",
    "$$H(p) \\triangleq - \\sum_{i=1}^n p( x_i) \\cdot\\log p(x_i).$$\n",
    "\n",
    "The *cross-entropy* of the distribution $q$ relative to a distribution $p$ over a given set is defined as $H(p,q)=- \\mathbb{E}_{p}[\\log q]$ where $\\mathbb{E}_{p}[\\cdot]$ is the expectation with respect to $p$. We assume two distribution $p$ and $q$ are discrete and take outcomes $x_i$ from $\\mathcal{X}$, we have\n",
    "\n",
    "$$H(p, q) = - \\sum_{x_i \\in \\mathcal{X}} p(x_i) \\log q(x_i).$$\n",
    "\n",
    "In the language model, we want to estimate the true distribution $p$ of words in any corpus, and $q$ is the distribution we estimated from a training corpus. To evaluate $p$, we may want to see its entropy $H(p)$ but we cannot directly calculate $H(p)$ or $H(p,q)$ since we do not know the true distribution $p$. However, we know an estimation of $p$, which is $q$ learned from a training corpus. The key idea of measuring $H(p)$ is that we can find an estimation of $H(p)$ based on $q$. To make this idea more specific, again, we assume two distributions $p$ and $q$ are discrete and take outcomes $x_i$ from the space $\\mathcal{X}$, we have\n",
    "\n",
    "$$\\begin{align}\n",
    "H(p, q) = - \\sum_{x_i \\in \\mathcal{X}} p(x_i) \\log q(x_i) &= - \\sum_{x_i \\in \\mathcal{X}} p(x_i) \\left( \\log p(x_i) + \\log q(x_i) - \\log p(x_i) \\right) \\\\\n",
    "&= H(p) + \\underbrace{\\sum_{x_i \\in \\mathcal{X}} p(x_i) \\left(\\log p(x_i) - \\log q(x_i)\\right)}_{D_{\\operatorname{KL}(p\\| q)} \\geq 0} \\geq H(p),\n",
    "\\end{align}$$\n",
    "\n",
    "where the last inequality from the fact that the Kullback-Leibler (KL) divergence of $p$ and $q$ (also called relative entropy) measures the relative information gain if $p$ would be used instead of $q$ which is currently used. Notice that the KL divergence is always non-negative, i.e. $D_{\\operatorname{KL}}(p || q) \\geq 0$. One can use the Gibbs' inequality, i.e., $\\sum _{i=1}^{n}p_{i}\\log p_{i} \\geq \\sum _{i=1}^{n}p_{i}\\log q_{i}$ to verify this (Try use trick, $\\log x \\leq x - 1$, then we have $\\log(q_i/p_i) \\leq q_i / p_i - 1$. Sum it over $i$, we will reach  this inequality.).\n",
    "\n",
    "From the above inequality, we see that $H(p,q)$ is an upper bound of $H(p)$ and if $q$ is closer to $p$, then $H(p,q)$ is closer to $H(p)$. The equality holds if and only if $p = q$. Now, by Shannon-McMillan-Breiman theorem as shown in Equ. (3.49) of Page 53 (Jurafsky, 2022), we have the following approximation of $H(p,q)$\n",
    "\n",
    "$$H(p) \\leq  H(p,q) = \\lim_{n\\rightarrow \\infty} -\\frac{1}{n} \\log q(w_{1:n})   \\approx H(s_{1:m}) \\triangleq -\\frac{1}{|s_{1:m}|} \\log p(s_{1:m}).$$\n",
    "\n",
    "This equation captures the whole point of perplexity: Our original goal is to calculate the true entropy of an unknown language model $p$, which is impossible to calculate. Instead, we use $-\\frac{1}{n} \\log q(w_1 w_2,\\ldots,w_n)$, a reasonable approximation, to estimate the true entropy. Finally, the perplexity of a language model $p$ on the test sequence $W$ is just the exponential of the approximation $H(W)$ we found in the above equation, that is\n",
    "\n",
    "$$\\text{PPL}(s_{1:m}) = 2^{- \\frac{1}{|s_{1:m}|} \\log_2 p(s_{1:m})} = 2^{H(s_{1:m})}.$$\n",
    "\n",
    "There is no particular reason to use the exponential form, except that it makes the numbers more distinguishable, making perplexity more sensitive than $H(W)$ (Note that $H(W)$ is an approximation, not the true entropy.). Perplexity is just one evaluation metric for language models. For example, Meister et al. (2021) proposed an alternative approach to evaluate language models. You can find more related papers if you're interested. In general, perplexity has the following advantages: 1) Perplexity scores are easier to understand and remember than entropy values. For instance, a perplexity range of 100-200 is more intuitive than entropy values like 6.64 to 7.64 bits; 2) A 10% improvement in perplexity feels more significant than a 2% reduction in entropy, even if they represent similar improvements; 3) Perplexity can be directly computed using held-out or test data, making it a straightforward metric for model performance and lower perplexity indicates a model closer to the \"true\" model that could generate the observed data.\n",
    "\n",
    "The main component of the $N$-gram model has been used in the first generation of Google Translate (Brants et al., 2007). However, a word $N$-gram language model is a purely statistical language model. It has been superseded by RNN-based models, which large language models (LLMs) have superseded. The notes provided are extensively revised or expanded for a personal understanding based on the original content provided in references and notes therein.\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "dc13d0cf-e0be-4b4f-afdf-0b2a08e7e9b4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 3000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import re\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "ds = load_dataset(\"IsaacDev/sentiment-labelled-sentences\")\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "720f2284-13bd-4add-9389-6793f488d4d6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['So there is no way for me to plug it in here in the US unless I go by a converter.\\t0',\n",
       "  'Good case, Excellent value.\\t1',\n",
       "  'Great for the jawbone.\\t1',\n",
       "  'Tied to charger for conversations lasting more than 45 minutes.MAJOR PROBLEMS!!\\t0',\n",
       "  'The mic is great.\\t1',\n",
       "  'I have to jiggle the plug to get it to line up right to get decent volume.\\t0',\n",
       "  'If you have several dozen or several hundred contacts, then imagine the fun of sending each of them one by one.\\t0',\n",
       "  'If you are Razr owner...you must have this!\\t1',\n",
       "  'Needless to say, I wasted my money.\\t0',\n",
       "  'What a waste of money and time!.\\t0']}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "9ffbb5ba-6dac-4d9a-8084-88f3e078144b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split: train rows: 3000\n",
      "columns: ['text']\n",
      "using text column: text\n",
      "Vocab size: 5166\n",
      "Distinct bigrams: 22179\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>want</th>\n",
       "      <th>to</th>\n",
       "      <th>eat</th>\n",
       "      <th>in</th>\n",
       "      <th>this</th>\n",
       "      <th>place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>want</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eat</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>place</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       i  want  to  eat  in  this  place\n",
       "i      0     5   0    1   0     0      0\n",
       "want   0     0  11    0   0     0      0\n",
       "to     0     1   0   12   2     6      2\n",
       "eat    0     0   0    0   2     0      0\n",
       "in     0     0   3    0   0    24      2\n",
       "this   1     0   4    0   2     0     73\n",
       "place  2     0  10    0   3     0      0"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) pick a split (many HF datasets use \"train\")\n",
    "split_name = list(ds.keys())[0]\n",
    "d = ds[split_name]\n",
    "print(\"split:\", split_name, \"rows:\", len(d))\n",
    "print(\"columns:\", d.column_names)\n",
    "\n",
    "# 2) find the text column automatically\n",
    "text_col_candidates = [\"text\", \"sentence\", \"sent\", \"review\"]\n",
    "text_col = next((c for c in text_col_candidates if c in d.column_names), None)\n",
    "if text_col is None:\n",
    "    # fallback: choose the first string column\n",
    "    for c in d.column_names:\n",
    "        if isinstance(d[0][c], str):\n",
    "            text_col = c\n",
    "            break\n",
    "print(\"using text column:\", text_col)\n",
    "\n",
    "sentences = d[text_col]\n",
    "\n",
    "# --- Tokenization + bigram counting ---\n",
    "def tokenize_simple(text):\n",
    "    text = text.lower()\n",
    "    return re.findall(r\"[a-z]+(?:'[a-z]+)?\", text)\n",
    "\n",
    "def build_bigram_stats(sentences, add_bos_eos=True):\n",
    "    unigram = Counter()\n",
    "    bigram = Counter()\n",
    "    for s in sentences:\n",
    "        toks = tokenize_simple(s)\n",
    "        if add_bos_eos:\n",
    "            toks = [\"<BOS>\"] + toks + [\"<EOS>\"]\n",
    "        unigram.update(toks)\n",
    "        bigram.update(zip(toks[:-1], toks[1:]))\n",
    "    return unigram, bigram\n",
    "\n",
    "unigram_counts, bigram_counts = build_bigram_stats(sentences)\n",
    "\n",
    "print(\"Vocab size:\", len(unigram_counts))\n",
    "print(\"Distinct bigrams:\", len(bigram_counts))\n",
    "\n",
    "# --- Make a small bigram count table like your slide ---\n",
    "rows = [\"i\", \"want\", \"to\", \"eat\", \"in\", \"this\", \"place\"]\n",
    "cols = [\"i\", \"want\", \"to\", \"eat\", \"in\", \"this\", \"place\"]\n",
    "\n",
    "tbl = pd.DataFrame(\n",
    "    [[bigram_counts[(r, c)] for c in cols] for r in rows],\n",
    "    index=rows,\n",
    "    columns=cols\n",
    ")\n",
    "tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0c7633c4-7a11-4b1c-b0b1-a3e17a425c84",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<table class=\"dataframe bigram\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th></th>\\n      <th>i</th>\\n      <th>want</th>\\n      <th>to</th>\\n      <th>eat</th>\\n      <th>in</th>\\n      <th>this</th>\\n      <th>place</th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <th>i</th>\\n      <td>0</td>\\n      <td>5</td>\\n      <td>0</td>\\n      <td>1</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>0</td>\\n    </tr>\\n    <tr>\\n      <th>want</th>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>11</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>0</td>\\n    </tr>\\n    <tr>\\n      <th>to</th>\\n      <td>0</td>\\n      <td>1</td>\\n      <td>0</td>\\n      <td>12</td>\\n      <td>2</td>\\n      <td>6</td>\\n      <td>2</td>\\n    </tr>\\n    <tr>\\n      <th>eat</th>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>2</td>\\n      <td>0</td>\\n      <td>0</td>\\n    </tr>\\n    <tr>\\n      <th>in</th>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>3</td>\\n      <td>0</td>\\n      <td>0</td>\\n      <td>24</td>\\n      <td>2</td>\\n    </tr>\\n    <tr>\\n      <th>this</th>\\n      <td>1</td>\\n      <td>0</td>\\n      <td>4</td>\\n      <td>0</td>\\n      <td>2</td>\\n      <td>0</td>\\n      <td>73</td>\\n    </tr>\\n    <tr>\\n      <th>place</th>\\n      <td>2</td>\\n      <td>0</td>\\n      <td>10</td>\\n      <td>0</td>\\n      <td>3</td>\\n      <td>0</td>\\n      <td>0</td>\\n    </tr>\\n  </tbody>\\n</table>'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tbl is your DataFrame (the 7x7 bigram count table)\n",
    "html_tbl = tbl.to_html(classes=\"bigram\", border=0)\n",
    "html_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a41770-bca8-470f-8b5b-b72009268297",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe1872fc-d453-4737-a628-b298107287b0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<a id=\"3\"></a>\n",
    "## 3. Build an ngram LM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d85e982-e186-4672-9b4d-45bd9ad50bfd",
   "metadata": {},
   "source": [
    "Statistical language models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c157d837-eb12-4e53-85f3-5922ed955274",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662605a3-bb9f-47f4-98eb-2d54ed22c524",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<a id=\"31\"></a>\n",
    "### 3.1 Load wikitext-103"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668212af-9573-4ed0-a7a9-2fc9afc5019f",
   "metadata": {},
   "source": [
    "- **Load wikitext-103**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e77dbf58-a4f5-46f5-8326-0fefe45f1be1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exists, skip: .datasets/wikitext103_raw_train.txt\n",
      "Exists, skip: .datasets/wikitext103_raw_test.txt\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "from pathlib import Path\n",
    "from datasets import load_dataset\n",
    "\n",
    "wiki103_ds = load_dataset(\"Salesforce/wikitext\", \"wikitext-103-raw-v1\")\n",
    "\n",
    "out_dir = Path(\".datasets\") # ensure .datasets/ exists, it will not track by git\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "out_path_train = out_dir / \"wikitext103_raw_train.txt\"\n",
    "out_path_test  = out_dir / \"wikitext103_raw_test.txt\"\n",
    "\n",
    "if out_path_train.exists():\n",
    "    print(f\"Exists, skip: {out_path_train}\")\n",
    "else:\n",
    "    with io.open(out_path_train, \"w\", encoding=\"utf-8\") as f:\n",
    "        for ex in wiki103_ds[\"train\"]:\n",
    "            line = ex[\"text\"].replace(\"\\n\", \" \").strip()\n",
    "            if line:\n",
    "                f.write(line + \"\\n\")\n",
    "    print(\"Wrote:\", out_path_train)\n",
    "\n",
    "if out_path_test.exists():\n",
    "    print(f\"Exists, skip: {out_path_test}\")\n",
    "else:\n",
    "    with io.open(out_path_test, \"w\", encoding=\"utf-8\") as f:\n",
    "        for ex in wiki103_ds[\"test\"]:\n",
    "            line = ex[\"text\"].replace(\"\\n\", \" \").strip()\n",
    "            if line:\n",
    "                f.write(line + \"\\n\")\n",
    "    print(\"Wrote:\", out_path_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcbf7d5-c8c8-42c7-9431-6222e6c5d5b4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<a id=\"32\"></a>\n",
    "### 3.2 Sentence tokenization for wikitext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad367d84-990f-40f1-aea5-ca2cc0e54c0f",
   "metadata": {},
   "source": [
    "- **Do preprocessing for wikitext103 dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1caaeef-18b0-493e-a6b6-85d4aed00e31",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: .datasets/wikitext103_raw_train.sents.txt  (sentences: 3736492)\n",
      "Wrote: .datasets/wikitext103_raw_test.sents.txt  (sentences: 9214)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "\n",
    "# -------- config --------\n",
    "in_dir = Path(\".datasets\")\n",
    "in_train = in_dir / \"wikitext103_raw_train.txt\"\n",
    "in_test  = in_dir / \"wikitext103_raw_test.txt\"\n",
    "\n",
    "out_train = in_dir / \"wikitext103_raw_train.sents.txt\"\n",
    "out_test  = in_dir / \"wikitext103_raw_test.sents.txt\"\n",
    "\n",
    "MIN_WORDS = 5          # drop very short \"sentences\"\n",
    "NORMALIZE_WIKITEXT = True\n",
    "\n",
    "# -------- helpers --------\n",
    "_heading_re = re.compile(r\"^\\s*=+\\s*[^=].*?\\s*=+\\s*$\")\n",
    "\n",
    "def is_heading(line: str) -> bool:\n",
    "    \"\"\"True for lines like '= Title =' or '== Career =='.\"\"\"\n",
    "    s = line.strip()\n",
    "    if not s:\n",
    "        return True\n",
    "    if _heading_re.match(s) and not any(p in s for p in \".?!\"):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def normalize_wikitext(s: str) -> str:\n",
    "    # Common WikiText tokenization artifacts\n",
    "    s = re.sub(r\"\\s*@-@\\s*\", \"-\", s)\n",
    "    s = re.sub(r\"\\s*@,@\\s*\", \",\", s)\n",
    "    s = re.sub(r\"\\s*@\\.\\@\\s*\", \".\", s)\n",
    "    # collapse whitespace a bit (optional)\n",
    "    s = re.sub(r\"[ \\t]+\", \" \", s)\n",
    "    return s.strip()\n",
    "\n",
    "def keep_sentence(sent: str) -> bool:\n",
    "    sent = sent.strip()\n",
    "    if not sent:\n",
    "        return False\n",
    "    # must contain at least one letter\n",
    "    if not re.search(r\"[A-Za-z]\", sent):\n",
    "        return False\n",
    "    # drop ultra-short fragments\n",
    "    if len(sent.split()) < MIN_WORDS:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# -------- spaCy sentence splitter --------\n",
    "# Fast, no download:\n",
    "nlp = spacy.blank(\"en\")\n",
    "nlp.add_pipe(\"sentencizer\")  # rule-based sentence boundary detector\n",
    "\n",
    "def split_file_to_sentences(in_path: Path, out_path: Path, batch_size: int = 1024):\n",
    "    if out_path.exists():\n",
    "        print(f\"Exists, skip: {out_path}\")\n",
    "        return\n",
    "\n",
    "    # Stream input lines and prefilter headings\n",
    "    def gen_texts():\n",
    "        with in_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                line = line.rstrip(\"\\n\")\n",
    "                if is_heading(line):\n",
    "                    continue\n",
    "                if NORMALIZE_WIKITEXT:\n",
    "                    line = normalize_wikitext(line)\n",
    "                if line:\n",
    "                    yield line\n",
    "\n",
    "    written = 0\n",
    "    with out_path.open(\"w\", encoding=\"utf-8\") as out_f:\n",
    "        for doc in nlp.pipe(gen_texts(), batch_size=batch_size):\n",
    "            for s in doc.sents:\n",
    "                sent = s.text.strip()\n",
    "                if keep_sentence(sent):\n",
    "                    out_f.write(sent + \"\\n\")\n",
    "                    written += 1\n",
    "\n",
    "    print(f\"Wrote: {out_path}  (sentences: {written})\")\n",
    "\n",
    "split_file_to_sentences(in_train, out_train)\n",
    "split_file_to_sentences(in_test,  out_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddf6bc6-9406-464a-b49e-90c2fda5ce07",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- **Use BPE tokenization from tokenizers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2ed73bff-a683-4bc1-a27d-e10b494ecce5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "saved .datasets/wikitext103_bpe_tokenizer.json\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import BertPreTokenizer\n",
    "from tokenizers.normalizers import NFKC\n",
    "\n",
    "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "tokenizer.normalizer = NFKC()\n",
    "tokenizer.pre_tokenizer = BertPreTokenizer()  # splits words & punctuation\n",
    "\n",
    "trainer = BpeTrainer(\n",
    "    vocab_size=50_000,\n",
    "    min_frequency=5,\n",
    "    special_tokens=[\"[UNK]\"],\n",
    "    continuing_subword_prefix=\"##\"\n",
    ")\n",
    "\n",
    "tokenizer.train([\".datasets/wikitext103_raw_train.sents.txt\", \".datasets/wikitext103_raw_test.sents.txt\"], trainer)\n",
    "tokenizer.save(\".datasets/wikitext103_bpe_tokenizer.json\")\n",
    "print(\"saved .datasets/wikitext103_bpe_tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4b8cec2c-996c-4bfe-a68d-f17ba828d356",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: BPE\n",
      "Vocab size: 50000\n",
      "Normalizer: NFKC()\n",
      "PreTokenizer: BertPreTokenizer()\n",
      "PostProcessor: None\n",
      "Decoder: None\n",
      "[('چ', 799), ('Brue', 42969), ('##levard', 18559), ('Hunt', 19069), ('##부', 7197)]\n"
     ]
    }
   ],
   "source": [
    "tok = Tokenizer.from_file(\".datasets/wikitext103_bpe_tokenizer.json\")\n",
    "print(\"Model:\", type(tok.model).__name__)\n",
    "print(\"Vocab size:\", tok.get_vocab_size())\n",
    "print(\"Normalizer:\", tok.normalizer)\n",
    "print(\"PreTokenizer:\", tok.pre_tokenizer)\n",
    "print(\"PostProcessor:\", tok.post_processor)\n",
    "print(\"Decoder:\", tok.decoder)\n",
    "vocab = tok.get_vocab()\n",
    "print([_ for _ in vocab.items()][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1e1eb1-93c0-4993-a9a3-793bf47f8bfc",
   "metadata": {},
   "source": [
    "- **Encode into a KenLM corpus: space-separated BPE tokens**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "617e9aaf-4384-44ce-b71f-1c13ec04f757",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bpe_tokenize(in_path, out_path):\n",
    "    FORBIDDEN = {\"<s>\", \"</s>\", \"<unk>\"} # these tokens are not allowed in kenlm\n",
    "    REPLACE = {\"<s>\": \"[BOS]\", \"</s>\": \"[EOS]\", \"<unk>\": \"[UNK]\"}  # safe substitutes\n",
    "    with io.open(in_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as fin, \\\n",
    "         io.open(out_path, \"w\", encoding=\"utf-8\") as fout:\n",
    "        for line in fin:\n",
    "            line = line.rstrip(\"\\n\")\n",
    "            if not line.strip():\n",
    "                fout.write(\"\\n\")\n",
    "                continue\n",
    "            enc = tok.encode(line)\n",
    "            tokens = enc.tokens\n",
    "            tokens = [REPLACE.get(t, t) for t in tokens]\n",
    "            fout.write(\" \".join(tokens) + \"\\n\")\n",
    "    print(\"Wrote:\", out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "63770ed0-fd5a-4653-8d3b-55c98845de7c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: .datasets/wikitext103_raw_train_bpe-kenlm.txt\n",
      "Wrote: .datasets/wikitext103_raw_test_bpe-kenlm.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tok = Tokenizer.from_file(\".datasets/wikitext103_bpe_tokenizer.json\")\n",
    "\n",
    "bpe_tokenize(in_path= \".datasets/wikitext103_raw_train.sents.txt\", \n",
    "             out_path= \".datasets/wikitext103_raw_train_bpe-kenlm.txt\")\n",
    "bpe_tokenize(in_path= \".datasets/wikitext103_raw_test.sents.txt\", \n",
    "             out_path= \".datasets/wikitext103_raw_test_bpe-kenlm.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f462ef3-56df-47c6-b8e5-9fd3b7886474",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<a id=\"33\"></a>\n",
    "### 3.3 Training Ngram via kenlm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e59e5e-a30c-41dc-8175-004ed31f9501",
   "metadata": {},
   "source": [
    "- **Format and filter dataset into kenlm text corpus**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2e385e21-eacd-435c-97b0-3f3cb750828b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 1/5 Counting and sorting n-grams ===\n",
      "Reading fd 3\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Unigram tokens 107813323 types 48101\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\n",
      "Chain sizes: 1:577212 2:15461305344\n",
      "Statistics:\n",
      "1 48101 D1=0.520241 D2=0.97802 D3+=1.50632\n",
      "2 9335629 D1=0.655118 D2=1.10406 D3+=1.44016\n",
      "Memory estimate for binary LM:\n",
      "type     MB\n",
      "probing 161 assuming -p 1.5\n",
      "probing 161 assuming -r models -p 1.5\n",
      "trie     53 without quantization\n",
      "trie     27 assuming -q 8 -b 8 quantization \n",
      "trie     53 assuming -a 22 array pointer compression\n",
      "trie     27 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\n",
      "Chain sizes: 1:577212 2:149370064\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
      "Chain sizes: 1:577212 2:149370064\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 5/5 Writing ARPA model ===\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "lmplz\t3142221824\t28753920\tRSSMax:3142221824 kB\tuser:20.2686\tsys:76.8719\tCPU:97.1406\treal:108.933\n"
     ]
    }
   ],
   "source": [
    "!kenlm/build/bin/lmplz -o 2 --text .datasets/wikitext103_raw_train_bpe-kenlm.txt --arpa .datasets/wikitext103_o2.arpa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f42779-2925-41c2-8a05-e911a39949a6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- **Do the above similar for 3-gram and 4-gram:**\n",
    "\n",
    "```\n",
    "!kenlm/build/bin/lmplz -o 3 --text .datasets/wikitext103_raw_train_bpe-kenlm.txt --arpa .datasets/wikitext103_o3.arpa\n",
    "\n",
    "!kenlm/build/bin/lmplz -o 4 --text .datasets/wikitext103_raw_train_bpe-kenlm.txt --arpa .datasets/wikitext103_o4.arpa\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d4938d1a-799b-4392-8340-e84f83ce353c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 1/5 Counting and sorting n-grams ===\n",
      "Reading fd 3\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Unigram tokens 107813323 types 48101\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\n",
      "Chain sizes: 1:577212 2:5377845248 3:10083460096\n",
      "Statistics:\n",
      "1 48101 D1=0.520241 D2=0.97802 D3+=1.50632\n",
      "2 9335629 D1=0.707805 D2=1.08596 D3+=1.38749\n",
      "3 39219751 D1=0.752131 D2=1.17832 D3+=1.41921\n",
      "Memory estimate for binary LM:\n",
      "type     MB\n",
      "probing 888 assuming -p 1.5\n",
      "probing 941 assuming -r models -p 1.5\n",
      "trie    337 without quantization\n",
      "trie    177 assuming -q 8 -b 8 quantization \n",
      "trie    318 assuming -a 22 array pointer compression\n",
      "trie    158 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\n",
      "Chain sizes: 1:577212 2:149370064 3:784395020\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
      "Chain sizes: 1:577212 2:149370064 3:784395020\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 5/5 Writing ARPA model ===\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "lmplz\t3483664384\t25706496\tRSSMax:3483664384 kB\tuser:40.4522\tsys:127.512\tCPU:167.964\treal:186.928\n"
     ]
    }
   ],
   "source": [
    "!kenlm/build/bin/lmplz -o 3 --text .datasets/wikitext103_raw_train_bpe-kenlm.txt --arpa .datasets/wikitext103_o3.arpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "59414f2a-dbaf-40d9-aec6-6745952b1a1a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 1/5 Counting and sorting n-grams ===\n",
      "Reading fd 3\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Unigram tokens 107813323 types 48101\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\n",
      "Chain sizes: 1:577212 2:2631711488 3:4934458880 4:7895134720\n",
      "Statistics:\n",
      "1 48101 D1=0.520241 D2=0.97802 D3+=1.50632\n",
      "2 9335629 D1=0.707805 D2=1.08596 D3+=1.38749\n",
      "3 39219751 D1=0.813267 D2=1.14078 D3+=1.36901\n",
      "4 67746706 D1=0.828298 D2=1.2904 D3+=1.44729\n",
      "Memory estimate for binary LM:\n",
      "type      MB\n",
      "probing 2275 assuming -p 1.5\n",
      "probing 2553 assuming -r models -p 1.5\n",
      "trie     993 without quantization\n",
      "trie     535 assuming -q 8 -b 8 quantization \n",
      "trie     884 assuming -a 22 array pointer compression\n",
      "trie     426 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\n",
      "Chain sizes: 1:577212 2:149370064 3:784395020 4:1625920944\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
      "Chain sizes: 1:577212 2:149370064 3:784395020 4:1625920944\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 5/5 Writing ARPA model ===\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "lmplz\t3730571264\t2342912\tRSSMax:3730571264 kB\tuser:66.8132\tsys:127.819\tCPU:194.633\treal:205.122\n"
     ]
    }
   ],
   "source": [
    "!kenlm/build/bin/lmplz -o 4 --text .datasets/wikitext103_raw_train_bpe-kenlm.txt --arpa .datasets/wikitext103_o4.arpa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b98af2-2696-419e-ad64-2a808d8418a0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<a id=\"34\"></a>\n",
    "### 3.4 Calculate the perplexity on test sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12028485-8752-49d9-9572-8eba99187d4b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- **Calculate the perplexity of a testing sentences.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5bc4e66a-ab3b-4878-88e1-d35ce8358e7b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_perplexity(test_sents, model):\n",
    "    tokens = 0\n",
    "    sum_log10_prob = 0.\n",
    "    for sent in test_sents:\n",
    "        log10_prob = model.score(sent, bos=True, eos=True)\n",
    "        tokens += len(sent.split())  + 1 # 1 means </s>\n",
    "        sum_log10_prob += log10_prob\n",
    "    # Calculate the perplexity: 10 ** (-log10_prob / N)\n",
    "    perplexity = 10.0 ** (-sum_log10_prob/tokens)\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "60e15ac9-0fd9-495c-a22c-4c4b3be0e5cb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-12.193455696105957\n",
      "107.70667424947884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading /Users/baojianzhou/git/llm-26/lecture-02-ngram-lm/.datasets/wikitext103_o2.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "import kenlm\n",
    "\n",
    "bigram_model = kenlm.Model('.datasets/wikitext103_o2.arpa')\n",
    "print(bigram_model.score('this is a sentence .', bos = True, eos = True))\n",
    "print(calculate_perplexity(['this is a sentence .'], bigram_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1e3b5553-b7e4-45ec-afa2-5e9d4277a719",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518.8217323943094\n"
     ]
    }
   ],
   "source": [
    "with open('.datasets/wikitext103_raw_test.sents.txt', 'r') as f:\n",
    "    test_sents = f.readlines()\n",
    "print(calculate_perplexity(test_sents, bigram_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fc13fb82-68a2-48df-8687-1a41fbaca604",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading /Users/baojianzhou/git/llm-26/lecture-02-ngram-lm/.datasets/wikitext103_o2.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading /Users/baojianzhou/git/llm-26/lecture-02-ngram-lm/.datasets/wikitext103_o3.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading /Users/baojianzhou/git/llm-26/lecture-02-ngram-lm/.datasets/wikitext103_o4.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "gram2_model = kenlm.Model('.datasets/wikitext103_o2.arpa')\n",
    "gram3_model = kenlm.Model('.datasets/wikitext103_o3.arpa')\n",
    "gram4_model = kenlm.Model('.datasets/wikitext103_o4.arpa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "81fa1a71-602c-4672-aa78-2c0f35083a26",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-gram 518.8217323943094\n",
      "3-gram 347.7833272587721\n",
      "4-gram 302.26669688195517\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'perplexity')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"411.285625pt\" height=\"310.86825pt\" viewBox=\"0 0 411.285625 310.86825\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2026-01-10T23:34:18.488426</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.10.7, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 310.86825 \n",
       "L 411.285625 310.86825 \n",
       "L 411.285625 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 46.965625 273.312 \n",
       "L 404.085625 273.312 \n",
       "L 404.085625 7.2 \n",
       "L 46.965625 7.2 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path id=\"made3ccc6e5\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#made3ccc6e5\" x=\"63.198352\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 2.00 -->\n",
       "      <g transform=\"translate(52.06554 287.910437) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \n",
       "L 1344 794 \n",
       "L 1344 0 \n",
       "L 684 0 \n",
       "L 684 794 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(63.623047 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(95.410156 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(159.033203 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#made3ccc6e5\" x=\"103.78017\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 2.25 -->\n",
       "      <g transform=\"translate(92.647358 287.910437) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(63.623047 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" transform=\"translate(95.410156 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" transform=\"translate(159.033203 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#made3ccc6e5\" x=\"144.361989\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 2.50 -->\n",
       "      <g transform=\"translate(133.229176 287.910437) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(63.623047 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" transform=\"translate(95.410156 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(159.033203 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#made3ccc6e5\" x=\"184.943807\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 2.75 -->\n",
       "      <g transform=\"translate(173.810994 287.910437) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-37\" d=\"M 525 4666 \n",
       "L 3525 4666 \n",
       "L 3525 4397 \n",
       "L 1831 0 \n",
       "L 1172 0 \n",
       "L 2766 4134 \n",
       "L 525 4134 \n",
       "L 525 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(63.623047 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-37\" transform=\"translate(95.410156 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" transform=\"translate(159.033203 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#made3ccc6e5\" x=\"225.525625\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 3.00 -->\n",
       "      <g transform=\"translate(214.392813 287.910437) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \n",
       "Q 3050 2419 3304 2112 \n",
       "Q 3559 1806 3559 1356 \n",
       "Q 3559 666 3084 287 \n",
       "Q 2609 -91 1734 -91 \n",
       "Q 1441 -91 1130 -33 \n",
       "Q 819 25 488 141 \n",
       "L 488 750 \n",
       "Q 750 597 1062 519 \n",
       "Q 1375 441 1716 441 \n",
       "Q 2309 441 2620 675 \n",
       "Q 2931 909 2931 1356 \n",
       "Q 2931 1769 2642 2001 \n",
       "Q 2353 2234 1838 2234 \n",
       "L 1294 2234 \n",
       "L 1294 2753 \n",
       "L 1863 2753 \n",
       "Q 2328 2753 2575 2939 \n",
       "Q 2822 3125 2822 3475 \n",
       "Q 2822 3834 2567 4026 \n",
       "Q 2313 4219 1838 4219 \n",
       "Q 1578 4219 1281 4162 \n",
       "Q 984 4106 628 3988 \n",
       "L 628 4550 \n",
       "Q 988 4650 1302 4700 \n",
       "Q 1616 4750 1894 4750 \n",
       "Q 2613 4750 3031 4423 \n",
       "Q 3450 4097 3450 3541 \n",
       "Q 3450 3153 3228 2886 \n",
       "Q 3006 2619 2597 2516 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-33\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(63.623047 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(95.410156 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(159.033203 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#made3ccc6e5\" x=\"266.107443\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 3.25 -->\n",
       "      <g transform=\"translate(254.974631 287.910437) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-33\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(63.623047 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" transform=\"translate(95.410156 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" transform=\"translate(159.033203 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_7\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#made3ccc6e5\" x=\"306.689261\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 3.50 -->\n",
       "      <g transform=\"translate(295.556449 287.910437) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-33\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(63.623047 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" transform=\"translate(95.410156 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(159.033203 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_8\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#made3ccc6e5\" x=\"347.27108\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 3.75 -->\n",
       "      <g transform=\"translate(336.138267 287.910437) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-33\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(63.623047 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-37\" transform=\"translate(95.410156 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" transform=\"translate(159.033203 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_9\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#made3ccc6e5\" x=\"387.852898\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 4.00 -->\n",
       "      <g transform=\"translate(376.720085 287.910437) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \n",
       "L 825 1625 \n",
       "L 2419 1625 \n",
       "L 2419 4116 \n",
       "z\n",
       "M 2253 4666 \n",
       "L 3047 4666 \n",
       "L 3047 1625 \n",
       "L 3713 1625 \n",
       "L 3713 1100 \n",
       "L 3047 1100 \n",
       "L 3047 0 \n",
       "L 2419 0 \n",
       "L 2419 1100 \n",
       "L 313 1100 \n",
       "L 313 1709 \n",
       "L 2253 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(63.623047 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(95.410156 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(159.033203 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_10\">\n",
       "     <!-- N-gram -->\n",
       "     <g transform=\"translate(206.817031 301.588562) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-4e\" d=\"M 628 4666 \n",
       "L 1478 4666 \n",
       "L 3547 763 \n",
       "L 3547 4666 \n",
       "L 4159 4666 \n",
       "L 4159 0 \n",
       "L 3309 0 \n",
       "L 1241 3903 \n",
       "L 1241 0 \n",
       "L 628 0 \n",
       "L 628 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-2d\" d=\"M 313 2009 \n",
       "L 1997 2009 \n",
       "L 1997 1497 \n",
       "L 313 1497 \n",
       "L 313 2009 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-67\" d=\"M 2906 1791 \n",
       "Q 2906 2416 2648 2759 \n",
       "Q 2391 3103 1925 3103 \n",
       "Q 1463 3103 1205 2759 \n",
       "Q 947 2416 947 1791 \n",
       "Q 947 1169 1205 825 \n",
       "Q 1463 481 1925 481 \n",
       "Q 2391 481 2648 825 \n",
       "Q 2906 1169 2906 1791 \n",
       "z\n",
       "M 3481 434 \n",
       "Q 3481 -459 3084 -895 \n",
       "Q 2688 -1331 1869 -1331 \n",
       "Q 1566 -1331 1297 -1286 \n",
       "Q 1028 -1241 775 -1147 \n",
       "L 775 -588 \n",
       "Q 1028 -725 1275 -790 \n",
       "Q 1522 -856 1778 -856 \n",
       "Q 2344 -856 2625 -561 \n",
       "Q 2906 -266 2906 331 \n",
       "L 2906 616 \n",
       "Q 2728 306 2450 153 \n",
       "Q 2172 0 1784 0 \n",
       "Q 1141 0 747 490 \n",
       "Q 353 981 353 1791 \n",
       "Q 353 2603 747 3093 \n",
       "Q 1141 3584 1784 3584 \n",
       "Q 2172 3584 2450 3431 \n",
       "Q 2728 3278 2906 2969 \n",
       "L 2906 3500 \n",
       "L 3481 3500 \n",
       "L 3481 434 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \n",
       "Q 2534 3019 2420 3045 \n",
       "Q 2306 3072 2169 3072 \n",
       "Q 1681 3072 1420 2755 \n",
       "Q 1159 2438 1159 1844 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1341 3275 1631 3429 \n",
       "Q 1922 3584 2338 3584 \n",
       "Q 2397 3584 2469 3576 \n",
       "Q 2541 3569 2628 3553 \n",
       "L 2631 2963 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \n",
       "Q 1497 1759 1228 1600 \n",
       "Q 959 1441 959 1056 \n",
       "Q 959 750 1161 570 \n",
       "Q 1363 391 1709 391 \n",
       "Q 2188 391 2477 730 \n",
       "Q 2766 1069 2766 1631 \n",
       "L 2766 1759 \n",
       "L 2194 1759 \n",
       "z\n",
       "M 3341 1997 \n",
       "L 3341 0 \n",
       "L 2766 0 \n",
       "L 2766 531 \n",
       "Q 2569 213 2275 61 \n",
       "Q 1981 -91 1556 -91 \n",
       "Q 1019 -91 701 211 \n",
       "Q 384 513 384 1019 \n",
       "Q 384 1609 779 1909 \n",
       "Q 1175 2209 1959 2209 \n",
       "L 2766 2209 \n",
       "L 2766 2266 \n",
       "Q 2766 2663 2505 2880 \n",
       "Q 2244 3097 1772 3097 \n",
       "Q 1472 3097 1187 3025 \n",
       "Q 903 2953 641 2809 \n",
       "L 641 3341 \n",
       "Q 956 3463 1253 3523 \n",
       "Q 1550 3584 1831 3584 \n",
       "Q 2591 3584 2966 3190 \n",
       "Q 3341 2797 3341 1997 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6d\" d=\"M 3328 2828 \n",
       "Q 3544 3216 3844 3400 \n",
       "Q 4144 3584 4550 3584 \n",
       "Q 5097 3584 5394 3201 \n",
       "Q 5691 2819 5691 2113 \n",
       "L 5691 0 \n",
       "L 5113 0 \n",
       "L 5113 2094 \n",
       "Q 5113 2597 4934 2840 \n",
       "Q 4756 3084 4391 3084 \n",
       "Q 3944 3084 3684 2787 \n",
       "Q 3425 2491 3425 1978 \n",
       "L 3425 0 \n",
       "L 2847 0 \n",
       "L 2847 2094 \n",
       "Q 2847 2600 2669 2842 \n",
       "Q 2491 3084 2119 3084 \n",
       "Q 1678 3084 1418 2786 \n",
       "Q 1159 2488 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1356 3278 1631 3431 \n",
       "Q 1906 3584 2284 3584 \n",
       "Q 2666 3584 2933 3390 \n",
       "Q 3200 3197 3328 2828 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-4e\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-2d\" transform=\"translate(74.804688 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-67\" transform=\"translate(110.888672 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" transform=\"translate(174.365234 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(215.478516 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6d\" transform=\"translate(276.757812 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <defs>\n",
       "       <path id=\"mafbc463a97\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#mafbc463a97\" x=\"46.965625\" y=\"263.748194\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 300 -->\n",
       "      <g transform=\"translate(20.878125 267.547413) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-33\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(127.246094 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mafbc463a97\" x=\"46.965625\" y=\"207.891723\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 350 -->\n",
       "      <g transform=\"translate(20.878125 211.690942) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-33\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" transform=\"translate(63.623047 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(127.246094 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mafbc463a97\" x=\"46.965625\" y=\"152.035252\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 400 -->\n",
       "      <g transform=\"translate(20.878125 155.834471) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(127.246094 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mafbc463a97\" x=\"46.965625\" y=\"96.178782\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_14\">\n",
       "      <!-- 450 -->\n",
       "      <g transform=\"translate(20.878125 99.978) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" transform=\"translate(63.623047 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(127.246094 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_14\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mafbc463a97\" x=\"46.965625\" y=\"40.322311\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_15\">\n",
       "      <!-- 500 -->\n",
       "      <g transform=\"translate(20.878125 44.12153) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(127.246094 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_16\">\n",
       "     <!-- perplexity -->\n",
       "     <g transform=\"translate(14.798438 165.382562) rotate(-90) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \n",
       "L 1159 -1331 \n",
       "L 581 -1331 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2969 \n",
       "Q 1341 3281 1617 3432 \n",
       "Q 1894 3584 2278 3584 \n",
       "Q 2916 3584 3314 3078 \n",
       "Q 3713 2572 3713 1747 \n",
       "Q 3713 922 3314 415 \n",
       "Q 2916 -91 2278 -91 \n",
       "Q 1894 -91 1617 61 \n",
       "Q 1341 213 1159 525 \n",
       "z\n",
       "M 3116 1747 \n",
       "Q 3116 2381 2855 2742 \n",
       "Q 2594 3103 2138 3103 \n",
       "Q 1681 3103 1420 2742 \n",
       "Q 1159 2381 1159 1747 \n",
       "Q 1159 1113 1420 752 \n",
       "Q 1681 391 2138 391 \n",
       "Q 2594 391 2855 752 \n",
       "Q 3116 1113 3116 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
       "L 3597 1613 \n",
       "L 953 1613 \n",
       "Q 991 1019 1311 708 \n",
       "Q 1631 397 2203 397 \n",
       "Q 2534 397 2845 478 \n",
       "Q 3156 559 3463 722 \n",
       "L 3463 178 \n",
       "Q 3153 47 2828 -22 \n",
       "Q 2503 -91 2169 -91 \n",
       "Q 1331 -91 842 396 \n",
       "Q 353 884 353 1716 \n",
       "Q 353 2575 817 3079 \n",
       "Q 1281 3584 2069 3584 \n",
       "Q 2775 3584 3186 3129 \n",
       "Q 3597 2675 3597 1894 \n",
       "z\n",
       "M 3022 2063 \n",
       "Q 3016 2534 2758 2815 \n",
       "Q 2500 3097 2075 3097 \n",
       "Q 1594 3097 1305 2825 \n",
       "Q 1016 2553 972 2059 \n",
       "L 3022 2063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-78\" d=\"M 3513 3500 \n",
       "L 2247 1797 \n",
       "L 3578 0 \n",
       "L 2900 0 \n",
       "L 1881 1375 \n",
       "L 863 0 \n",
       "L 184 0 \n",
       "L 1544 1831 \n",
       "L 300 3500 \n",
       "L 978 3500 \n",
       "L 1906 2253 \n",
       "L 2834 3500 \n",
       "L 3513 3500 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \n",
       "L 1178 3500 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 3500 \n",
       "z\n",
       "M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 4134 \n",
       "L 603 4134 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \n",
       "L 1172 3500 \n",
       "L 2356 3500 \n",
       "L 2356 3053 \n",
       "L 1172 3053 \n",
       "L 1172 1153 \n",
       "Q 1172 725 1289 603 \n",
       "Q 1406 481 1766 481 \n",
       "L 2356 481 \n",
       "L 2356 0 \n",
       "L 1766 0 \n",
       "Q 1100 0 847 248 \n",
       "Q 594 497 594 1153 \n",
       "L 594 3053 \n",
       "L 172 3053 \n",
       "L 172 3500 \n",
       "L 594 3500 \n",
       "L 594 4494 \n",
       "L 1172 4494 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-79\" d=\"M 2059 -325 \n",
       "Q 1816 -950 1584 -1140 \n",
       "Q 1353 -1331 966 -1331 \n",
       "L 506 -1331 \n",
       "L 506 -850 \n",
       "L 844 -850 \n",
       "Q 1081 -850 1212 -737 \n",
       "Q 1344 -625 1503 -206 \n",
       "L 1606 56 \n",
       "L 191 3500 \n",
       "L 800 3500 \n",
       "L 1894 763 \n",
       "L 2988 3500 \n",
       "L 3597 3500 \n",
       "L 2059 -325 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-70\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(63.476562 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" transform=\"translate(125 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-70\" transform=\"translate(166.113281 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6c\" transform=\"translate(229.589844 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(257.373047 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-78\" transform=\"translate(317.146484 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" transform=\"translate(376.326172 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(404.109375 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-79\" transform=\"translate(443.318359 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_15\">\n",
       "    <path d=\"M 63.198352 19.296 \n",
       "L 225.525625 210.368033 \n",
       "L 387.852898 261.216 \n",
       "\" clip-path=\"url(#pa4ad7b897e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 46.965625 273.312 \n",
       "L 46.965625 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 404.085625 273.312 \n",
       "L 404.085625 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 46.965625 273.312 \n",
       "L 404.085625 273.312 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 46.965625 7.2 \n",
       "L 404.085625 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"pa4ad7b897e\">\n",
       "   <rect x=\"46.965625\" y=\"7.2\" width=\"357.12\" height=\"266.112\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "perplexity = []\n",
    "with open('.datasets/wikitext103_raw_test.sents.txt', 'r') as f:\n",
    "    test_sents = f.readlines()\n",
    "model_names = ['2-gram', '3-gram', '4-gram']\n",
    "for model, model_name in zip([gram2_model, gram3_model, gram4_model], model_names):\n",
    "    print(model_name, calculate_perplexity(test_sents, model))\n",
    "    perplexity.append(calculate_perplexity(test_sents, model))\n",
    "\n",
    "plt.plot([2, 3, 4],perplexity)\n",
    "plt.xlabel('N-gram')\n",
    "plt.ylabel('perplexity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4099a6ec-ca8d-44f6-930b-3855793f912a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<a id=\"35\"></a>\n",
    "### 3.5 Generate sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9f9742-7fd8-4a95-9d6d-5da0c30eaae0",
   "metadata": {},
   "source": [
    "- **Generate sentences from ngram LMs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e1eb6892-4103-4182-8a33-83d55309191c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def detok_wordpiece(sentence):\n",
    "    \"\"\"\n",
    "    Merge WordPiece tokens: 'play', '##ing' -> 'playing'\n",
    "    Keep punctuation tight-ish.\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    tokens = sentence.split(\" \")\n",
    "    for t in tokens:\n",
    "        if t.startswith(\"##\") and out:\n",
    "            out[-1] = out[-1] + t[2:]\n",
    "        else:\n",
    "            out.append(t)\n",
    "\n",
    "    text = \" \".join(out)\n",
    "\n",
    "    # optional cleanup rules (lightweight)\n",
    "    text = re.sub(r\"\\s+([.,!?;:%\\)\\]\\}])\", r\"\\1\", text)   # remove space before punctuation\n",
    "    text = re.sub(r\"([\\(\\[\\{])\\s+\", r\"\\1\", text)          # remove space after opening bracket\n",
    "    text = re.sub(r\"\\s+'\", \"'\", text)                     # space before apostrophe\n",
    "    text = re.sub(r\"``\\s*\", '\"', text)\n",
    "    text = re.sub(r\"\\s*''\", '\"', text)\n",
    "    return text\n",
    "    \n",
    "def ngram_generate(model, vocab, prompt, rand_seed, k, max_words):\n",
    "    random.seed(rand_seed)\n",
    "    sentence = ''\n",
    "    state_in, state_out = kenlm.State(), kenlm.State()\n",
    "    total_score = 0.0\n",
    "    model.BeginSentenceWrite(state_in)\n",
    "    selected_next_word = prompt\n",
    "    count = 0\n",
    "    while count < max_words:\n",
    "        sentence += ' ' + selected_next_word\n",
    "        sentence = sentence.strip()\n",
    "        total_score += model.BaseScore(state_in, sentence, state_out)\n",
    "        candidates = list((model.score(sentence + ' ' + next_word), next_word) for next_word in vocab)\n",
    "        top_words = sorted(candidates, key=lambda item: item[0], reverse=True)\n",
    "        selected_next_word = top_words[random.randint(0, k)][1]\n",
    "        state_in, state_out = state_out, state_in\n",
    "        count += 1\n",
    "    return detok_wordpiece(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8a411ae8-3270-4e80-85f8-b79c788df6ff",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "tok = Tokenizer.from_file(\".datasets/wikitext103_bpe_tokenizer.json\")\n",
    "vocab = tok.get_vocab()   # dict: token -> id\n",
    "print(len(vocab))\n",
    "vocab = set([_[0] for _ in vocab.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7ed2233f-20fa-48a8-ba90-0555dbb6024b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-gram:  He is] = Week 15 pm guitar parts = 36 yards? equation \" Donora? producer Dorney High Streets vocals spanning 13 pm that:. 09 ” / 4 [engineer! engineering design] − \"! ¡ (H2O mixing elements 99 goals during\n",
      "2-gram:  He is written – 07Faceo!. com named storms developed Batman War Machine; 55)] 3 − 36 oz –) 40 (46 [2 OT producer Frank — 42 rounds \" that the [0 percent grade I feel] production assistant head\n",
      "2-gram:  He is = \" that — ‌. 01; 33 ′ 50 percent \" Love — = (3264 Magazine: 10% share and piano solo recording labelmateus = 16 oz * 026 11 kg [t have to: 40. 088!\n",
      "----------------------------------------\n",
      "3-gram:  He is the angle bis: 23 women like “ that green crab.} 6 x OGames stated a new bass saxophone Award Association championships there and performer and judge. view this as) internal structure, guitar driven, piano works also helped transform Cá\n",
      "3-gram:  He is usually not badlands, producer Robert Kelly and producer, actor Taylor: 12 = b + 5 = | +! engineer,? x ∗ engineer * uk × 8: 25: 543 + ν; 2008 = 12 = ¡ / Lino\n",
      "3-gram:  He is first accompanied Louise Fletcher and Hens as CsSB1230 design for Ontario, engineering design!) or, or? 1 −; others including, Tokyo Express x. {x =. — China with: 42 Commando force – 2014 average student\n",
      "----------------------------------------\n",
      "4-gram:  He is later fired: 5381 ft 0? ([Heaton Vezo fishermen * COR, Indiana \"; Davies and episode 12 retired General Liarder newspaper called VX! −! 1 percent speak English as required 12, 1993 to\n",
      "4-gram:  He is currently impossible]; / 08)) \" = OGNSV) Squadron 3 Murray (editor at Dallas ranked: 4 horns play) that = 8 goals are simply * – 1862 a!.] Regiment # 40 guns) is present design\n",
      "4-gram:  He is shown that a jury masts replaced = {{α7 − 17 / E # 42 - 14 teams]] is actually informed Emperor Wu, 1993]: 24 January 1998 when crying;. (UF 2 built; production on; but both men\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "for n, model in zip([2, 3, 4], [gram2_model, gram3_model, gram4_model]):\n",
    "    for i in range(3):\n",
    "        sentence = ngram_generate(model, vocab, \"He is\", rand_seed=i*4 + n, k=50, max_words=50)\n",
    "        print(f'{n}-gram: ', sentence)\n",
    "    print('-'*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f77489-c70f-4e24-8568-3eff764fd5b3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<a id=\"4\"></a>\n",
    "## 4. Build a Neural Probabilistic Language Model (NPLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7503d139-7507-4f8b-a427-2fe31fce9a3d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### 4.1 backpropagation\n",
    "\n",
    "The following followed from Adnrej's [micrograd](https://github.com/karpathy/micrograd)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19e26813-04c6-46f5-8b92-f18222f294b3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return 3 * x ** 2. - 4. * x + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21b9b40a-b3a1-4044-b5df-2fe7fdfc907e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating f at x=3.0 : 20.0\n"
     ]
    }
   ],
   "source": [
    "x = 3.\n",
    "print(f\"evaluating f at x={x} : {f(x=x)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb72bc2f-01c1-4578-b400-4f85c71a0640",
   "metadata": {},
   "source": [
    "- **Draw the curve of f**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9906b383-0107-4094-997a-5e80db10fda5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1123b8530>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"397.6075pt\" height=\"297.190125pt\" viewBox=\"0 0 397.6075 297.190125\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2026-01-08T18:15:22.129646</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.10.7, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 297.190125 \n",
       "L 397.6075 297.190125 \n",
       "L 397.6075 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 33.2875 273.312 \n",
       "L 390.4075 273.312 \n",
       "L 390.4075 7.2 \n",
       "L 33.2875 7.2 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path id=\"m77158e535b\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m77158e535b\" x=\"82.818129\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- −4 -->\n",
       "      <g transform=\"translate(75.447036 287.910437) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-2212\" d=\"M 678 2272 \n",
       "L 4684 2272 \n",
       "L 4684 1741 \n",
       "L 678 1741 \n",
       "L 678 2272 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \n",
       "L 825 1625 \n",
       "L 2419 1625 \n",
       "L 2419 4116 \n",
       "z\n",
       "M 2253 4666 \n",
       "L 3047 4666 \n",
       "L 3047 1625 \n",
       "L 3713 1625 \n",
       "L 3713 1100 \n",
       "L 3047 1100 \n",
       "L 3047 0 \n",
       "L 2419 0 \n",
       "L 2419 1100 \n",
       "L 313 1100 \n",
       "L 313 1709 \n",
       "L 2253 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-34\" transform=\"translate(83.789062 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m77158e535b\" x=\"149.413934\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- −2 -->\n",
       "      <g transform=\"translate(142.04284 287.910437) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" transform=\"translate(83.789062 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m77158e535b\" x=\"216.009738\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(212.828488 287.910437) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m77158e535b\" x=\"282.605542\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 2 -->\n",
       "      <g transform=\"translate(279.424292 287.910437) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m77158e535b\" x=\"349.201346\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 4 -->\n",
       "      <g transform=\"translate(346.020096 287.910437) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <defs>\n",
       "       <path id=\"m584804a02f\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m584804a02f\" x=\"33.2875\" y=\"270.478349\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(19.925 274.277568) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m584804a02f\" x=\"33.2875\" y=\"220.241879\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 20 -->\n",
       "      <g transform=\"translate(13.5625 224.041098) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m584804a02f\" x=\"33.2875\" y=\"170.005409\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 40 -->\n",
       "      <g transform=\"translate(13.5625 173.804628) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m584804a02f\" x=\"33.2875\" y=\"119.76894\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 60 -->\n",
       "      <g transform=\"translate(13.5625 123.568158) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \n",
       "Q 1688 2584 1439 2293 \n",
       "Q 1191 2003 1191 1497 \n",
       "Q 1191 994 1439 701 \n",
       "Q 1688 409 2113 409 \n",
       "Q 2538 409 2786 701 \n",
       "Q 3034 994 3034 1497 \n",
       "Q 3034 2003 2786 2293 \n",
       "Q 2538 2584 2113 2584 \n",
       "z\n",
       "M 3366 4563 \n",
       "L 3366 3988 \n",
       "Q 3128 4100 2886 4159 \n",
       "Q 2644 4219 2406 4219 \n",
       "Q 1781 4219 1451 3797 \n",
       "Q 1122 3375 1075 2522 \n",
       "Q 1259 2794 1537 2939 \n",
       "Q 1816 3084 2150 3084 \n",
       "Q 2853 3084 3261 2657 \n",
       "Q 3669 2231 3669 1497 \n",
       "Q 3669 778 3244 343 \n",
       "Q 2819 -91 2113 -91 \n",
       "Q 1303 -91 875 529 \n",
       "Q 447 1150 447 2328 \n",
       "Q 447 3434 972 4092 \n",
       "Q 1497 4750 2381 4750 \n",
       "Q 2619 4750 2861 4703 \n",
       "Q 3103 4656 3366 4563 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-36\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m584804a02f\" x=\"33.2875\" y=\"69.53247\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 80 -->\n",
       "      <g transform=\"translate(13.5625 73.331689) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \n",
       "Q 1584 2216 1326 1975 \n",
       "Q 1069 1734 1069 1313 \n",
       "Q 1069 891 1326 650 \n",
       "Q 1584 409 2034 409 \n",
       "Q 2484 409 2743 651 \n",
       "Q 3003 894 3003 1313 \n",
       "Q 3003 1734 2745 1975 \n",
       "Q 2488 2216 2034 2216 \n",
       "z\n",
       "M 1403 2484 \n",
       "Q 997 2584 770 2862 \n",
       "Q 544 3141 544 3541 \n",
       "Q 544 4100 942 4425 \n",
       "Q 1341 4750 2034 4750 \n",
       "Q 2731 4750 3128 4425 \n",
       "Q 3525 4100 3525 3541 \n",
       "Q 3525 3141 3298 2862 \n",
       "Q 3072 2584 2669 2484 \n",
       "Q 3125 2378 3379 2068 \n",
       "Q 3634 1759 3634 1313 \n",
       "Q 3634 634 3220 271 \n",
       "Q 2806 -91 2034 -91 \n",
       "Q 1263 -91 848 271 \n",
       "Q 434 634 434 1313 \n",
       "Q 434 1759 690 2068 \n",
       "Q 947 2378 1403 2484 \n",
       "z\n",
       "M 1172 3481 \n",
       "Q 1172 3119 1398 2916 \n",
       "Q 1625 2713 2034 2713 \n",
       "Q 2441 2713 2670 2916 \n",
       "Q 2900 3119 2900 3481 \n",
       "Q 2900 3844 2670 4047 \n",
       "Q 2441 4250 2034 4250 \n",
       "Q 1625 4250 1398 4047 \n",
       "Q 1172 3844 1172 3481 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-38\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m584804a02f\" x=\"33.2875\" y=\"19.296\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 100 -->\n",
       "      <g transform=\"translate(7.2 23.095219) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(127.246094 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_12\">\n",
       "    <path d=\"M 49.520227 19.296 \n",
       "L 57.844703 40.175533 \n",
       "L 66.169178 60.113132 \n",
       "L 74.493654 79.108797 \n",
       "L 82.818129 97.162528 \n",
       "L 91.142605 114.274326 \n",
       "L 99.46708 130.444189 \n",
       "L 107.791556 145.672119 \n",
       "L 116.116031 159.958116 \n",
       "L 124.440507 173.302178 \n",
       "L 132.764983 185.704306 \n",
       "L 141.089458 197.164501 \n",
       "L 149.413934 207.682762 \n",
       "L 157.738409 217.259089 \n",
       "L 166.062885 225.893482 \n",
       "L 174.38736 233.585942 \n",
       "L 182.711836 240.336467 \n",
       "L 191.036311 246.145059 \n",
       "L 199.360787 251.011717 \n",
       "L 207.685262 254.936441 \n",
       "L 216.009738 257.919232 \n",
       "L 224.334213 259.960088 \n",
       "L 232.658689 261.059011 \n",
       "L 240.983164 261.216 \n",
       "L 249.30764 260.431055 \n",
       "L 257.632115 258.704177 \n",
       "L 265.956591 256.035364 \n",
       "L 274.281066 252.424618 \n",
       "L 282.605542 247.871938 \n",
       "L 290.930017 242.377324 \n",
       "L 299.254493 235.940776 \n",
       "L 307.578969 228.562295 \n",
       "L 315.903444 220.241879 \n",
       "L 324.22792 210.97953 \n",
       "L 332.552395 200.775247 \n",
       "L 340.876871 189.62903 \n",
       "L 349.201346 177.54088 \n",
       "L 357.525822 164.510796 \n",
       "L 365.850297 150.538777 \n",
       "L 374.174773 135.624825 \n",
       "\" clip-path=\"url(#p6111b404bd)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_13\">\n",
       "    <path d=\"M 238.208339 273.312 \n",
       "L 238.208339 7.2 \n",
       "\" clip-path=\"url(#p6111b404bd)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff0000; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 33.2875 273.312 \n",
       "L 33.2875 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 390.4075 273.312 \n",
       "L 390.4075 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 33.2875 273.312 \n",
       "L 390.4075 273.312 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 33.2875 7.2 \n",
       "L 390.4075 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 185.9575 70.5 \n",
       "L 379.9075 70.5 \n",
       "Q 382.9075 70.5 382.9075 67.5 \n",
       "L 382.9075 17.7 \n",
       "Q 382.9075 14.7 379.9075 14.7 \n",
       "L 185.9575 14.7 \n",
       "Q 182.9575 14.7 182.9575 17.7 \n",
       "L 182.9575 67.5 \n",
       "Q 182.9575 70.5 185.9575 70.5 \n",
       "z\n",
       "\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_14\">\n",
       "     <path d=\"M 188.9575 28.080469 \n",
       "L 203.9575 28.080469 \n",
       "L 218.9575 28.080469 \n",
       "\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_12\">\n",
       "     <!-- $f(x) = 3 \\cdot x^2 - 4 x + 5$ -->\n",
       "     <g transform=\"translate(230.9575 33.330469) scale(0.15 -0.15)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-Oblique-66\" d=\"M 3059 4863 \n",
       "L 2969 4384 \n",
       "L 2419 4384 \n",
       "Q 2106 4384 1964 4261 \n",
       "Q 1822 4138 1753 3809 \n",
       "L 1691 3500 \n",
       "L 2638 3500 \n",
       "L 2553 3053 \n",
       "L 1606 3053 \n",
       "L 1013 0 \n",
       "L 434 0 \n",
       "L 1031 3053 \n",
       "L 481 3053 \n",
       "L 563 3500 \n",
       "L 1113 3500 \n",
       "L 1159 3744 \n",
       "Q 1278 4363 1576 4613 \n",
       "Q 1875 4863 2516 4863 \n",
       "L 3059 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-28\" d=\"M 1984 4856 \n",
       "Q 1566 4138 1362 3434 \n",
       "Q 1159 2731 1159 2009 \n",
       "Q 1159 1288 1364 580 \n",
       "Q 1569 -128 1984 -844 \n",
       "L 1484 -844 \n",
       "Q 1016 -109 783 600 \n",
       "Q 550 1309 550 2009 \n",
       "Q 550 2706 781 3412 \n",
       "Q 1013 4119 1484 4856 \n",
       "L 1984 4856 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-Oblique-78\" d=\"M 3841 3500 \n",
       "L 2234 1784 \n",
       "L 3219 0 \n",
       "L 2559 0 \n",
       "L 1819 1388 \n",
       "L 531 0 \n",
       "L -166 0 \n",
       "L 1556 1844 \n",
       "L 641 3500 \n",
       "L 1300 3500 \n",
       "L 1972 2234 \n",
       "L 3144 3500 \n",
       "L 3841 3500 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-29\" d=\"M 513 4856 \n",
       "L 1013 4856 \n",
       "Q 1481 4119 1714 3412 \n",
       "Q 1947 2706 1947 2009 \n",
       "Q 1947 1309 1714 600 \n",
       "Q 1481 -109 1013 -844 \n",
       "L 513 -844 \n",
       "Q 928 -128 1133 580 \n",
       "Q 1338 1288 1338 2009 \n",
       "Q 1338 2731 1133 3434 \n",
       "Q 928 4138 513 4856 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-3d\" d=\"M 678 2906 \n",
       "L 4684 2906 \n",
       "L 4684 2381 \n",
       "L 678 2381 \n",
       "L 678 2906 \n",
       "z\n",
       "M 678 1631 \n",
       "L 4684 1631 \n",
       "L 4684 1100 \n",
       "L 678 1100 \n",
       "L 678 1631 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \n",
       "Q 3050 2419 3304 2112 \n",
       "Q 3559 1806 3559 1356 \n",
       "Q 3559 666 3084 287 \n",
       "Q 2609 -91 1734 -91 \n",
       "Q 1441 -91 1130 -33 \n",
       "Q 819 25 488 141 \n",
       "L 488 750 \n",
       "Q 750 597 1062 519 \n",
       "Q 1375 441 1716 441 \n",
       "Q 2309 441 2620 675 \n",
       "Q 2931 909 2931 1356 \n",
       "Q 2931 1769 2642 2001 \n",
       "Q 2353 2234 1838 2234 \n",
       "L 1294 2234 \n",
       "L 1294 2753 \n",
       "L 1863 2753 \n",
       "Q 2328 2753 2575 2939 \n",
       "Q 2822 3125 2822 3475 \n",
       "Q 2822 3834 2567 4026 \n",
       "Q 2313 4219 1838 4219 \n",
       "Q 1578 4219 1281 4162 \n",
       "Q 984 4106 628 3988 \n",
       "L 628 4550 \n",
       "Q 988 4650 1302 4700 \n",
       "Q 1616 4750 1894 4750 \n",
       "Q 2613 4750 3031 4423 \n",
       "Q 3450 4097 3450 3541 \n",
       "Q 3450 3153 3228 2886 \n",
       "Q 3006 2619 2597 2516 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-22c5\" d=\"M 684 2619 \n",
       "L 1344 2619 \n",
       "L 1344 1825 \n",
       "L 684 1825 \n",
       "L 684 2619 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-2b\" d=\"M 2944 4013 \n",
       "L 2944 2272 \n",
       "L 4684 2272 \n",
       "L 4684 1741 \n",
       "L 2944 1741 \n",
       "L 2944 0 \n",
       "L 2419 0 \n",
       "L 2419 1741 \n",
       "L 678 1741 \n",
       "L 678 2272 \n",
       "L 2419 2272 \n",
       "L 2419 4013 \n",
       "L 2944 4013 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-Oblique-66\" transform=\"translate(0 0.765625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-28\" transform=\"translate(35.205078 0.765625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-Oblique-78\" transform=\"translate(74.21875 0.765625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-29\" transform=\"translate(133.398438 0.765625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-3d\" transform=\"translate(191.894531 0.765625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-33\" transform=\"translate(295.166016 0.765625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-22c5\" transform=\"translate(378.271484 0.765625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-Oblique-78\" transform=\"translate(429.541016 0.765625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-32\" transform=\"translate(493.186849 39.046875) scale(0.7)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-2212\" transform=\"translate(559.939779 0.765625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-34\" transform=\"translate(663.211263 0.765625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-Oblique-78\" transform=\"translate(726.83431 0.765625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-2b\" transform=\"translate(805.496419 0.765625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-35\" transform=\"translate(908.767904 0.765625)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_15\">\n",
       "     <path d=\"M 188.9575 53.1 \n",
       "L 203.9575 53.1 \n",
       "L 218.9575 53.1 \n",
       "\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff0000; stroke-width: 1.5\"/>\n",
       "    </g>\n",
       "    <g id=\"text_13\">\n",
       "     <!-- $x = \\frac{2}{3}$ -->\n",
       "     <g transform=\"translate(230.9575 58.35) scale(0.15 -0.15)\">\n",
       "      <use xlink:href=\"#DejaVuSans-Oblique-78\" transform=\"translate(0 0.25)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-3d\" transform=\"translate(78.662109 0.25)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-32\" transform=\"translate(181.933594 44.046875) scale(0.7)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-33\" transform=\"translate(181.933594 -39.15625) scale(0.7)\"/>\n",
       "      <path d=\"M 181.933594 19.046875 \n",
       "L 181.933594 25.296875 \n",
       "L 226.469727 25.296875 \n",
       "L 226.469727 19.046875 \n",
       "L 181.933594 19.046875 \n",
       "z\n",
       "\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p6111b404bd\">\n",
       "   <rect x=\"33.2875\" y=\"7.2\" width=\"357.12\" height=\"266.112\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xs = np.arange(-5, 5, 0.25)\n",
    "ys = f(xs)\n",
    "plt.plot(xs, ys, label = r\"$f(x) = 3 \\cdot x^2 - 4 x + 5$\")\n",
    "plt.axvline(x=2/3, color='r', linestyle='--', label=r'$x = \\frac{2}{3}$')\n",
    "plt.legend(fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dcd840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c9f52bc-5464-4777-b202-22c66bdd2fe9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "- What is the devaritive of $f(x)$ at any point $x$. Recall that\n",
    "  $$\n",
    "  f^\\prime (x) = \\lim_{h\\rightarrow 0} \\frac{ f(x + h ) - f(x)}{h}.\n",
    "  $$\n",
    "  We can approximate $f^\\prime {x}$ by the following approximation:\n",
    "  $$\n",
    "  f^\\prime (x) \\approx \\frac{ f(x + \\delta_h ) - f(x)}{\\delta_h}, \\text{where } \\delta_h \\text{ is small.}\n",
    "  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "338dd1b9-c616-42ea-aede-50bd9abf5ef5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.999378523327323e-06"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = 0.000001\n",
    "x = 2 / 3\n",
    "(f(x + h) - f(x))/h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a668e754",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: Don't you love 🤗 Transformers? We sure do.\n",
      "\n",
      "Token IDs: [8161, 956, 499, 3021, 11410, 97, 245, 81632, 30, 1226, 2771, 656, 13]\n",
      "\n",
      "Token strings: ['Don', \"'t\", ' you', ' love', ' �', '�', '�', ' Transformers', '?', ' We', ' sure', ' do', '.']\n"
     ]
    }
   ],
   "source": [
    "# Tokenization visualization\n",
    "import tiktoken\n",
    "\n",
    "cl100k_tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "text = \"Don't you love 🤗 Transformers? We sure do.\"\n",
    "token_ids = cl100k_tokenizer.encode(text)\n",
    "token_strs = [cl100k_tokenizer.decode([tid]) for tid in token_ids]\n",
    "print(\"Original text:\", text)\n",
    "print(\"\\nToken IDs:\", token_ids)\n",
    "print(\"\\nToken strings:\", token_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf66ed63",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410e6374-7cdd-43c3-97a3-38b9fd220cb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d74037d8-558a-40af-8bc2-0b160f57f608",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "<a id=\"5\"></a>\n",
    "## 5. References and Missing Lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce1115f-9136-48d2-9e46-7312a2510291",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<a id=\"51\"></a>\n",
    "### 5.1 References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8fa448-19d7-4e57-8205-9813a90257c0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "- https://cs229.stanford.edu/lectures-spring2023/cs229-probability_review.pdf\n",
    "- https://cs229.stanford.edu/notes2022fall/main_notes.pdf\n",
    "- https://anoopsarkar.github.io/nlp-class/assets/slides/prob.pdf\n",
    "- https://www.cs.columbia.edu/~mcollins/courses/nlp2011/notes/lm.pdf\n",
    "- https://pages.cs.wisc.edu/~jerryzhu/cs838/LM.pdf\n",
    "- https://www3.nd.edu/~dchiang/teaching/nlp/2021/notes/chapter2v2.pdf\n",
    "- https://www.fit.vut.cz/study/phd-thesis-file/283/283.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e928130-2b4c-49b9-9922-7b15c4110485",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<a id=\"52\"></a>\n",
    "### 5.2 Missing lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d59516a-84aa-4e81-805c-2f2a4affd798",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<div style=\"\n",
    "  background: rgba(0,0,0,0.05);\n",
    "  border: 0px solid rgba(0,0,0,0.1);\n",
    "  border-radius: 6px;\n",
    "  padding: 15px 15px;\n",
    "  line-height: 1.2;\n",
    "\">\n",
    "\n",
    "Given a concave function $\\varphi: \\mathbb{R} \\rightarrow \\mathbb{R}$, and positive weights $a_{i}, i =1,2,\\ldots,n$, Jensen's inequality can be stated as: $\\varphi \\left(\\sum_{i=1}^n a_{i}x_{i} / \\sum_{i=1}^n a_{i}\\right) \\geq \\sum_{i=1}^n a_{i}\\varphi (x_{i}) / \\sum_{i=1}^n a_{i}$. That is, when $\\varphi$ is concave and $a_i = 1$\n",
    "\n",
    "$$n \\cdot \\varphi \\left(\\sum_{i=1}^n \\frac {x_{i}}{n} \\right) \\geq \\sum_{i=1}^n \\varphi (x_{i}).$$\n",
    "\n",
    "The following theorem states that when the probability distribution of random variable $X$ is uniform, the entropy of the random variable $X$ is maximized.\n",
    "\n",
    "> **Theorem (Maximal entropy)**  \n",
    "> Given a random variable $X$ and its probability distribution $p$, if $p$ is a uniform distribution, then the entropy of $X$ is maximized.\n",
    "\n",
    "**Proof:**  \n",
    "We can use Jensen's inequality to prove it. Let $\\varphi( y) = - y \\log (y)$ and we assume that $\\varphi(0) = 0$ (This assumption does make sense). Assume further that random variable $X$ has $n$ possible outcomes, i.e., $x_1,x_2,\\ldots, x_n$  with probability $p(x_1),p(x_2),\\ldots, p(x_n)$. Since $\\varphi(y)$ is concave on $[0,1]$ and $y_1 = p(x_1), y_2 = p(x_2),\\ldots, y_n = p(x_n)$ are points in $[0,1]$, we have\n",
    "\n",
    "$$\\begin{align*}\n",
    "n \\cdot \\varphi \\left(\\sum_{i=1}^n \\frac {y_{i}}{n} \\right) &\\geq \\sum_{i=1}^n \\varphi (y_{i}) \\\\    \n",
    "n \\cdot \\left( - \\sum_{i=1}^n \\frac {p(x_i)}{n}\\right) \\log \\left(\\sum_{i=1}^n \\frac { p(x_i)}{n}\\right) &\\geq -\\sum_{i=1}^n p(x_i) \\log p(x_i) \\\\\n",
    "n \\cdot \\left( - \\frac{1}{n} \\right) \\log \\left(\\frac{1}{n} \\right) &\\geq -\\sum_{i=1}^n p(x_i) \\log p(x_i) := H(p),\n",
    "\\end{align*}$$\n",
    "\n",
    "where the last inequality directly indicates $\\log(n) \\geq H(p)$. Clearly, the upper bound of the entropy $H(p)$ is attainable when $p(x_i)=1/n$ for all $i=1,2,\\ldots,n$. We finish the proof.\n",
    "\n",
    "One can find more on this topic in Conrad (2004).\n",
    "\n",
    "    </div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
